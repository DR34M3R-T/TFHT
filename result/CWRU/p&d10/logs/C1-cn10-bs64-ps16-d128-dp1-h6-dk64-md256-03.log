[2022-08-07 14:49:13,195] ## start time: 2022-08-07 14:49:13.070275
[2022-08-07 14:49:13,196] Using cuda device
[2022-08-07 14:49:13,197] In train:p&d10.npy.
[2022-08-07 14:49:13,198] One Channel
[2022-08-07 14:49:13,198] With Normal data.
[2022-08-07 14:49:13,199] Nunber of classes:10.
[2022-08-07 14:49:13,199] Nunber of ViT channels:1.
[2022-08-07 14:49:13,392] Totol epochs: 15
[2022-08-07 14:49:13,393] Epoch 1---------------
[2022-08-07 14:49:13,394] lr: 2.000000e-03
[2022-08-07 14:49:13,648] loss: 2.388058  [    0/ 4694]
[2022-08-07 14:49:17,432] loss: 1.672459  [  960/ 4694]
[2022-08-07 14:49:21,217] loss: 1.432140  [ 1920/ 4694]
[2022-08-07 14:49:25,000] loss: 0.571862  [ 2880/ 4694]
[2022-08-07 14:49:28,784] loss: 0.358299  [ 3840/ 4694]
[2022-08-07 14:49:38,721] Train Error: Accuracy: 86.834%, Avg loss: 0.411209
[2022-08-07 14:49:41,760] Test  Error: Accuracy: 87.219%, Avg loss: 0.411831
[2022-08-07 14:49:41,761] Epoch 2---------------
[2022-08-07 14:49:41,762] lr: 1.900000e-03
[2022-08-07 14:49:42,017] loss: 0.318603  [    0/ 4694]
[2022-08-07 14:49:45,802] loss: 0.347748  [  960/ 4694]
[2022-08-07 14:49:49,585] loss: 0.103568  [ 1920/ 4694]
[2022-08-07 14:49:53,369] loss: 0.137855  [ 2880/ 4694]
[2022-08-07 14:49:57,155] loss: 0.106443  [ 3840/ 4694]
[2022-08-07 14:50:07,092] Train Error: Accuracy: 79.911%, Avg loss: 0.740474
[2022-08-07 14:50:10,131] Test  Error: Accuracy: 79.272%, Avg loss: 0.765418
[2022-08-07 14:50:10,131] Epoch 3---------------
[2022-08-07 14:50:10,132] lr: 1.326841e-03
[2022-08-07 14:50:10,388] loss: 0.841140  [    0/ 4694]
[2022-08-07 14:50:14,171] loss: 0.189324  [  960/ 4694]
[2022-08-07 14:50:17,955] loss: 0.065030  [ 1920/ 4694]
[2022-08-07 14:50:21,737] loss: 0.043844  [ 2880/ 4694]
[2022-08-07 14:50:25,521] loss: 0.052396  [ 3840/ 4694]
[2022-08-07 14:50:35,461] Train Error: Accuracy: 96.890%, Avg loss: 0.094904
[2022-08-07 14:50:38,498] Test  Error: Accuracy: 96.745%, Avg loss: 0.108008
[2022-08-07 14:50:38,498] Epoch 4---------------
[2022-08-07 14:50:38,499] lr: 1.260499e-03
[2022-08-07 14:50:38,754] loss: 0.091141  [    0/ 4694]
[2022-08-07 14:50:42,538] loss: 0.036265  [  960/ 4694]
[2022-08-07 14:50:46,321] loss: 0.027784  [ 1920/ 4694]
[2022-08-07 14:50:50,105] loss: 0.052505  [ 2880/ 4694]
[2022-08-07 14:50:53,889] loss: 0.070955  [ 3840/ 4694]
[2022-08-07 14:51:03,826] Train Error: Accuracy: 98.850%, Avg loss: 0.042940
[2022-08-07 14:51:06,862] Test  Error: Accuracy: 98.468%, Avg loss: 0.057298
[2022-08-07 14:51:06,863] Epoch 5---------------
[2022-08-07 14:51:06,864] lr: 1.197474e-03
[2022-08-07 14:51:07,118] loss: 0.037874  [    0/ 4694]
[2022-08-07 14:51:10,902] loss: 0.027772  [  960/ 4694]
[2022-08-07 14:51:14,688] loss: 0.023279  [ 1920/ 4694]
[2022-08-07 14:51:18,471] loss: 0.031262  [ 2880/ 4694]
[2022-08-07 14:51:22,254] loss: 0.074805  [ 3840/ 4694]
[2022-08-07 14:51:32,190] Train Error: Accuracy: 98.850%, Avg loss: 0.037939
[2022-08-07 14:51:35,227] Test  Error: Accuracy: 98.277%, Avg loss: 0.061795
[2022-08-07 14:51:35,227] Epoch 6---------------
[2022-08-07 14:51:35,231] lr: 1.026684e-03
[2022-08-07 14:51:35,486] loss: 0.020167  [    0/ 4694]
[2022-08-07 14:51:39,270] loss: 0.023909  [  960/ 4694]
[2022-08-07 14:51:43,053] loss: 0.016618  [ 1920/ 4694]
[2022-08-07 14:51:46,837] loss: 0.039161  [ 2880/ 4694]
[2022-08-07 14:51:50,621] loss: 0.018606  [ 3840/ 4694]
[2022-08-07 14:52:00,562] Train Error: Accuracy: 98.615%, Avg loss: 0.044424
[2022-08-07 14:52:03,601] Test  Error: Accuracy: 98.085%, Avg loss: 0.063903
[2022-08-07 14:52:03,601] Epoch 7---------------
[2022-08-07 14:52:03,603] lr: 8.802533e-04
[2022-08-07 14:52:03,857] loss: 0.048962  [    0/ 4694]
[2022-08-07 14:52:07,640] loss: 0.037659  [  960/ 4694]
[2022-08-07 14:52:11,425] loss: 0.030215  [ 1920/ 4694]
[2022-08-07 14:52:15,210] loss: 0.010722  [ 2880/ 4694]
[2022-08-07 14:52:18,994] loss: 0.008179  [ 3840/ 4694]
[2022-08-07 14:52:28,931] Train Error: Accuracy: 99.808%, Avg loss: 0.012301
[2022-08-07 14:52:31,968] Test  Error: Accuracy: 99.043%, Avg loss: 0.031846
[2022-08-07 14:52:31,969] Epoch 8---------------
[2022-08-07 14:52:31,970] lr: 8.362407e-04
[2022-08-07 14:52:32,226] loss: 0.003068  [    0/ 4694]
[2022-08-07 14:52:36,024] loss: 0.007459  [  960/ 4694]
[2022-08-07 14:52:39,824] loss: 0.006534  [ 1920/ 4694]
[2022-08-07 14:52:43,624] loss: 0.011527  [ 2880/ 4694]
[2022-08-07 14:52:47,423] loss: 0.013851  [ 3840/ 4694]
[2022-08-07 14:52:57,398] Train Error: Accuracy: 99.531%, Avg loss: 0.018061
[2022-08-07 14:53:00,448] Test  Error: Accuracy: 99.043%, Avg loss: 0.037781
[2022-08-07 14:53:00,448] Epoch 9---------------
[2022-08-07 14:53:00,450] lr: 6.470671e-04
[2022-08-07 14:53:00,705] loss: 0.027626  [    0/ 4694]
[2022-08-07 14:53:04,504] loss: 0.017860  [  960/ 4694]
[2022-08-07 14:53:08,302] loss: 0.026292  [ 1920/ 4694]
[2022-08-07 14:53:12,101] loss: 0.016441  [ 2880/ 4694]
[2022-08-07 14:53:15,900] loss: 0.030203  [ 3840/ 4694]
[2022-08-07 14:53:25,876] Train Error: Accuracy: 99.744%, Avg loss: 0.012888
[2022-08-07 14:53:28,925] Test  Error: Accuracy: 98.995%, Avg loss: 0.033896
[2022-08-07 14:53:28,925] Epoch 10---------------
[2022-08-07 14:53:28,926] lr: 6.147137e-04
[2022-08-07 14:53:29,182] loss: 0.018441  [    0/ 4694]
[2022-08-07 14:53:32,981] loss: 0.004881  [  960/ 4694]
[2022-08-07 14:53:36,781] loss: 0.006110  [ 1920/ 4694]
[2022-08-07 14:53:40,579] loss: 0.002876  [ 2880/ 4694]
[2022-08-07 14:53:44,378] loss: 0.020380  [ 3840/ 4694]
[2022-08-07 14:53:54,356] Train Error: Accuracy: 99.446%, Avg loss: 0.017579
[2022-08-07 14:53:57,404] Test  Error: Accuracy: 99.090%, Avg loss: 0.026712
[2022-08-07 14:53:57,405] Epoch 11---------------
[2022-08-07 14:53:57,406] lr: 5.839780e-04
[2022-08-07 14:53:57,661] loss: 0.004851  [    0/ 4694]
[2022-08-07 14:54:01,460] loss: 0.002717  [  960/ 4694]
[2022-08-07 14:54:05,258] loss: 0.017355  [ 1920/ 4694]
[2022-08-07 14:54:09,057] loss: 0.045360  [ 2880/ 4694]
[2022-08-07 14:54:12,857] loss: 0.001754  [ 3840/ 4694]
[2022-08-07 14:54:22,845] Train Error: Accuracy: 99.893%, Avg loss: 0.007916
[2022-08-07 14:54:25,900] Test  Error: Accuracy: 99.090%, Avg loss: 0.029983
[2022-08-07 14:54:25,901] Epoch 12---------------
[2022-08-07 14:54:25,902] lr: 4.518711e-04
[2022-08-07 14:54:26,157] loss: 0.003936  [    0/ 4694]
[2022-08-07 14:54:29,957] loss: 0.011520  [  960/ 4694]
[2022-08-07 14:54:33,755] loss: 0.001191  [ 1920/ 4694]
[2022-08-07 14:54:37,555] loss: 0.002081  [ 2880/ 4694]
[2022-08-07 14:54:41,353] loss: 0.024334  [ 3840/ 4694]
[2022-08-07 14:54:51,345] Train Error: Accuracy: 99.979%, Avg loss: 0.006031
[2022-08-07 14:54:54,401] Test  Error: Accuracy: 99.282%, Avg loss: 0.023330
[2022-08-07 14:54:54,402] Epoch 13---------------
[2022-08-07 14:54:54,402] lr: 4.292775e-04
[2022-08-07 14:54:54,658] loss: 0.003905  [    0/ 4694]
[2022-08-07 14:54:58,458] loss: 0.001556  [  960/ 4694]
[2022-08-07 14:55:02,258] loss: 0.028806  [ 1920/ 4694]
[2022-08-07 14:55:06,057] loss: 0.021228  [ 2880/ 4694]
[2022-08-07 14:55:09,856] loss: 0.003402  [ 3840/ 4694]
[2022-08-07 14:55:19,848] Train Error: Accuracy: 99.915%, Avg loss: 0.006759
[2022-08-07 14:55:22,901] Test  Error: Accuracy: 99.473%, Avg loss: 0.022341
[2022-08-07 14:55:22,902] Epoch 14---------------
[2022-08-07 14:55:22,903] lr: 4.078137e-04
[2022-08-07 14:55:23,159] loss: 0.010785  [    0/ 4694]
[2022-08-07 14:55:26,958] loss: 0.003809  [  960/ 4694]
[2022-08-07 14:55:30,758] loss: 0.020093  [ 1920/ 4694]
[2022-08-07 14:55:34,558] loss: 0.002326  [ 2880/ 4694]
[2022-08-07 14:55:38,357] loss: 0.005002  [ 3840/ 4694]
[2022-08-07 14:55:48,347] Train Error: Accuracy: 99.787%, Avg loss: 0.009939
[2022-08-07 14:55:51,399] Test  Error: Accuracy: 99.186%, Avg loss: 0.022045
[2022-08-07 14:55:51,399] Epoch 15---------------
[2022-08-07 14:55:51,400] lr: 3.874230e-04
[2022-08-07 14:55:51,656] loss: 0.007395  [    0/ 4694]
[2022-08-07 14:55:55,456] loss: 0.001263  [  960/ 4694]
[2022-08-07 14:55:59,255] loss: 0.006913  [ 1920/ 4694]
[2022-08-07 14:56:03,054] loss: 0.004710  [ 2880/ 4694]
[2022-08-07 14:56:06,853] loss: 0.003688  [ 3840/ 4694]
[2022-08-07 14:56:16,840] Train Error: Accuracy: 99.851%, Avg loss: 0.007363
[2022-08-07 14:56:19,893] Test  Error: Accuracy: 98.947%, Avg loss: 0.027649
[2022-08-07 14:56:19,893] Done!
[2022-08-07 14:56:19,895] Number of parameters:567050
[2022-08-07 14:56:19,896] ## end time: 2022-08-07 14:56:19.893635
[2022-08-07 14:56:19,896] ## used time: 0:07:06.823360
