[2022-08-06 15:17:54,670] ## start time: 2022-08-06 15:17:54.546899
[2022-08-06 15:17:54,671] Using cuda device
[2022-08-06 15:17:54,672] In train:p&d10.npy.
[2022-08-06 15:17:54,673] One Channel
[2022-08-06 15:17:54,674] With Normal data.
[2022-08-06 15:17:54,674] Nunber of classes:10.
[2022-08-06 15:17:54,674] Nunber of ViT channels:1.
[2022-08-06 15:17:54,864] Totol epochs: 10
[2022-08-06 15:17:54,865] Epoch 1---------------
[2022-08-06 15:17:54,865] lr: 2.000000e-03
[2022-08-06 15:17:54,879] loss: 2.645735  [    0/ 4726]
[2022-08-06 15:17:55,041] loss: 1.919621  [  960/ 4726]
[2022-08-06 15:17:55,200] loss: 1.402756  [ 1920/ 4726]
[2022-08-06 15:17:55,363] loss: 0.738438  [ 2880/ 4726]
[2022-08-06 15:17:55,520] loss: 0.458537  [ 3840/ 4726]
[2022-08-06 15:17:55,958] Train Error: Accuracy: 94.520%, Avg loss: 0.311086
[2022-08-06 15:17:56,092] Test  Error: Accuracy: 94.409%, Avg loss: 0.321004
[2022-08-06 15:17:56,093] Epoch 2---------------
[2022-08-06 15:17:56,094] lr: 1.900000e-03
[2022-08-06 15:17:56,107] loss: 0.310083  [    0/ 4726]
[2022-08-06 15:17:56,268] loss: 0.183209  [  960/ 4726]
[2022-08-06 15:17:56,427] loss: 0.102753  [ 1920/ 4726]
[2022-08-06 15:17:56,587] loss: 0.070007  [ 2880/ 4726]
[2022-08-06 15:17:56,745] loss: 0.074957  [ 3840/ 4726]
[2022-08-06 15:17:57,181] Train Error: Accuracy: 99.683%, Avg loss: 0.050477
[2022-08-06 15:17:57,311] Test  Error: Accuracy: 99.562%, Avg loss: 0.052767
[2022-08-06 15:17:57,311] Epoch 3---------------
[2022-08-06 15:17:57,312] lr: 1.805000e-03
[2022-08-06 15:17:57,326] loss: 0.046562  [    0/ 4726]
[2022-08-06 15:17:57,481] loss: 0.037435  [  960/ 4726]
[2022-08-06 15:17:57,639] loss: 0.038254  [ 1920/ 4726]
[2022-08-06 15:17:57,795] loss: 0.027530  [ 2880/ 4726]
[2022-08-06 15:17:57,950] loss: 0.022820  [ 3840/ 4726]
[2022-08-06 15:17:58,374] Train Error: Accuracy: 99.704%, Avg loss: 0.025199
[2022-08-06 15:17:58,502] Test  Error: Accuracy: 99.854%, Avg loss: 0.026358
[2022-08-06 15:17:58,503] Epoch 4---------------
[2022-08-06 15:17:58,504] lr: 1.714750e-03
[2022-08-06 15:17:58,516] loss: 0.050314  [    0/ 4726]
[2022-08-06 15:17:58,672] loss: 0.020901  [  960/ 4726]
[2022-08-06 15:17:58,830] loss: 0.059276  [ 1920/ 4726]
[2022-08-06 15:17:58,985] loss: 0.015149  [ 2880/ 4726]
[2022-08-06 15:17:59,139] loss: 0.117615  [ 3840/ 4726]
[2022-08-06 15:17:59,565] Train Error: Accuracy: 99.788%, Avg loss: 0.030321
[2022-08-06 15:17:59,694] Test  Error: Accuracy: 99.708%, Avg loss: 0.029945
[2022-08-06 15:17:59,695] Epoch 5---------------
[2022-08-06 15:17:59,696] lr: 1.326841e-03
[2022-08-06 15:17:59,709] loss: 0.024825  [    0/ 4726]
[2022-08-06 15:17:59,866] loss: 0.020996  [  960/ 4726]
[2022-08-06 15:18:00,021] loss: 0.014633  [ 1920/ 4726]
[2022-08-06 15:18:00,176] loss: 0.011449  [ 2880/ 4726]
[2022-08-06 15:18:00,335] loss: 0.010201  [ 3840/ 4726]
[2022-08-06 15:18:00,760] Train Error: Accuracy: 100.000%, Avg loss: 0.010247
[2022-08-06 15:18:00,891] Test  Error: Accuracy: 99.951%, Avg loss: 0.013470
[2022-08-06 15:18:00,891] Epoch 6---------------
[2022-08-06 15:18:00,892] lr: 1.260499e-03
[2022-08-06 15:18:00,906] loss: 0.011683  [    0/ 4726]
[2022-08-06 15:18:01,063] loss: 0.009897  [  960/ 4726]
[2022-08-06 15:18:01,218] loss: 0.006554  [ 1920/ 4726]
[2022-08-06 15:18:01,373] loss: 0.006058  [ 2880/ 4726]
[2022-08-06 15:18:01,528] loss: 0.007007  [ 3840/ 4726]
[2022-08-06 15:18:01,954] Train Error: Accuracy: 99.979%, Avg loss: 0.007266
[2022-08-06 15:18:02,086] Test  Error: Accuracy: 99.903%, Avg loss: 0.009756
[2022-08-06 15:18:02,087] Epoch 7---------------
[2022-08-06 15:18:02,088] lr: 1.197474e-03
[2022-08-06 15:18:02,102] loss: 0.005373  [    0/ 4726]
[2022-08-06 15:18:02,257] loss: 0.005243  [  960/ 4726]
[2022-08-06 15:18:02,413] loss: 0.004333  [ 1920/ 4726]
[2022-08-06 15:18:02,569] loss: 0.006307  [ 2880/ 4726]
[2022-08-06 15:18:02,725] loss: 0.004457  [ 3840/ 4726]
[2022-08-06 15:18:03,151] Train Error: Accuracy: 99.979%, Avg loss: 0.006945
[2022-08-06 15:18:03,283] Test  Error: Accuracy: 99.903%, Avg loss: 0.007952
[2022-08-06 15:18:03,284] Epoch 8---------------
[2022-08-06 15:18:03,285] lr: 1.137600e-03
[2022-08-06 15:18:03,298] loss: 0.003761  [    0/ 4726]
[2022-08-06 15:18:03,453] loss: 0.007343  [  960/ 4726]
[2022-08-06 15:18:03,609] loss: 0.004630  [ 1920/ 4726]
[2022-08-06 15:18:03,764] loss: 0.004878  [ 2880/ 4726]
[2022-08-06 15:18:03,919] loss: 0.003817  [ 3840/ 4726]
[2022-08-06 15:18:04,345] Train Error: Accuracy: 99.937%, Avg loss: 0.006747
[2022-08-06 15:18:04,474] Test  Error: Accuracy: 100.000%, Avg loss: 0.008006
[2022-08-06 15:18:04,474] Epoch 9---------------
[2022-08-06 15:18:04,475] lr: 9.753500e-04
[2022-08-06 15:18:04,489] loss: 0.006963  [    0/ 4726]
[2022-08-06 15:18:04,645] loss: 0.004187  [  960/ 4726]
[2022-08-06 15:18:04,801] loss: 0.005124  [ 1920/ 4726]
[2022-08-06 15:18:04,956] loss: 0.004209  [ 2880/ 4726]
[2022-08-06 15:18:05,111] loss: 0.004737  [ 3840/ 4726]
[2022-08-06 15:18:05,537] Train Error: Accuracy: 99.979%, Avg loss: 0.004059
[2022-08-06 15:18:05,667] Test  Error: Accuracy: 100.000%, Avg loss: 0.004588
[2022-08-06 15:18:05,668] Epoch 10---------------
[2022-08-06 15:18:05,669] lr: 9.265825e-04
[2022-08-06 15:18:05,682] loss: 0.004387  [    0/ 4726]
[2022-08-06 15:18:05,838] loss: 0.030074  [  960/ 4726]
[2022-08-06 15:18:05,993] loss: 0.002917  [ 1920/ 4726]
[2022-08-06 15:18:06,148] loss: 0.006088  [ 2880/ 4726]
[2022-08-06 15:18:06,305] loss: 0.003522  [ 3840/ 4726]
[2022-08-06 15:18:06,730] Train Error: Accuracy: 100.000%, Avg loss: 0.003746
[2022-08-06 15:18:06,864] Test  Error: Accuracy: 99.854%, Avg loss: 0.007328
[2022-08-06 15:18:06,864] Done!
[2022-08-06 15:18:06,866] Number of parameters:124874
[2022-08-06 15:18:06,866] ## end time: 2022-08-06 15:18:06.864038
[2022-08-06 15:18:06,867] ## used time: 0:00:12.317139
