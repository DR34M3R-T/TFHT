[2022-08-06 15:29:37,317] ## start time: 2022-08-06 15:29:37.195832
[2022-08-06 15:29:37,318] Using cuda device
[2022-08-06 15:29:37,320] In train:p&d10.npy.
[2022-08-06 15:29:37,320] One Channel
[2022-08-06 15:29:37,320] With Normal data.
[2022-08-06 15:29:37,321] Nunber of classes:10.
[2022-08-06 15:29:37,321] Nunber of ViT channels:1.
[2022-08-06 15:29:37,512] Totol epochs: 10
[2022-08-06 15:29:37,514] Epoch 1---------------
[2022-08-06 15:29:37,514] lr: 2.000000e-03
[2022-08-06 15:29:37,528] loss: 2.489919  [    0/ 4821]
[2022-08-06 15:29:37,685] loss: 2.087590  [  960/ 4821]
[2022-08-06 15:29:37,843] loss: 1.903468  [ 1920/ 4821]
[2022-08-06 15:29:38,000] loss: 1.607052  [ 2880/ 4821]
[2022-08-06 15:29:38,150] loss: 1.295316  [ 3840/ 4821]
[2022-08-06 15:29:38,298] loss: 1.051824  [ 4800/ 4821]
[2022-08-06 15:29:38,565] Train Error: Accuracy: 62.684%, Avg loss: 1.059256
[2022-08-06 15:29:38,674] Test  Error: Accuracy: 63.252%, Avg loss: 1.049050
[2022-08-06 15:29:38,674] Epoch 2---------------
[2022-08-06 15:29:38,675] lr: 1.900000e-03
[2022-08-06 15:29:38,687] loss: 1.143651  [    0/ 4821]
[2022-08-06 15:29:38,836] loss: 0.744062  [  960/ 4821]
[2022-08-06 15:29:38,985] loss: 0.593521  [ 1920/ 4821]
[2022-08-06 15:29:39,138] loss: 0.410649  [ 2880/ 4821]
[2022-08-06 15:29:39,293] loss: 0.328750  [ 3840/ 4821]
[2022-08-06 15:29:39,448] loss: 0.271730  [ 4800/ 4821]
[2022-08-06 15:29:39,719] Train Error: Accuracy: 95.291%, Avg loss: 0.272187
[2022-08-06 15:29:39,829] Test  Error: Accuracy: 95.260%, Avg loss: 0.274665
[2022-08-06 15:29:39,830] Epoch 3---------------
[2022-08-06 15:29:39,831] lr: 1.805000e-03
[2022-08-06 15:29:39,843] loss: 0.259258  [    0/ 4821]
[2022-08-06 15:29:39,992] loss: 0.171255  [  960/ 4821]
[2022-08-06 15:29:40,145] loss: 0.198834  [ 1920/ 4821]
[2022-08-06 15:29:40,295] loss: 0.234795  [ 2880/ 4821]
[2022-08-06 15:29:40,443] loss: 0.141513  [ 3840/ 4821]
[2022-08-06 15:29:40,591] loss: 0.130896  [ 4800/ 4821]
[2022-08-06 15:29:40,856] Train Error: Accuracy: 98.092%, Avg loss: 0.127395
[2022-08-06 15:29:40,965] Test  Error: Accuracy: 97.961%, Avg loss: 0.131310
[2022-08-06 15:29:40,965] Epoch 4---------------
[2022-08-06 15:29:40,966] lr: 1.714750e-03
[2022-08-06 15:29:40,978] loss: 0.152328  [    0/ 4821]
[2022-08-06 15:29:41,130] loss: 0.102807  [  960/ 4821]
[2022-08-06 15:29:41,283] loss: 0.156925  [ 1920/ 4821]
[2022-08-06 15:29:41,432] loss: 0.087958  [ 2880/ 4821]
[2022-08-06 15:29:41,583] loss: 0.054415  [ 3840/ 4821]
[2022-08-06 15:29:41,732] loss: 0.121228  [ 4800/ 4821]
[2022-08-06 15:29:41,999] Train Error: Accuracy: 98.050%, Avg loss: 0.093689
[2022-08-06 15:29:42,108] Test  Error: Accuracy: 98.114%, Avg loss: 0.093439
[2022-08-06 15:29:42,108] Epoch 5---------------
[2022-08-06 15:29:42,109] lr: 1.629012e-03
[2022-08-06 15:29:42,123] loss: 0.069579  [    0/ 4821]
[2022-08-06 15:29:42,276] loss: 0.085113  [  960/ 4821]
[2022-08-06 15:29:42,426] loss: 0.065885  [ 1920/ 4821]
[2022-08-06 15:29:42,574] loss: 0.045047  [ 2880/ 4821]
[2022-08-06 15:29:42,724] loss: 0.026724  [ 3840/ 4821]
[2022-08-06 15:29:42,872] loss: 0.061241  [ 4800/ 4821]
[2022-08-06 15:29:43,137] Train Error: Accuracy: 99.233%, Avg loss: 0.050752
[2022-08-06 15:29:43,245] Test  Error: Accuracy: 98.726%, Avg loss: 0.066190
[2022-08-06 15:29:43,245] Epoch 6---------------
[2022-08-06 15:29:43,246] lr: 1.547562e-03
[2022-08-06 15:29:43,258] loss: 0.026705  [    0/ 4821]
[2022-08-06 15:29:43,411] loss: 0.037113  [  960/ 4821]
[2022-08-06 15:29:43,562] loss: 0.031587  [ 1920/ 4821]
[2022-08-06 15:29:43,710] loss: 0.085567  [ 2880/ 4821]
[2022-08-06 15:29:43,858] loss: 0.020162  [ 3840/ 4821]
[2022-08-06 15:29:44,005] loss: 0.035362  [ 4800/ 4821]
[2022-08-06 15:29:44,270] Train Error: Accuracy: 99.046%, Avg loss: 0.050351
[2022-08-06 15:29:44,381] Test  Error: Accuracy: 98.828%, Avg loss: 0.056782
[2022-08-06 15:29:44,382] Epoch 7---------------
[2022-08-06 15:29:44,383] lr: 1.470184e-03
[2022-08-06 15:29:44,395] loss: 0.117873  [    0/ 4821]
[2022-08-06 15:29:44,546] loss: 0.030161  [  960/ 4821]
[2022-08-06 15:29:44,696] loss: 0.038668  [ 1920/ 4821]
[2022-08-06 15:29:44,849] loss: 0.037697  [ 2880/ 4821]
[2022-08-06 15:29:45,000] loss: 0.028327  [ 3840/ 4821]
[2022-08-06 15:29:45,151] loss: 0.044880  [ 4800/ 4821]
[2022-08-06 15:29:45,420] Train Error: Accuracy: 98.942%, Avg loss: 0.050463
[2022-08-06 15:29:45,533] Test  Error: Accuracy: 98.471%, Avg loss: 0.061310
[2022-08-06 15:29:45,533] Epoch 8---------------
[2022-08-06 15:29:45,534] lr: 1.260499e-03
[2022-08-06 15:29:45,546] loss: 0.077662  [    0/ 4821]
[2022-08-06 15:29:45,696] loss: 0.020960  [  960/ 4821]
[2022-08-06 15:29:45,845] loss: 0.069090  [ 1920/ 4821]
[2022-08-06 15:29:45,993] loss: 0.027321  [ 2880/ 4821]
[2022-08-06 15:29:46,144] loss: 0.011376  [ 3840/ 4821]
[2022-08-06 15:29:46,291] loss: 0.042195  [ 4800/ 4821]
[2022-08-06 15:29:46,559] Train Error: Accuracy: 99.274%, Avg loss: 0.035905
[2022-08-06 15:29:46,669] Test  Error: Accuracy: 98.573%, Avg loss: 0.051225
[2022-08-06 15:29:46,669] Epoch 9---------------
[2022-08-06 15:29:46,671] lr: 1.197474e-03
[2022-08-06 15:29:46,682] loss: 0.028737  [    0/ 4821]
[2022-08-06 15:29:46,833] loss: 0.021006  [  960/ 4821]
[2022-08-06 15:29:46,982] loss: 0.011343  [ 1920/ 4821]
[2022-08-06 15:29:47,132] loss: 0.036959  [ 2880/ 4821]
[2022-08-06 15:29:47,281] loss: 0.018934  [ 3840/ 4821]
[2022-08-06 15:29:47,430] loss: 0.016231  [ 4800/ 4821]
[2022-08-06 15:29:47,703] Train Error: Accuracy: 99.564%, Avg loss: 0.024291
[2022-08-06 15:29:47,810] Test  Error: Accuracy: 99.388%, Avg loss: 0.031325
[2022-08-06 15:29:47,810] Epoch 10---------------
[2022-08-06 15:29:47,811] lr: 1.137600e-03
[2022-08-06 15:29:47,822] loss: 0.016192  [    0/ 4821]
[2022-08-06 15:29:47,971] loss: 0.030173  [  960/ 4821]
[2022-08-06 15:29:48,121] loss: 0.009555  [ 1920/ 4821]
[2022-08-06 15:29:48,270] loss: 0.009057  [ 2880/ 4821]
[2022-08-06 15:29:48,423] loss: 0.008510  [ 3840/ 4821]
[2022-08-06 15:29:48,571] loss: 0.041859  [ 4800/ 4821]
[2022-08-06 15:29:48,843] Train Error: Accuracy: 99.647%, Avg loss: 0.022749
[2022-08-06 15:29:48,952] Test  Error: Accuracy: 98.879%, Avg loss: 0.040141
[2022-08-06 15:29:48,952] Done!
[2022-08-06 15:29:48,954] Number of parameters:27626
[2022-08-06 15:29:48,954] ## end time: 2022-08-06 15:29:48.952412
[2022-08-06 15:29:48,955] ## used time: 0:00:11.756580
