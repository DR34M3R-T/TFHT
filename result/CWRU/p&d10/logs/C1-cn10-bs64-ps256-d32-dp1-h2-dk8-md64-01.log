[2022-08-06 15:20:35,963] ## start time: 2022-08-06 15:20:35.837338
[2022-08-06 15:20:35,964] Using cuda device
[2022-08-06 15:20:35,964] In train:p&d10.npy.
[2022-08-06 15:20:35,964] One Channel
[2022-08-06 15:20:35,964] With Normal data.
[2022-08-06 15:20:35,965] Nunber of classes:10.
[2022-08-06 15:20:35,965] Nunber of ViT channels:1.
[2022-08-06 15:20:36,967] Totol epochs: 10
[2022-08-06 15:20:36,968] Epoch 1---------------
[2022-08-06 15:20:36,968] lr: 2.000000e-03
[2022-08-06 15:20:38,482] loss: 2.382379  [    0/ 4720]
[2022-08-06 15:20:38,634] loss: 1.955048  [  960/ 4720]
[2022-08-06 15:20:38,787] loss: 1.766098  [ 1920/ 4720]
[2022-08-06 15:20:38,939] loss: 1.103002  [ 2880/ 4720]
[2022-08-06 15:20:39,090] loss: 0.898892  [ 3840/ 4720]
[2022-08-06 15:20:39,485] Train Error: Accuracy: 86.631%, Avg loss: 0.512435
[2022-08-06 15:20:39,606] Test  Error: Accuracy: 86.476%, Avg loss: 0.526944
[2022-08-06 15:20:39,606] Epoch 2---------------
[2022-08-06 15:20:39,606] lr: 1.900000e-03
[2022-08-06 15:20:39,617] loss: 0.542778  [    0/ 4720]
[2022-08-06 15:20:39,767] loss: 0.534409  [  960/ 4720]
[2022-08-06 15:20:39,917] loss: 0.262853  [ 1920/ 4720]
[2022-08-06 15:20:40,068] loss: 0.164498  [ 2880/ 4720]
[2022-08-06 15:20:40,230] loss: 0.101180  [ 3840/ 4720]
[2022-08-06 15:20:40,648] Train Error: Accuracy: 97.881%, Avg loss: 0.112692
[2022-08-06 15:20:40,769] Test  Error: Accuracy: 97.189%, Avg loss: 0.134728
[2022-08-06 15:20:40,769] Epoch 3---------------
[2022-08-06 15:20:40,770] lr: 1.805000e-03
[2022-08-06 15:20:40,782] loss: 0.116132  [    0/ 4720]
[2022-08-06 15:20:40,936] loss: 0.090111  [  960/ 4720]
[2022-08-06 15:20:41,089] loss: 0.086945  [ 1920/ 4720]
[2022-08-06 15:20:41,242] loss: 0.047373  [ 2880/ 4720]
[2022-08-06 15:20:41,395] loss: 0.045755  [ 3840/ 4720]
[2022-08-06 15:20:41,809] Train Error: Accuracy: 99.258%, Avg loss: 0.047968
[2022-08-06 15:20:41,933] Test  Error: Accuracy: 98.594%, Avg loss: 0.067301
[2022-08-06 15:20:41,933] Epoch 4---------------
[2022-08-06 15:20:41,934] lr: 1.714750e-03
[2022-08-06 15:20:41,946] loss: 0.044139  [    0/ 4720]
[2022-08-06 15:20:42,098] loss: 0.088415  [  960/ 4720]
[2022-08-06 15:20:42,251] loss: 0.050395  [ 1920/ 4720]
[2022-08-06 15:20:42,403] loss: 0.023250  [ 2880/ 4720]
[2022-08-06 15:20:42,555] loss: 0.057461  [ 3840/ 4720]
[2022-08-06 15:20:42,965] Train Error: Accuracy: 99.386%, Avg loss: 0.035223
[2022-08-06 15:20:43,087] Test  Error: Accuracy: 98.594%, Avg loss: 0.060986
[2022-08-06 15:20:43,088] Epoch 5---------------
[2022-08-06 15:20:43,089] lr: 1.629012e-03
[2022-08-06 15:20:43,102] loss: 0.024135  [    0/ 4720]
[2022-08-06 15:20:43,254] loss: 0.018188  [  960/ 4720]
[2022-08-06 15:20:43,406] loss: 0.017626  [ 1920/ 4720]
[2022-08-06 15:20:43,562] loss: 0.016615  [ 2880/ 4720]
[2022-08-06 15:20:43,716] loss: 0.013625  [ 3840/ 4720]
[2022-08-06 15:20:44,117] Train Error: Accuracy: 99.407%, Avg loss: 0.027836
[2022-08-06 15:20:44,235] Test  Error: Accuracy: 98.740%, Avg loss: 0.047935
[2022-08-06 15:20:44,236] Epoch 6---------------
[2022-08-06 15:20:44,237] lr: 1.547562e-03
[2022-08-06 15:20:44,250] loss: 0.029953  [    0/ 4720]
[2022-08-06 15:20:44,400] loss: 0.017844  [  960/ 4720]
[2022-08-06 15:20:44,551] loss: 0.011993  [ 1920/ 4720]
[2022-08-06 15:20:44,700] loss: 0.011121  [ 2880/ 4720]
[2022-08-06 15:20:44,851] loss: 0.031529  [ 3840/ 4720]
[2022-08-06 15:20:45,252] Train Error: Accuracy: 98.729%, Avg loss: 0.043609
[2022-08-06 15:20:45,378] Test  Error: Accuracy: 97.916%, Avg loss: 0.061535
[2022-08-06 15:20:45,379] Epoch 7---------------
[2022-08-06 15:20:45,380] lr: 1.080720e-03
[2022-08-06 15:20:45,392] loss: 0.043920  [    0/ 4720]
[2022-08-06 15:20:45,549] loss: 0.013034  [  960/ 4720]
[2022-08-06 15:20:45,703] loss: 0.013216  [ 1920/ 4720]
[2022-08-06 15:20:45,855] loss: 0.012544  [ 2880/ 4720]
[2022-08-06 15:20:46,010] loss: 0.004380  [ 3840/ 4720]
[2022-08-06 15:20:46,409] Train Error: Accuracy: 99.894%, Avg loss: 0.011408
[2022-08-06 15:20:46,528] Test  Error: Accuracy: 99.515%, Avg loss: 0.024040
[2022-08-06 15:20:46,529] Epoch 8---------------
[2022-08-06 15:20:46,530] lr: 1.026684e-03
[2022-08-06 15:20:46,542] loss: 0.010643  [    0/ 4720]
[2022-08-06 15:20:46,692] loss: 0.015109  [  960/ 4720]
[2022-08-06 15:20:46,845] loss: 0.007112  [ 1920/ 4720]
[2022-08-06 15:20:46,996] loss: 0.011518  [ 2880/ 4720]
[2022-08-06 15:20:47,151] loss: 0.009202  [ 3840/ 4720]
[2022-08-06 15:20:47,550] Train Error: Accuracy: 99.873%, Avg loss: 0.008780
[2022-08-06 15:20:47,672] Test  Error: Accuracy: 99.661%, Avg loss: 0.019638
[2022-08-06 15:20:47,672] Epoch 9---------------
[2022-08-06 15:20:47,673] lr: 9.753500e-04
[2022-08-06 15:20:47,684] loss: 0.007589  [    0/ 4720]
[2022-08-06 15:20:47,835] loss: 0.009204  [  960/ 4720]
[2022-08-06 15:20:47,985] loss: 0.008612  [ 1920/ 4720]
[2022-08-06 15:20:48,137] loss: 0.004641  [ 2880/ 4720]
[2022-08-06 15:20:48,290] loss: 0.004419  [ 3840/ 4720]
[2022-08-06 15:20:48,687] Train Error: Accuracy: 99.936%, Avg loss: 0.007755
[2022-08-06 15:20:48,804] Test  Error: Accuracy: 99.224%, Avg loss: 0.028390
[2022-08-06 15:20:48,804] Epoch 10---------------
[2022-08-06 15:20:48,805] lr: 6.811233e-04
[2022-08-06 15:20:48,816] loss: 0.004532  [    0/ 4720]
[2022-08-06 15:20:48,969] loss: 0.004787  [  960/ 4720]
[2022-08-06 15:20:49,120] loss: 0.011748  [ 1920/ 4720]
[2022-08-06 15:20:49,274] loss: 0.009900  [ 2880/ 4720]
[2022-08-06 15:20:49,425] loss: 0.004261  [ 3840/ 4720]
[2022-08-06 15:20:49,825] Train Error: Accuracy: 99.894%, Avg loss: 0.008063
[2022-08-06 15:20:49,943] Test  Error: Accuracy: 99.273%, Avg loss: 0.024226
[2022-08-06 15:20:49,944] Done!
[2022-08-06 15:20:49,945] Number of parameters:30666
[2022-08-06 15:20:49,946] ## end time: 2022-08-06 15:20:49.944095
[2022-08-06 15:20:49,946] ## used time: 0:00:14.106757
