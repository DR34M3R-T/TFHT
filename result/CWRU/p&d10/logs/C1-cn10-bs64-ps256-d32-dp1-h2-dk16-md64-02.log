[2022-08-06 15:21:25,019] ## start time: 2022-08-06 15:21:24.896232
[2022-08-06 15:21:25,019] Using cuda device
[2022-08-06 15:21:25,020] In train:p&d10.npy.
[2022-08-06 15:21:25,021] One Channel
[2022-08-06 15:21:25,022] With Normal data.
[2022-08-06 15:21:25,022] Nunber of classes:10.
[2022-08-06 15:21:25,023] Nunber of ViT channels:1.
[2022-08-06 15:21:25,206] Totol epochs: 10
[2022-08-06 15:21:25,208] Epoch 1---------------
[2022-08-06 15:21:25,208] lr: 2.000000e-03
[2022-08-06 15:21:25,221] loss: 2.491919  [    0/ 4730]
[2022-08-06 15:21:25,378] loss: 2.075085  [  960/ 4730]
[2022-08-06 15:21:25,537] loss: 1.472634  [ 1920/ 4730]
[2022-08-06 15:21:25,688] loss: 1.263704  [ 2880/ 4730]
[2022-08-06 15:21:25,839] loss: 0.919105  [ 3840/ 4730]
[2022-08-06 15:21:26,232] Train Error: Accuracy: 88.203%, Avg loss: 0.502784
[2022-08-06 15:21:26,349] Test  Error: Accuracy: 86.751%, Avg loss: 0.523852
[2022-08-06 15:21:26,349] Epoch 2---------------
[2022-08-06 15:21:26,350] lr: 1.900000e-03
[2022-08-06 15:21:26,361] loss: 0.416080  [    0/ 4730]
[2022-08-06 15:21:26,510] loss: 0.470067  [  960/ 4730]
[2022-08-06 15:21:26,662] loss: 0.191317  [ 1920/ 4730]
[2022-08-06 15:21:26,813] loss: 0.134126  [ 2880/ 4730]
[2022-08-06 15:21:26,963] loss: 0.174867  [ 3840/ 4730]
[2022-08-06 15:21:27,353] Train Error: Accuracy: 98.541%, Avg loss: 0.108427
[2022-08-06 15:21:27,468] Test  Error: Accuracy: 98.052%, Avg loss: 0.125285
[2022-08-06 15:21:27,468] Epoch 3---------------
[2022-08-06 15:21:27,469] lr: 1.805000e-03
[2022-08-06 15:21:27,481] loss: 0.088978  [    0/ 4730]
[2022-08-06 15:21:27,631] loss: 0.077466  [  960/ 4730]
[2022-08-06 15:21:27,780] loss: 0.058257  [ 1920/ 4730]
[2022-08-06 15:21:27,937] loss: 0.047078  [ 2880/ 4730]
[2022-08-06 15:21:28,089] loss: 0.076350  [ 3840/ 4730]
[2022-08-06 15:21:28,480] Train Error: Accuracy: 99.323%, Avg loss: 0.044050
[2022-08-06 15:21:28,598] Test  Error: Accuracy: 98.977%, Avg loss: 0.054199
[2022-08-06 15:21:28,599] Epoch 4---------------
[2022-08-06 15:21:28,600] lr: 1.714750e-03
[2022-08-06 15:21:28,611] loss: 0.073540  [    0/ 4730]
[2022-08-06 15:21:28,761] loss: 0.016406  [  960/ 4730]
[2022-08-06 15:21:28,910] loss: 0.021802  [ 1920/ 4730]
[2022-08-06 15:21:29,062] loss: 0.050510  [ 2880/ 4730]
[2022-08-06 15:21:29,210] loss: 0.027650  [ 3840/ 4730]
[2022-08-06 15:21:29,602] Train Error: Accuracy: 85.624%, Avg loss: 0.394729
[2022-08-06 15:21:29,718] Test  Error: Accuracy: 84.803%, Avg loss: 0.428125
[2022-08-06 15:21:29,718] Epoch 5---------------
[2022-08-06 15:21:29,719] lr: 1.197474e-03
[2022-08-06 15:21:29,731] loss: 0.401403  [    0/ 4730]
[2022-08-06 15:21:29,879] loss: 0.018127  [  960/ 4730]
[2022-08-06 15:21:30,031] loss: 0.021734  [ 1920/ 4730]
[2022-08-06 15:21:30,180] loss: 0.027747  [ 2880/ 4730]
[2022-08-06 15:21:30,329] loss: 0.020961  [ 3840/ 4730]
[2022-08-06 15:21:30,721] Train Error: Accuracy: 99.683%, Avg loss: 0.019278
[2022-08-06 15:21:30,837] Test  Error: Accuracy: 99.513%, Avg loss: 0.026073
[2022-08-06 15:21:30,837] Epoch 6---------------
[2022-08-06 15:21:30,838] lr: 1.137600e-03
[2022-08-06 15:21:30,850] loss: 0.014377  [    0/ 4730]
[2022-08-06 15:21:30,999] loss: 0.005497  [  960/ 4730]
[2022-08-06 15:21:31,153] loss: 0.024978  [ 1920/ 4730]
[2022-08-06 15:21:31,304] loss: 0.008373  [ 2880/ 4730]
[2022-08-06 15:21:31,451] loss: 0.021754  [ 3840/ 4730]
[2022-08-06 15:21:31,848] Train Error: Accuracy: 99.767%, Avg loss: 0.017429
[2022-08-06 15:21:31,964] Test  Error: Accuracy: 99.513%, Avg loss: 0.028237
[2022-08-06 15:21:31,964] Epoch 7---------------
[2022-08-06 15:21:31,965] lr: 9.753500e-04
[2022-08-06 15:21:31,978] loss: 0.033499  [    0/ 4730]
[2022-08-06 15:21:32,131] loss: 0.005323  [  960/ 4730]
[2022-08-06 15:21:32,282] loss: 0.007634  [ 1920/ 4730]
[2022-08-06 15:21:32,431] loss: 0.004184  [ 2880/ 4730]
[2022-08-06 15:21:32,580] loss: 0.007025  [ 3840/ 4730]
[2022-08-06 15:21:32,973] Train Error: Accuracy: 99.873%, Avg loss: 0.010773
[2022-08-06 15:21:33,093] Test  Error: Accuracy: 99.708%, Avg loss: 0.017134
[2022-08-06 15:21:33,093] Epoch 8---------------
[2022-08-06 15:21:33,094] lr: 9.265825e-04
[2022-08-06 15:21:33,107] loss: 0.007056  [    0/ 4730]
[2022-08-06 15:21:33,269] loss: 0.011539  [  960/ 4730]
[2022-08-06 15:21:33,420] loss: 0.011523  [ 1920/ 4730]
[2022-08-06 15:21:33,570] loss: 0.003623  [ 2880/ 4730]
[2022-08-06 15:21:33,720] loss: 0.012228  [ 3840/ 4730]
[2022-08-06 15:21:34,115] Train Error: Accuracy: 99.958%, Avg loss: 0.008202
[2022-08-06 15:21:34,232] Test  Error: Accuracy: 99.756%, Avg loss: 0.013460
[2022-08-06 15:21:34,232] Epoch 9---------------
[2022-08-06 15:21:34,233] lr: 8.802533e-04
[2022-08-06 15:21:34,245] loss: 0.007814  [    0/ 4730]
[2022-08-06 15:21:34,397] loss: 0.008072  [  960/ 4730]
[2022-08-06 15:21:34,545] loss: 0.004360  [ 1920/ 4730]
[2022-08-06 15:21:34,693] loss: 0.009136  [ 2880/ 4730]
[2022-08-06 15:21:34,842] loss: 0.006736  [ 3840/ 4730]
[2022-08-06 15:21:35,233] Train Error: Accuracy: 99.937%, Avg loss: 0.006233
[2022-08-06 15:21:35,350] Test  Error: Accuracy: 99.659%, Avg loss: 0.017157
[2022-08-06 15:21:35,350] Epoch 10---------------
[2022-08-06 15:21:35,351] lr: 6.147137e-04
[2022-08-06 15:21:35,363] loss: 0.005660  [    0/ 4730]
[2022-08-06 15:21:35,518] loss: 0.006482  [  960/ 4730]
[2022-08-06 15:21:35,669] loss: 0.003628  [ 1920/ 4730]
[2022-08-06 15:21:35,816] loss: 0.005551  [ 2880/ 4730]
[2022-08-06 15:21:35,967] loss: 0.006295  [ 3840/ 4730]
[2022-08-06 15:21:36,362] Train Error: Accuracy: 99.894%, Avg loss: 0.007622
[2022-08-06 15:21:36,479] Test  Error: Accuracy: 99.805%, Avg loss: 0.010848
[2022-08-06 15:21:36,480] Done!
[2022-08-06 15:21:36,482] Number of parameters:34762
[2022-08-06 15:21:36,482] ## end time: 2022-08-06 15:21:36.480844
[2022-08-06 15:21:36,482] ## used time: 0:00:11.584612
