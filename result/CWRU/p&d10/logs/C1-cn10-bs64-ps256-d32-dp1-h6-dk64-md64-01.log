[2022-08-06 15:17:42,215] ## start time: 2022-08-06 15:17:42.093649
[2022-08-06 15:17:42,216] Using cuda device
[2022-08-06 15:17:42,217] In train:p&d10.npy.
[2022-08-06 15:17:42,218] One Channel
[2022-08-06 15:17:42,219] With Normal data.
[2022-08-06 15:17:42,219] Nunber of classes:10.
[2022-08-06 15:17:42,219] Nunber of ViT channels:1.
[2022-08-06 15:17:42,406] Totol epochs: 10
[2022-08-06 15:17:42,407] Epoch 1---------------
[2022-08-06 15:17:42,407] lr: 2.000000e-03
[2022-08-06 15:17:42,421] loss: 2.437446  [    0/ 4792]
[2022-08-06 15:17:42,582] loss: 1.775970  [  960/ 4792]
[2022-08-06 15:17:42,746] loss: 1.392288  [ 1920/ 4792]
[2022-08-06 15:17:42,905] loss: 0.987931  [ 2880/ 4792]
[2022-08-06 15:17:43,062] loss: 0.432202  [ 3840/ 4792]
[2022-08-06 15:17:43,533] Train Error: Accuracy: 96.932%, Avg loss: 0.225148
[2022-08-06 15:17:43,667] Test  Error: Accuracy: 95.831%, Avg loss: 0.252468
[2022-08-06 15:17:43,667] Epoch 2---------------
[2022-08-06 15:17:43,668] lr: 1.900000e-03
[2022-08-06 15:17:43,681] loss: 0.249453  [    0/ 4792]
[2022-08-06 15:17:43,842] loss: 0.111613  [  960/ 4792]
[2022-08-06 15:17:44,003] loss: 0.082388  [ 1920/ 4792]
[2022-08-06 15:17:44,159] loss: 0.104473  [ 2880/ 4792]
[2022-08-06 15:17:44,315] loss: 0.063288  [ 3840/ 4792]
[2022-08-06 15:17:44,756] Train Error: Accuracy: 99.750%, Avg loss: 0.046173
[2022-08-06 15:17:44,882] Test  Error: Accuracy: 99.548%, Avg loss: 0.054067
[2022-08-06 15:17:44,882] Epoch 3---------------
[2022-08-06 15:17:44,883] lr: 1.805000e-03
[2022-08-06 15:17:44,896] loss: 0.054930  [    0/ 4792]
[2022-08-06 15:17:45,052] loss: 0.041333  [  960/ 4792]
[2022-08-06 15:17:45,207] loss: 0.024192  [ 1920/ 4792]
[2022-08-06 15:17:45,362] loss: 0.105705  [ 2880/ 4792]
[2022-08-06 15:17:45,517] loss: 0.025960  [ 3840/ 4792]
[2022-08-06 15:17:45,966] Train Error: Accuracy: 99.604%, Avg loss: 0.027949
[2022-08-06 15:17:46,091] Test  Error: Accuracy: 99.448%, Avg loss: 0.037426
[2022-08-06 15:17:46,091] Epoch 4---------------
[2022-08-06 15:17:46,092] lr: 1.714750e-03
[2022-08-06 15:17:46,106] loss: 0.016317  [    0/ 4792]
[2022-08-06 15:17:46,260] loss: 0.021481  [  960/ 4792]
[2022-08-06 15:17:46,415] loss: 0.016088  [ 1920/ 4792]
[2022-08-06 15:17:46,574] loss: 0.015689  [ 2880/ 4792]
[2022-08-06 15:17:46,733] loss: 0.012162  [ 3840/ 4792]
[2022-08-06 15:17:47,176] Train Error: Accuracy: 99.624%, Avg loss: 0.025972
[2022-08-06 15:17:47,301] Test  Error: Accuracy: 99.096%, Avg loss: 0.040359
[2022-08-06 15:17:47,301] Epoch 5---------------
[2022-08-06 15:17:47,302] lr: 1.470184e-03
[2022-08-06 15:17:47,315] loss: 0.013795  [    0/ 4792]
[2022-08-06 15:17:47,470] loss: 0.018553  [  960/ 4792]
[2022-08-06 15:17:47,626] loss: 0.008089  [ 1920/ 4792]
[2022-08-06 15:17:47,781] loss: 0.021791  [ 2880/ 4792]
[2022-08-06 15:17:47,936] loss: 0.008272  [ 3840/ 4792]
[2022-08-06 15:17:48,376] Train Error: Accuracy: 99.937%, Avg loss: 0.007742
[2022-08-06 15:17:48,501] Test  Error: Accuracy: 99.799%, Avg loss: 0.013735
[2022-08-06 15:17:48,501] Epoch 6---------------
[2022-08-06 15:17:48,502] lr: 1.396675e-03
[2022-08-06 15:17:48,515] loss: 0.004263  [    0/ 4792]
[2022-08-06 15:17:48,672] loss: 0.005122  [  960/ 4792]
[2022-08-06 15:17:48,828] loss: 0.005573  [ 1920/ 4792]
[2022-08-06 15:17:48,983] loss: 0.006976  [ 2880/ 4792]
[2022-08-06 15:17:49,141] loss: 0.008382  [ 3840/ 4792]
[2022-08-06 15:17:49,577] Train Error: Accuracy: 99.979%, Avg loss: 0.005539
[2022-08-06 15:17:49,701] Test  Error: Accuracy: 99.900%, Avg loss: 0.010432
[2022-08-06 15:17:49,701] Epoch 7---------------
[2022-08-06 15:17:49,702] lr: 1.326841e-03
[2022-08-06 15:17:49,716] loss: 0.003847  [    0/ 4792]
[2022-08-06 15:17:49,871] loss: 0.006415  [  960/ 4792]
[2022-08-06 15:17:50,025] loss: 0.046333  [ 1920/ 4792]
[2022-08-06 15:17:50,181] loss: 0.013921  [ 2880/ 4792]
[2022-08-06 15:17:50,336] loss: 0.004790  [ 3840/ 4792]
[2022-08-06 15:17:50,774] Train Error: Accuracy: 99.833%, Avg loss: 0.011281
[2022-08-06 15:17:50,898] Test  Error: Accuracy: 99.498%, Avg loss: 0.020992
[2022-08-06 15:17:50,898] Epoch 8---------------
[2022-08-06 15:17:50,899] lr: 9.265825e-04
[2022-08-06 15:17:50,912] loss: 0.006457  [    0/ 4792]
[2022-08-06 15:17:51,066] loss: 0.023921  [  960/ 4792]
[2022-08-06 15:17:51,223] loss: 0.004344  [ 1920/ 4792]
[2022-08-06 15:17:51,378] loss: 0.006126  [ 2880/ 4792]
[2022-08-06 15:17:51,535] loss: 0.002729  [ 3840/ 4792]
[2022-08-06 15:17:51,972] Train Error: Accuracy: 99.979%, Avg loss: 0.003946
[2022-08-06 15:17:52,099] Test  Error: Accuracy: 99.900%, Avg loss: 0.006773
[2022-08-06 15:17:52,099] Epoch 9---------------
[2022-08-06 15:17:52,100] lr: 8.802533e-04
[2022-08-06 15:17:52,113] loss: 0.002319  [    0/ 4792]
[2022-08-06 15:17:52,270] loss: 0.002315  [  960/ 4792]
[2022-08-06 15:17:52,425] loss: 0.002607  [ 1920/ 4792]
[2022-08-06 15:17:52,580] loss: 0.002534  [ 2880/ 4792]
[2022-08-06 15:17:52,738] loss: 0.002955  [ 3840/ 4792]
[2022-08-06 15:17:53,174] Train Error: Accuracy: 99.917%, Avg loss: 0.005041
[2022-08-06 15:17:53,299] Test  Error: Accuracy: 99.900%, Avg loss: 0.007812
[2022-08-06 15:17:53,300] Epoch 10---------------
[2022-08-06 15:17:53,301] lr: 6.811233e-04
[2022-08-06 15:17:53,314] loss: 0.001988  [    0/ 4792]
[2022-08-06 15:17:53,469] loss: 0.003232  [  960/ 4792]
[2022-08-06 15:17:53,625] loss: 0.002122  [ 1920/ 4792]
[2022-08-06 15:17:53,781] loss: 0.002807  [ 2880/ 4792]
[2022-08-06 15:17:53,937] loss: 0.004143  [ 3840/ 4792]
[2022-08-06 15:17:54,375] Train Error: Accuracy: 99.979%, Avg loss: 0.003344
[2022-08-06 15:17:54,500] Test  Error: Accuracy: 99.799%, Avg loss: 0.007067
[2022-08-06 15:17:54,500] Done!
[2022-08-06 15:17:54,502] Number of parameters:124874
[2022-08-06 15:17:54,503] ## end time: 2022-08-06 15:17:54.500889
[2022-08-06 15:17:54,503] ## used time: 0:00:12.407240
