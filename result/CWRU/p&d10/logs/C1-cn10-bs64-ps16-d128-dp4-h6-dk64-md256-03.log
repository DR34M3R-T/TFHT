[2022-08-07 16:35:51,836] ## start time: 2022-08-07 16:35:51.670094
[2022-08-07 16:35:51,836] Using cuda device
[2022-08-07 16:35:51,838] In train:p&d10.npy.
[2022-08-07 16:35:51,839] One Channel
[2022-08-07 16:35:51,839] With Normal data.
[2022-08-07 16:35:51,840] Nunber of classes:10.
[2022-08-07 16:35:51,840] Nunber of ViT channels:1.
[2022-08-07 16:35:52,104] Totol epochs: 15
[2022-08-07 16:35:52,107] Epoch 1---------------
[2022-08-07 16:35:52,107] lr: 2.000000e-03
[2022-08-07 16:35:53,109] loss: 2.743991  [    0/ 4710]
[2022-08-07 16:36:08,099] loss: 1.693189  [  960/ 4710]
[2022-08-07 16:36:23,090] loss: 1.806386  [ 1920/ 4710]
[2022-08-07 16:36:38,080] loss: 1.576490  [ 2880/ 4710]
[2022-08-07 16:36:53,072] loss: 0.567306  [ 3840/ 4710]
[2022-08-07 16:37:32,330] Train Error: Accuracy: 81.359%, Avg loss: 0.520149
[2022-08-07 16:37:44,069] Test  Error: Accuracy: 79.112%, Avg loss: 0.560611
[2022-08-07 16:37:44,070] Epoch 2---------------
[2022-08-07 16:37:44,071] lr: 1.900000e-03
[2022-08-07 16:37:45,074] loss: 0.660574  [    0/ 4710]
[2022-08-07 16:38:00,066] loss: 0.084052  [  960/ 4710]
[2022-08-07 16:38:15,056] loss: 0.065030  [ 1920/ 4710]
[2022-08-07 16:38:30,047] loss: 0.032485  [ 2880/ 4710]
[2022-08-07 16:38:45,036] loss: 0.035603  [ 3840/ 4710]
[2022-08-07 16:39:24,293] Train Error: Accuracy: 98.875%, Avg loss: 0.049412
[2022-08-07 16:39:36,029] Test  Error: Accuracy: 98.553%, Avg loss: 0.056993
[2022-08-07 16:39:36,030] Epoch 3---------------
[2022-08-07 16:39:36,030] lr: 1.805000e-03
[2022-08-07 16:39:37,031] loss: 0.046780  [    0/ 4710]
[2022-08-07 16:39:52,021] loss: 0.044365  [  960/ 4710]
[2022-08-07 16:40:07,010] loss: 0.021046  [ 1920/ 4710]
[2022-08-07 16:40:22,000] loss: 0.016450  [ 2880/ 4710]
[2022-08-07 16:40:36,991] loss: 0.041527  [ 3840/ 4710]
[2022-08-07 16:41:16,250] Train Error: Accuracy: 90.234%, Avg loss: 0.320938
[2022-08-07 16:41:27,990] Test  Error: Accuracy: 90.063%, Avg loss: 0.354508
[2022-08-07 16:41:27,990] Epoch 4---------------
[2022-08-07 16:41:27,990] lr: 1.260499e-03
[2022-08-07 16:41:28,991] loss: 0.356897  [    0/ 4710]
[2022-08-07 16:41:43,984] loss: 0.024576  [  960/ 4710]
[2022-08-07 16:41:58,975] loss: 0.027535  [ 1920/ 4710]
[2022-08-07 16:42:13,966] loss: 0.069478  [ 2880/ 4710]
[2022-08-07 16:42:28,957] loss: 0.016939  [ 3840/ 4710]
[2022-08-07 16:43:08,220] Train Error: Accuracy: 99.002%, Avg loss: 0.041372
[2022-08-07 16:43:19,959] Test  Error: Accuracy: 98.794%, Avg loss: 0.042443
[2022-08-07 16:43:19,960] Epoch 5---------------
[2022-08-07 16:43:19,960] lr: 1.197474e-03
[2022-08-07 16:43:20,961] loss: 0.022583  [    0/ 4710]
[2022-08-07 16:43:35,951] loss: 0.007126  [  960/ 4710]
[2022-08-07 16:43:50,941] loss: 0.007810  [ 1920/ 4710]
[2022-08-07 16:44:05,931] loss: 0.006759  [ 2880/ 4710]
[2022-08-07 16:44:20,921] loss: 0.020908  [ 3840/ 4710]
[2022-08-07 16:45:00,181] Train Error: Accuracy: 99.809%, Avg loss: 0.010110
[2022-08-07 16:45:11,920] Test  Error: Accuracy: 99.469%, Avg loss: 0.021633
[2022-08-07 16:45:11,920] Epoch 6---------------
[2022-08-07 16:45:11,920] lr: 1.137600e-03
[2022-08-07 16:45:12,921] loss: 0.010303  [    0/ 4710]
[2022-08-07 16:45:27,909] loss: 0.007308  [  960/ 4710]
[2022-08-07 16:45:42,898] loss: 0.043859  [ 1920/ 4710]
[2022-08-07 16:45:57,885] loss: 0.004954  [ 2880/ 4710]
[2022-08-07 16:46:12,874] loss: 0.006265  [ 3840/ 4710]
[2022-08-07 16:46:52,136] Train Error: Accuracy: 98.705%, Avg loss: 0.043143
[2022-08-07 16:47:03,874] Test  Error: Accuracy: 97.829%, Avg loss: 0.058385
[2022-08-07 16:47:03,874] Epoch 7---------------
[2022-08-07 16:47:03,875] lr: 7.944286e-04
[2022-08-07 16:47:04,875] loss: 0.038477  [    0/ 4710]
[2022-08-07 16:47:19,865] loss: 0.004041  [  960/ 4710]
[2022-08-07 16:47:34,853] loss: 0.009562  [ 1920/ 4710]
[2022-08-07 16:47:49,841] loss: 0.003478  [ 2880/ 4710]
[2022-08-07 16:48:04,830] loss: 0.001694  [ 3840/ 4710]
[2022-08-07 16:48:44,089] Train Error: Accuracy: 99.894%, Avg loss: 0.006961
[2022-08-07 16:48:55,825] Test  Error: Accuracy: 99.904%, Avg loss: 0.008163
[2022-08-07 16:48:55,826] Epoch 8---------------
[2022-08-07 16:48:55,826] lr: 7.547072e-04
[2022-08-07 16:48:56,828] loss: 0.012792  [    0/ 4710]
[2022-08-07 16:49:11,816] loss: 0.005968  [  960/ 4710]
[2022-08-07 16:49:26,805] loss: 0.001440  [ 1920/ 4710]
[2022-08-07 16:49:41,794] loss: 0.002669  [ 2880/ 4710]
[2022-08-07 16:49:56,783] loss: 0.004389  [ 3840/ 4710]
[2022-08-07 16:50:36,040] Train Error: Accuracy: 99.958%, Avg loss: 0.004201
[2022-08-07 16:50:47,772] Test  Error: Accuracy: 99.807%, Avg loss: 0.008777
[2022-08-07 16:50:47,773] Epoch 9---------------
[2022-08-07 16:50:47,774] lr: 6.470671e-04
[2022-08-07 16:50:48,775] loss: 0.003810  [    0/ 4710]
[2022-08-07 16:51:03,765] loss: 0.006447  [  960/ 4710]
[2022-08-07 16:51:18,754] loss: 0.003036  [ 1920/ 4710]
[2022-08-07 16:51:33,743] loss: 0.001415  [ 2880/ 4710]
[2022-08-07 16:51:48,731] loss: 0.003009  [ 3840/ 4710]
[2022-08-07 16:52:27,986] Train Error: Accuracy: 100.000%, Avg loss: 0.001818
[2022-08-07 16:52:39,720] Test  Error: Accuracy: 99.807%, Avg loss: 0.006594
[2022-08-07 16:52:39,720] Epoch 10---------------
[2022-08-07 16:52:39,721] lr: 6.147137e-04
[2022-08-07 16:52:40,723] loss: 0.002063  [    0/ 4710]
[2022-08-07 16:52:55,711] loss: 0.001449  [  960/ 4710]
[2022-08-07 16:53:10,701] loss: 0.001747  [ 1920/ 4710]
[2022-08-07 16:53:25,688] loss: 0.001015  [ 2880/ 4710]
[2022-08-07 16:53:40,676] loss: 0.002166  [ 3840/ 4710]
[2022-08-07 16:54:19,934] Train Error: Accuracy: 100.000%, Avg loss: 0.001873
[2022-08-07 16:54:31,670] Test  Error: Accuracy: 99.904%, Avg loss: 0.004879
[2022-08-07 16:54:31,670] Epoch 11---------------
[2022-08-07 16:54:31,671] lr: 5.839780e-04
[2022-08-07 16:54:32,674] loss: 0.001585  [    0/ 4710]
[2022-08-07 16:54:47,661] loss: 0.000754  [  960/ 4710]
[2022-08-07 16:55:02,651] loss: 0.001651  [ 1920/ 4710]
[2022-08-07 16:55:17,641] loss: 0.003421  [ 2880/ 4710]
[2022-08-07 16:55:32,631] loss: 0.002657  [ 3840/ 4710]
[2022-08-07 16:56:11,889] Train Error: Accuracy: 99.979%, Avg loss: 0.001783
[2022-08-07 16:56:23,625] Test  Error: Accuracy: 100.000%, Avg loss: 0.003691
[2022-08-07 16:56:23,625] Epoch 12---------------
[2022-08-07 16:56:23,626] lr: 5.547791e-04
[2022-08-07 16:56:24,628] loss: 0.001776  [    0/ 4710]
[2022-08-07 16:56:39,620] loss: 0.001049  [  960/ 4710]
[2022-08-07 16:56:54,609] loss: 0.001245  [ 1920/ 4710]
[2022-08-07 16:57:09,599] loss: 0.001216  [ 2880/ 4710]
[2022-08-07 16:57:24,590] loss: 0.000780  [ 3840/ 4710]
[2022-08-07 16:58:03,848] Train Error: Accuracy: 99.979%, Avg loss: 0.001469
[2022-08-07 16:58:15,588] Test  Error: Accuracy: 99.855%, Avg loss: 0.007536
[2022-08-07 16:58:15,589] Epoch 13---------------
[2022-08-07 16:58:15,590] lr: 3.874230e-04
[2022-08-07 16:58:16,591] loss: 0.001337  [    0/ 4710]
[2022-08-07 16:58:31,581] loss: 0.001317  [  960/ 4710]
[2022-08-07 16:58:46,572] loss: 0.000753  [ 1920/ 4710]
[2022-08-07 16:59:01,562] loss: 0.003062  [ 2880/ 4710]
[2022-08-07 16:59:16,552] loss: 0.001596  [ 3840/ 4710]
[2022-08-07 16:59:55,803] Train Error: Accuracy: 100.000%, Avg loss: 0.001337
[2022-08-07 17:00:07,542] Test  Error: Accuracy: 99.807%, Avg loss: 0.004808
[2022-08-07 17:00:07,542] Epoch 14---------------
[2022-08-07 17:00:07,543] lr: 3.680518e-04
[2022-08-07 17:00:08,545] loss: 0.001035  [    0/ 4710]
[2022-08-07 17:00:23,535] loss: 0.001240  [  960/ 4710]
[2022-08-07 17:00:38,525] loss: 0.000895  [ 1920/ 4710]
[2022-08-07 17:00:53,513] loss: 0.000707  [ 2880/ 4710]
[2022-08-07 17:01:08,501] loss: 0.000995  [ 3840/ 4710]
[2022-08-07 17:01:47,762] Train Error: Accuracy: 100.000%, Avg loss: 0.001364
[2022-08-07 17:01:59,501] Test  Error: Accuracy: 99.855%, Avg loss: 0.005103
[2022-08-07 17:01:59,501] Epoch 15---------------
[2022-08-07 17:01:59,505] lr: 3.155584e-04
[2022-08-07 17:02:00,507] loss: 0.001211  [    0/ 4710]
[2022-08-07 17:02:15,498] loss: 0.000880  [  960/ 4710]
[2022-08-07 17:02:30,487] loss: 0.000868  [ 1920/ 4710]
[2022-08-07 17:02:45,476] loss: 0.000760  [ 2880/ 4710]
[2022-08-07 17:03:00,465] loss: 0.000786  [ 3840/ 4710]
[2022-08-07 17:03:39,726] Train Error: Accuracy: 99.936%, Avg loss: 0.002801
[2022-08-07 17:03:51,461] Test  Error: Accuracy: 99.662%, Avg loss: 0.006863
[2022-08-07 17:03:51,462] Done!
[2022-08-07 17:03:51,465] Number of parameters:2146058
[2022-08-07 17:03:51,465] ## end time: 2022-08-07 17:03:51.462671
[2022-08-07 17:03:51,465] ## used time: 0:27:59.792577
