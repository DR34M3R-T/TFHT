[2022-08-06 19:08:01,780] ## start time: 2022-08-06 19:08:01.642325
[2022-08-06 19:08:01,781] Using cuda device
[2022-08-06 19:08:01,782] In train:p&d10.npy.
[2022-08-06 19:08:01,782] One Channel
[2022-08-06 19:08:01,783] With Normal data.
[2022-08-06 19:08:01,783] Nunber of classes:10.
[2022-08-06 19:08:01,784] Nunber of ViT channels:1.
[2022-08-06 19:08:02,045] Totol epochs: 15
[2022-08-06 19:08:02,047] Epoch 1---------------
[2022-08-06 19:08:02,048] lr: 2.000000e-03
[2022-08-06 19:08:03,133] loss: 2.515104  [    0/ 4704]
[2022-08-06 19:08:19,394] loss: 1.952829  [  960/ 4704]
[2022-08-06 19:08:35,655] loss: 1.788204  [ 1920/ 4704]
[2022-08-06 19:08:51,916] loss: 1.059865  [ 2880/ 4704]
[2022-08-06 19:09:08,177] loss: 0.628241  [ 3840/ 4704]
[2022-08-06 19:09:51,322] Train Error: Accuracy: 73.363%, Avg loss: 0.737285
[2022-08-06 19:10:04,394] Test  Error: Accuracy: 70.515%, Avg loss: 0.827430
[2022-08-06 19:10:04,395] Epoch 2---------------
[2022-08-06 19:10:04,396] lr: 1.900000e-03
[2022-08-06 19:10:05,481] loss: 0.601307  [    0/ 4704]
[2022-08-06 19:10:21,741] loss: 0.378998  [  960/ 4704]
[2022-08-06 19:10:38,001] loss: 0.487434  [ 1920/ 4704]
[2022-08-06 19:10:54,261] loss: 0.133104  [ 2880/ 4704]
[2022-08-06 19:11:10,522] loss: 0.141164  [ 3840/ 4704]
[2022-08-06 19:11:53,666] Train Error: Accuracy: 96.195%, Avg loss: 0.128882
[2022-08-06 19:12:06,737] Test  Error: Accuracy: 95.527%, Avg loss: 0.144216
[2022-08-06 19:12:06,738] Epoch 3---------------
[2022-08-06 19:12:06,739] lr: 1.805000e-03
[2022-08-06 19:12:07,825] loss: 0.255916  [    0/ 4704]
[2022-08-06 19:12:24,084] loss: 0.139195  [  960/ 4704]
[2022-08-06 19:12:40,344] loss: 0.069821  [ 1920/ 4704]
[2022-08-06 19:12:56,605] loss: 0.086174  [ 2880/ 4704]
[2022-08-06 19:13:12,865] loss: 0.051819  [ 3840/ 4704]
[2022-08-06 19:13:56,010] Train Error: Accuracy: 97.832%, Avg loss: 0.076283
[2022-08-06 19:14:09,085] Test  Error: Accuracy: 96.825%, Avg loss: 0.099545
[2022-08-06 19:14:09,085] Epoch 4---------------
[2022-08-06 19:14:09,087] lr: 1.714750e-03
[2022-08-06 19:14:10,173] loss: 0.071480  [    0/ 4704]
[2022-08-06 19:14:26,433] loss: 0.122271  [  960/ 4704]
[2022-08-06 19:14:47,810] loss: 0.016867  [ 1920/ 4704]
[2022-08-06 19:15:04,070] loss: 0.017484  [ 2880/ 4704]
[2022-08-06 19:15:20,333] loss: 0.056967  [ 3840/ 4704]
[2022-08-06 19:16:03,475] Train Error: Accuracy: 98.214%, Avg loss: 0.057165
[2022-08-06 19:16:16,551] Test  Error: Accuracy: 97.210%, Avg loss: 0.117405
[2022-08-06 19:16:16,552] Epoch 5---------------
[2022-08-06 19:16:16,552] lr: 1.326841e-03
[2022-08-06 19:16:17,638] loss: 0.038756  [    0/ 4704]
[2022-08-06 19:16:33,900] loss: 0.007495  [  960/ 4704]
[2022-08-06 19:16:50,162] loss: 0.013487  [ 1920/ 4704]
[2022-08-06 19:17:06,424] loss: 0.100078  [ 2880/ 4704]
[2022-08-06 19:17:22,715] loss: 0.019183  [ 3840/ 4704]
[2022-08-06 19:18:06,045] Train Error: Accuracy: 99.766%, Avg loss: 0.010730
[2022-08-06 19:18:19,172] Test  Error: Accuracy: 99.038%, Avg loss: 0.035604
[2022-08-06 19:18:19,173] Epoch 6---------------
[2022-08-06 19:18:19,175] lr: 1.260499e-03
[2022-08-06 19:18:20,266] loss: 0.021287  [    0/ 4704]
[2022-08-06 19:18:36,590] loss: 0.007865  [  960/ 4704]
[2022-08-06 19:18:52,916] loss: 0.012302  [ 1920/ 4704]
[2022-08-06 19:19:09,240] loss: 0.100059  [ 2880/ 4704]
[2022-08-06 19:19:25,567] loss: 0.007917  [ 3840/ 4704]
[2022-08-06 19:20:08,888] Train Error: Accuracy: 99.915%, Avg loss: 0.007935
[2022-08-06 19:20:22,014] Test  Error: Accuracy: 99.278%, Avg loss: 0.027062
[2022-08-06 19:20:22,014] Epoch 7---------------
[2022-08-06 19:20:22,015] lr: 1.197474e-03
[2022-08-06 19:20:23,105] loss: 0.006383  [    0/ 4704]
[2022-08-06 19:20:39,432] loss: 0.002767  [  960/ 4704]
[2022-08-06 19:20:55,757] loss: 0.002343  [ 1920/ 4704]
[2022-08-06 19:21:12,082] loss: 0.003828  [ 2880/ 4704]
[2022-08-06 19:21:28,407] loss: 0.003294  [ 3840/ 4704]
[2022-08-06 19:22:11,721] Train Error: Accuracy: 97.534%, Avg loss: 0.080490
[2022-08-06 19:22:24,844] Test  Error: Accuracy: 96.825%, Avg loss: 0.112217
[2022-08-06 19:22:24,845] Epoch 8---------------
[2022-08-06 19:22:24,846] lr: 8.362407e-04
[2022-08-06 19:22:25,936] loss: 0.178395  [    0/ 4704]
[2022-08-06 19:22:42,262] loss: 0.003139  [  960/ 4704]
[2022-08-06 19:22:58,587] loss: 0.002539  [ 1920/ 4704]
[2022-08-06 19:23:14,910] loss: 0.001771  [ 2880/ 4704]
[2022-08-06 19:23:31,232] loss: 0.001830  [ 3840/ 4704]
[2022-08-06 19:24:14,541] Train Error: Accuracy: 100.000%, Avg loss: 0.002209
[2022-08-06 19:24:27,665] Test  Error: Accuracy: 99.519%, Avg loss: 0.021292
[2022-08-06 19:24:27,666] Epoch 9---------------
[2022-08-06 19:24:27,666] lr: 7.944286e-04
[2022-08-06 19:24:28,757] loss: 0.001504  [    0/ 4704]
[2022-08-06 19:24:45,080] loss: 0.001796  [  960/ 4704]
[2022-08-06 19:25:01,404] loss: 0.001780  [ 1920/ 4704]
[2022-08-06 19:25:17,727] loss: 0.001016  [ 2880/ 4704]
[2022-08-06 19:25:34,049] loss: 0.002387  [ 3840/ 4704]
[2022-08-06 19:26:17,356] Train Error: Accuracy: 100.000%, Avg loss: 0.001473
[2022-08-06 19:26:30,480] Test  Error: Accuracy: 99.471%, Avg loss: 0.023663
[2022-08-06 19:26:30,481] Epoch 10---------------
[2022-08-06 19:26:30,481] lr: 6.147137e-04
[2022-08-06 19:26:31,572] loss: 0.007743  [    0/ 4704]
[2022-08-06 19:26:47,893] loss: 0.001187  [  960/ 4704]
[2022-08-06 19:27:04,214] loss: 0.002123  [ 1920/ 4704]
[2022-08-06 19:27:20,536] loss: 0.005517  [ 2880/ 4704]
[2022-08-06 19:27:36,859] loss: 0.000880  [ 3840/ 4704]
[2022-08-06 19:28:20,172] Train Error: Accuracy: 99.957%, Avg loss: 0.002233
[2022-08-06 19:28:33,300] Test  Error: Accuracy: 99.615%, Avg loss: 0.018033
[2022-08-06 19:28:33,300] Epoch 11---------------
[2022-08-06 19:28:33,301] lr: 5.839780e-04
[2022-08-06 19:28:34,391] loss: 0.002894  [    0/ 4704]
[2022-08-06 19:28:50,714] loss: 0.003435  [  960/ 4704]
[2022-08-06 19:43:13,428] loss: 0.001270  [ 1920/ 4704]
[2022-08-06 19:43:29,455] loss: 0.000926  [ 2880/ 4704]
[2022-08-06 19:43:45,537] loss: 0.001641  [ 3840/ 4704]
[2022-08-06 19:44:28,303] Train Error: Accuracy: 99.979%, Avg loss: 0.001804
[2022-08-06 19:44:41,281] Test  Error: Accuracy: 99.615%, Avg loss: 0.015551
[2022-08-06 19:44:41,281] Epoch 12---------------
[2022-08-06 19:44:41,282] lr: 5.547791e-04
[2022-08-06 19:44:42,361] loss: 0.000997  [    0/ 4704]
[2022-08-06 19:44:58,507] loss: 0.001391  [  960/ 4704]
[2022-08-06 19:45:14,652] loss: 0.000862  [ 1920/ 4704]
[2022-08-06 19:45:30,796] loss: 0.010448  [ 2880/ 4704]
[2022-08-06 19:45:46,941] loss: 0.000848  [ 3840/ 4704]
[2022-08-06 19:46:30,069] Train Error: Accuracy: 100.000%, Avg loss: 0.001296
[2022-08-06 19:46:43,140] Test  Error: Accuracy: 99.567%, Avg loss: 0.020481
[2022-08-06 19:46:43,141] Epoch 13---------------
[2022-08-06 19:46:43,141] lr: 3.874230e-04
[2022-08-06 19:46:44,228] loss: 0.000827  [    0/ 4704]
[2022-08-06 19:47:00,484] loss: 0.000757  [  960/ 4704]
[2022-08-06 19:47:16,741] loss: 0.000700  [ 1920/ 4704]
[2022-08-06 19:47:32,997] loss: 0.001170  [ 2880/ 4704]
[2022-08-06 19:47:49,254] loss: 0.000728  [ 3840/ 4704]
[2022-08-06 19:48:32,392] Train Error: Accuracy: 100.000%, Avg loss: 0.001257
[2022-08-06 19:48:45,462] Test  Error: Accuracy: 99.711%, Avg loss: 0.012569
[2022-08-06 19:48:45,463] Epoch 14---------------
[2022-08-06 19:48:45,463] lr: 3.680518e-04
[2022-08-06 19:48:46,550] loss: 0.001022  [    0/ 4704]
[2022-08-06 19:49:02,807] loss: 0.001143  [  960/ 4704]
[2022-08-06 19:49:19,063] loss: 0.000906  [ 1920/ 4704]
[2022-08-06 19:49:35,320] loss: 0.000914  [ 2880/ 4704]
[2022-08-06 19:49:51,576] loss: 0.001350  [ 3840/ 4704]
[2022-08-06 19:50:34,714] Train Error: Accuracy: 100.000%, Avg loss: 0.001036
[2022-08-06 19:50:47,784] Test  Error: Accuracy: 99.615%, Avg loss: 0.017236
[2022-08-06 19:50:47,784] Epoch 15---------------
[2022-08-06 19:50:47,785] lr: 2.570243e-04
[2022-08-06 19:50:48,872] loss: 0.000644  [    0/ 4704]
[2022-08-06 19:51:05,127] loss: 0.001143  [  960/ 4704]
[2022-08-06 19:51:21,383] loss: 0.000925  [ 1920/ 4704]
[2022-08-06 19:51:37,641] loss: 0.000980  [ 2880/ 4704]
[2022-08-06 19:51:53,897] loss: 0.000671  [ 3840/ 4704]
[2022-08-06 19:52:37,030] Train Error: Accuracy: 100.000%, Avg loss: 0.001338
[2022-08-06 19:52:50,099] Test  Error: Accuracy: 99.615%, Avg loss: 0.019576
[2022-08-06 19:52:50,100] Done!
[2022-08-06 19:52:50,104] Number of parameters:2412298
[2022-08-06 19:52:50,104] ## end time: 2022-08-06 19:52:50.100997
[2022-08-06 19:52:50,105] ## used time: 0:44:48.458672
