[2022-08-07 14:34:46,964] ## start time: 2022-08-07 14:34:46.619464
[2022-08-07 14:34:46,965] Using cuda device
[2022-08-07 14:34:46,965] In train:p&d10.npy.
[2022-08-07 14:34:46,966] One Channel
[2022-08-07 14:34:46,966] With Normal data.
[2022-08-07 14:34:46,966] Nunber of classes:10.
[2022-08-07 14:34:46,966] Nunber of ViT channels:1.
[2022-08-07 14:34:48,055] Totol epochs: 15
[2022-08-07 14:34:48,056] Epoch 1---------------
[2022-08-07 14:34:48,057] lr: 2.000000e-03
[2022-08-07 14:34:51,037] loss: 2.569688  [    0/ 4815]
[2022-08-07 14:34:54,781] loss: 1.678219  [  960/ 4815]
[2022-08-07 14:34:58,527] loss: 1.038375  [ 1920/ 4815]
[2022-08-07 14:35:02,275] loss: 0.567617  [ 2880/ 4815]
[2022-08-07 14:35:06,022] loss: 0.350505  [ 3840/ 4815]
[2022-08-07 14:35:09,580] loss: 0.450430  [ 4800/ 4815]
[2022-08-07 14:35:16,469] Train Error: Accuracy: 80.623%, Avg loss: 0.501986
[2022-08-07 14:35:19,282] Test  Error: Accuracy: 80.386%, Avg loss: 0.529084
[2022-08-07 14:35:19,282] Epoch 2---------------
[2022-08-07 14:35:19,283] lr: 1.900000e-03
[2022-08-07 14:35:19,532] loss: 0.404751  [    0/ 4815]
[2022-08-07 14:35:23,247] loss: 0.308252  [  960/ 4815]
[2022-08-07 14:35:26,966] loss: 0.117216  [ 1920/ 4815]
[2022-08-07 14:35:30,682] loss: 0.129173  [ 2880/ 4815]
[2022-08-07 14:35:34,397] loss: 0.262487  [ 3840/ 4815]
[2022-08-07 14:35:37,929] loss: 0.061627  [ 4800/ 4815]
[2022-08-07 14:35:44,866] Train Error: Accuracy: 96.303%, Avg loss: 0.118056
[2022-08-07 14:35:47,702] Test  Error: Accuracy: 95.681%, Avg loss: 0.137657
[2022-08-07 14:35:47,703] Epoch 3---------------
[2022-08-07 14:35:47,704] lr: 1.805000e-03
[2022-08-07 14:35:47,955] loss: 0.142159  [    0/ 4815]
[2022-08-07 14:35:51,699] loss: 0.040209  [  960/ 4815]
[2022-08-07 14:35:55,443] loss: 0.186987  [ 1920/ 4815]
[2022-08-07 14:35:59,186] loss: 0.035467  [ 2880/ 4815]
[2022-08-07 14:36:02,929] loss: 0.093118  [ 3840/ 4815]
[2022-08-07 14:36:06,486] loss: 0.012910  [ 4800/ 4815]
[2022-08-07 14:36:13,424] Train Error: Accuracy: 97.009%, Avg loss: 0.085535
[2022-08-07 14:36:16,263] Test  Error: Accuracy: 96.291%, Avg loss: 0.111904
[2022-08-07 14:36:16,263] Epoch 4---------------
[2022-08-07 14:36:16,264] lr: 1.714750e-03
[2022-08-07 14:36:16,516] loss: 0.135373  [    0/ 4815]
[2022-08-07 14:36:20,260] loss: 0.061524  [  960/ 4815]
[2022-08-07 14:36:24,003] loss: 0.133176  [ 1920/ 4815]
[2022-08-07 14:36:27,747] loss: 0.161324  [ 2880/ 4815]
[2022-08-07 14:36:31,489] loss: 0.057416  [ 3840/ 4815]
[2022-08-07 14:36:35,047] loss: 0.005380  [ 4800/ 4815]
[2022-08-07 14:36:42,012] Train Error: Accuracy: 98.609%, Avg loss: 0.045098
[2022-08-07 14:36:44,859] Test  Error: Accuracy: 97.256%, Avg loss: 0.082260
[2022-08-07 14:36:44,859] Epoch 5---------------
[2022-08-07 14:36:44,860] lr: 1.629012e-03
[2022-08-07 14:36:45,113] loss: 0.027869  [    0/ 4815]
[2022-08-07 14:36:48,871] loss: 0.016631  [  960/ 4815]
[2022-08-07 14:36:52,630] loss: 0.010261  [ 1920/ 4815]
[2022-08-07 14:36:56,390] loss: 0.432549  [ 2880/ 4815]
[2022-08-07 14:37:00,147] loss: 0.032992  [ 3840/ 4815]
[2022-08-07 14:37:03,718] loss: 0.054260  [ 4800/ 4815]
[2022-08-07 14:37:10,686] Train Error: Accuracy: 94.579%, Avg loss: 0.210725
[2022-08-07 14:37:13,533] Test  Error: Accuracy: 94.207%, Avg loss: 0.205464
[2022-08-07 14:37:13,534] Epoch 6---------------
[2022-08-07 14:37:13,535] lr: 1.137600e-03
[2022-08-07 14:37:13,787] loss: 0.368204  [    0/ 4815]
[2022-08-07 14:37:17,547] loss: 0.022275  [  960/ 4815]
[2022-08-07 14:37:21,305] loss: 0.028626  [ 1920/ 4815]
[2022-08-07 14:37:25,064] loss: 0.016062  [ 2880/ 4815]
[2022-08-07 14:37:28,822] loss: 0.055282  [ 3840/ 4815]
[2022-08-07 14:37:32,394] loss: 0.032726  [ 4800/ 4815]
[2022-08-07 14:37:39,363] Train Error: Accuracy: 99.543%, Avg loss: 0.020919
[2022-08-07 14:37:42,211] Test  Error: Accuracy: 98.526%, Avg loss: 0.042656
[2022-08-07 14:37:42,211] Epoch 7---------------
[2022-08-07 14:37:42,212] lr: 1.080720e-03
[2022-08-07 14:37:42,465] loss: 0.010669  [    0/ 4815]
[2022-08-07 14:37:46,224] loss: 0.022816  [  960/ 4815]
[2022-08-07 14:37:49,983] loss: 0.013443  [ 1920/ 4815]
[2022-08-07 14:37:53,741] loss: 0.009028  [ 2880/ 4815]
[2022-08-07 14:37:57,500] loss: 0.008320  [ 3840/ 4815]
[2022-08-07 14:38:01,071] loss: 0.061260  [ 4800/ 4815]
[2022-08-07 14:38:08,040] Train Error: Accuracy: 96.594%, Avg loss: 0.097521
[2022-08-07 14:38:10,888] Test  Error: Accuracy: 95.986%, Avg loss: 0.124405
[2022-08-07 14:38:10,888] Epoch 8---------------
[2022-08-07 14:38:10,889] lr: 7.547072e-04
[2022-08-07 14:38:11,142] loss: 0.053539  [    0/ 4815]
[2022-08-07 14:38:14,912] loss: 0.017272  [  960/ 4815]
[2022-08-07 14:38:18,696] loss: 0.006739  [ 1920/ 4815]
[2022-08-07 14:38:22,480] loss: 0.005025  [ 2880/ 4815]
[2022-08-07 14:38:26,265] loss: 0.011703  [ 3840/ 4815]
[2022-08-07 14:38:29,860] loss: 0.012260  [ 4800/ 4815]
[2022-08-07 14:38:36,873] Train Error: Accuracy: 99.709%, Avg loss: 0.012490
[2022-08-07 14:38:39,740] Test  Error: Accuracy: 99.085%, Avg loss: 0.027841
[2022-08-07 14:38:39,741] Epoch 9---------------
[2022-08-07 14:38:39,742] lr: 7.169718e-04
[2022-08-07 14:38:39,997] loss: 0.003421  [    0/ 4815]
[2022-08-07 14:38:43,780] loss: 0.008277  [  960/ 4815]
[2022-08-07 14:38:47,565] loss: 0.029113  [ 1920/ 4815]
[2022-08-07 14:38:51,349] loss: 0.034333  [ 2880/ 4815]
[2022-08-07 14:38:55,134] loss: 0.013668  [ 3840/ 4815]
[2022-08-07 14:38:58,729] loss: 0.007687  [ 4800/ 4815]
[2022-08-07 14:39:05,744] Train Error: Accuracy: 99.813%, Avg loss: 0.009848
[2022-08-07 14:39:08,610] Test  Error: Accuracy: 99.187%, Avg loss: 0.024117
[2022-08-07 14:39:08,611] Epoch 10---------------
[2022-08-07 14:39:08,611] lr: 6.811233e-04
[2022-08-07 14:39:08,866] loss: 0.004075  [    0/ 4815]
[2022-08-07 14:39:12,650] loss: 0.009876  [  960/ 4815]
[2022-08-07 14:39:16,434] loss: 0.003706  [ 1920/ 4815]
[2022-08-07 14:39:20,218] loss: 0.004927  [ 2880/ 4815]
[2022-08-07 14:39:24,002] loss: 0.026932  [ 3840/ 4815]
[2022-08-07 14:39:27,597] loss: 0.001628  [ 4800/ 4815]
[2022-08-07 14:39:34,614] Train Error: Accuracy: 99.813%, Avg loss: 0.009299
[2022-08-07 14:39:37,482] Test  Error: Accuracy: 99.136%, Avg loss: 0.030539
[2022-08-07 14:39:37,482] Epoch 11---------------
[2022-08-07 14:39:37,483] lr: 4.756538e-04
[2022-08-07 14:39:37,739] loss: 0.008021  [    0/ 4815]
[2022-08-07 14:39:41,522] loss: 0.028906  [  960/ 4815]
[2022-08-07 14:39:45,306] loss: 0.021682  [ 1920/ 4815]
[2022-08-07 14:39:49,091] loss: 0.005646  [ 2880/ 4815]
[2022-08-07 14:39:52,876] loss: 0.003491  [ 3840/ 4815]
[2022-08-07 14:39:56,473] loss: 0.000671  [ 4800/ 4815]
[2022-08-07 14:40:03,496] Train Error: Accuracy: 99.896%, Avg loss: 0.007027
[2022-08-07 14:40:06,363] Test  Error: Accuracy: 99.339%, Avg loss: 0.020805
[2022-08-07 14:40:06,363] Epoch 12---------------
[2022-08-07 14:40:06,364] lr: 4.518711e-04
[2022-08-07 14:40:06,619] loss: 0.002339  [    0/ 4815]
[2022-08-07 14:40:10,405] loss: 0.004194  [  960/ 4815]
[2022-08-07 14:40:14,189] loss: 0.004733  [ 1920/ 4815]
[2022-08-07 14:40:17,973] loss: 0.001692  [ 2880/ 4815]
[2022-08-07 14:40:21,758] loss: 0.010124  [ 3840/ 4815]
[2022-08-07 14:40:25,355] loss: 0.002295  [ 4800/ 4815]
[2022-08-07 14:40:32,371] Train Error: Accuracy: 99.896%, Avg loss: 0.005386
[2022-08-07 14:40:35,238] Test  Error: Accuracy: 99.136%, Avg loss: 0.023766
[2022-08-07 14:40:35,238] Epoch 13---------------
[2022-08-07 14:40:35,239] lr: 3.496492e-04
[2022-08-07 14:40:35,494] loss: 0.001604  [    0/ 4815]
[2022-08-07 14:40:39,279] loss: 0.005287  [  960/ 4815]
[2022-08-07 14:40:43,063] loss: 0.002473  [ 1920/ 4815]
[2022-08-07 14:40:46,847] loss: 0.003363  [ 2880/ 4815]
[2022-08-07 14:40:50,632] loss: 0.003703  [ 3840/ 4815]
[2022-08-07 14:40:54,227] loss: 0.003846  [ 4800/ 4815]
[2022-08-07 14:41:01,241] Train Error: Accuracy: 99.938%, Avg loss: 0.004360
[2022-08-07 14:41:04,109] Test  Error: Accuracy: 99.136%, Avg loss: 0.022249
[2022-08-07 14:41:04,109] Epoch 14---------------
[2022-08-07 14:41:04,110] lr: 3.321668e-04
[2022-08-07 14:41:04,365] loss: 0.003262  [    0/ 4815]
[2022-08-07 14:41:08,148] loss: 0.013749  [  960/ 4815]
[2022-08-07 14:41:11,933] loss: 0.003928  [ 1920/ 4815]
[2022-08-07 14:41:15,718] loss: 0.006757  [ 2880/ 4815]
[2022-08-07 14:41:19,502] loss: 0.001726  [ 3840/ 4815]
[2022-08-07 14:41:23,098] loss: 0.001085  [ 4800/ 4815]
[2022-08-07 14:41:30,110] Train Error: Accuracy: 99.958%, Avg loss: 0.004484
[2022-08-07 14:41:32,974] Test  Error: Accuracy: 99.035%, Avg loss: 0.024497
[2022-08-07 14:41:32,975] Epoch 15---------------
[2022-08-07 14:41:32,976] lr: 2.847915e-04
[2022-08-07 14:41:33,231] loss: 0.001764  [    0/ 4815]
[2022-08-07 14:41:37,015] loss: 0.003959  [  960/ 4815]
[2022-08-07 14:41:40,799] loss: 0.002607  [ 1920/ 4815]
[2022-08-07 14:41:44,583] loss: 0.000883  [ 2880/ 4815]
[2022-08-07 14:41:48,369] loss: 0.001756  [ 3840/ 4815]
[2022-08-07 14:41:51,964] loss: 0.000638  [ 4800/ 4815]
[2022-08-07 14:41:58,989] Train Error: Accuracy: 99.958%, Avg loss: 0.004223
[2022-08-07 14:42:01,855] Test  Error: Accuracy: 99.187%, Avg loss: 0.020728
[2022-08-07 14:42:01,855] Done!
[2022-08-07 14:42:01,857] Number of parameters:567050
[2022-08-07 14:42:01,858] ## end time: 2022-08-07 14:42:01.855487
[2022-08-07 14:42:01,858] ## used time: 0:07:15.236023
