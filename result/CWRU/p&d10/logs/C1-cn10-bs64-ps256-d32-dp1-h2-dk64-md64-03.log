[2022-08-06 15:10:31,830] ## start time: 2022-08-06 15:10:31.707709
[2022-08-06 15:10:31,830] Using cuda device
[2022-08-06 15:10:31,831] In train:p&d10.npy.
[2022-08-06 15:10:31,833] One Channel
[2022-08-06 15:10:31,833] With Normal data.
[2022-08-06 15:10:31,834] Nunber of classes:10.
[2022-08-06 15:10:31,834] Nunber of ViT channels:1.
[2022-08-06 15:10:32,024] Totol epochs: 10
[2022-08-06 15:10:32,025] Epoch 1---------------
[2022-08-06 15:10:32,026] lr: 2.000000e-03
[2022-08-06 15:10:32,042] loss: 2.484107  [    0/ 4755]
[2022-08-06 15:10:32,225] loss: 1.899739  [  960/ 4755]
[2022-08-06 15:10:32,398] loss: 1.693409  [ 1920/ 4755]
[2022-08-06 15:10:32,560] loss: 1.051407  [ 2880/ 4755]
[2022-08-06 15:10:32,720] loss: 0.659500  [ 3840/ 4755]
[2022-08-06 15:10:33,169] Train Error: Accuracy: 58.633%, Avg loss: 1.212712
[2022-08-06 15:10:33,301] Test  Error: Accuracy: 59.320%, Avg loss: 1.212873
[2022-08-06 15:10:33,301] Epoch 2---------------
[2022-08-06 15:10:33,302] lr: 1.900000e-03
[2022-08-06 15:10:33,314] loss: 1.298224  [    0/ 4755]
[2022-08-06 15:10:33,479] loss: 0.470374  [  960/ 4755]
[2022-08-06 15:10:33,640] loss: 0.237928  [ 1920/ 4755]
[2022-08-06 15:10:33,793] loss: 0.222806  [ 2880/ 4755]
[2022-08-06 15:10:33,945] loss: 0.153943  [ 3840/ 4755]
[2022-08-06 15:10:34,352] Train Error: Accuracy: 98.086%, Avg loss: 0.115163
[2022-08-06 15:10:34,468] Test  Error: Accuracy: 97.239%, Avg loss: 0.137215
[2022-08-06 15:10:34,468] Epoch 3---------------
[2022-08-06 15:10:34,469] lr: 1.805000e-03
[2022-08-06 15:10:34,481] loss: 0.097998  [    0/ 4755]
[2022-08-06 15:10:34,639] loss: 0.061022  [  960/ 4755]
[2022-08-06 15:10:34,789] loss: 0.074321  [ 1920/ 4755]
[2022-08-06 15:10:34,944] loss: 0.093559  [ 2880/ 4755]
[2022-08-06 15:10:35,094] loss: 0.169519  [ 3840/ 4755]
[2022-08-06 15:10:35,503] Train Error: Accuracy: 98.170%, Avg loss: 0.084541
[2022-08-06 15:10:35,618] Test  Error: Accuracy: 97.288%, Avg loss: 0.114245
[2022-08-06 15:10:35,619] Epoch 4---------------
[2022-08-06 15:10:35,620] lr: 1.714750e-03
[2022-08-06 15:10:35,632] loss: 0.074227  [    0/ 4755]
[2022-08-06 15:10:35,786] loss: 0.048438  [  960/ 4755]
[2022-08-06 15:10:35,939] loss: 0.023862  [ 1920/ 4755]
[2022-08-06 15:10:36,090] loss: 0.041224  [ 2880/ 4755]
[2022-08-06 15:10:36,240] loss: 0.044525  [ 3840/ 4755]
[2022-08-06 15:10:36,647] Train Error: Accuracy: 99.222%, Avg loss: 0.041476
[2022-08-06 15:10:36,764] Test  Error: Accuracy: 98.323%, Avg loss: 0.068267
[2022-08-06 15:10:36,764] Epoch 5---------------
[2022-08-06 15:10:36,765] lr: 1.629012e-03
[2022-08-06 15:10:36,777] loss: 0.028792  [    0/ 4755]
[2022-08-06 15:10:36,932] loss: 0.017699  [  960/ 4755]
[2022-08-06 15:10:37,083] loss: 0.026667  [ 1920/ 4755]
[2022-08-06 15:10:37,235] loss: 0.014083  [ 2880/ 4755]
[2022-08-06 15:10:37,386] loss: 0.029821  [ 3840/ 4755]
[2022-08-06 15:10:37,795] Train Error: Accuracy: 99.790%, Avg loss: 0.016329
[2022-08-06 15:10:37,910] Test  Error: Accuracy: 99.310%, Avg loss: 0.033911
[2022-08-06 15:10:37,910] Epoch 6---------------
[2022-08-06 15:10:37,912] lr: 1.547562e-03
[2022-08-06 15:10:37,924] loss: 0.044416  [    0/ 4755]
[2022-08-06 15:10:38,077] loss: 0.009406  [  960/ 4755]
[2022-08-06 15:10:38,229] loss: 0.049691  [ 1920/ 4755]
[2022-08-06 15:10:38,383] loss: 0.016119  [ 2880/ 4755]
[2022-08-06 15:10:38,534] loss: 0.051605  [ 3840/ 4755]
[2022-08-06 15:10:38,960] Train Error: Accuracy: 99.832%, Avg loss: 0.013052
[2022-08-06 15:10:39,081] Test  Error: Accuracy: 99.260%, Avg loss: 0.033625
[2022-08-06 15:10:39,081] Epoch 7---------------
[2022-08-06 15:10:39,082] lr: 1.470184e-03
[2022-08-06 15:10:39,095] loss: 0.027103  [    0/ 4755]
[2022-08-06 15:10:39,258] loss: 0.032066  [  960/ 4755]
[2022-08-06 15:10:39,413] loss: 0.021910  [ 1920/ 4755]
[2022-08-06 15:10:39,568] loss: 0.017678  [ 2880/ 4755]
[2022-08-06 15:10:39,721] loss: 0.009346  [ 3840/ 4755]
[2022-08-06 15:10:40,135] Train Error: Accuracy: 99.832%, Avg loss: 0.013082
[2022-08-06 15:10:40,251] Test  Error: Accuracy: 99.458%, Avg loss: 0.024644
[2022-08-06 15:10:40,251] Epoch 8---------------
[2022-08-06 15:10:40,252] lr: 1.396675e-03
[2022-08-06 15:10:40,265] loss: 0.024124  [    0/ 4755]
[2022-08-06 15:10:40,414] loss: 0.023060  [  960/ 4755]
[2022-08-06 15:10:40,565] loss: 0.015053  [ 1920/ 4755]
[2022-08-06 15:10:40,717] loss: 0.019593  [ 2880/ 4755]
[2022-08-06 15:10:40,868] loss: 0.013402  [ 3840/ 4755]
[2022-08-06 15:10:41,279] Train Error: Accuracy: 99.811%, Avg loss: 0.011738
[2022-08-06 15:10:41,395] Test  Error: Accuracy: 99.408%, Avg loss: 0.024501
[2022-08-06 15:10:41,395] Epoch 9---------------
[2022-08-06 15:10:41,396] lr: 1.326841e-03
[2022-08-06 15:10:41,408] loss: 0.008595  [    0/ 4755]
[2022-08-06 15:10:41,559] loss: 0.005913  [  960/ 4755]
[2022-08-06 15:10:41,712] loss: 0.002866  [ 1920/ 4755]
[2022-08-06 15:10:41,865] loss: 0.002708  [ 2880/ 4755]
[2022-08-06 15:10:42,018] loss: 0.003105  [ 3840/ 4755]
[2022-08-06 15:10:42,431] Train Error: Accuracy: 99.979%, Avg loss: 0.006148
[2022-08-06 15:10:42,548] Test  Error: Accuracy: 99.507%, Avg loss: 0.018907
[2022-08-06 15:10:42,548] Epoch 10---------------
[2022-08-06 15:10:42,549] lr: 1.260499e-03
[2022-08-06 15:10:42,561] loss: 0.004880  [    0/ 4755]
[2022-08-06 15:10:42,714] loss: 0.003918  [  960/ 4755]
[2022-08-06 15:10:42,863] loss: 0.004285  [ 1920/ 4755]
[2022-08-06 15:10:43,017] loss: 0.005605  [ 2880/ 4755]
[2022-08-06 15:10:43,169] loss: 0.006540  [ 3840/ 4755]
[2022-08-06 15:10:43,581] Train Error: Accuracy: 99.958%, Avg loss: 0.006292
[2022-08-06 15:10:43,698] Test  Error: Accuracy: 99.458%, Avg loss: 0.018511
[2022-08-06 15:10:43,698] Done!
[2022-08-06 15:10:43,700] Number of parameters:59338
[2022-08-06 15:10:43,701] ## end time: 2022-08-06 15:10:43.698919
[2022-08-06 15:10:43,701] ## used time: 0:00:11.991210
