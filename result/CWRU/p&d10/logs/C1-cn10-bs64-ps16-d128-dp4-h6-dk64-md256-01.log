[2022-08-07 15:38:56,195] ## start time: 2022-08-07 15:38:56.054067
[2022-08-07 15:38:56,196] Using cuda device
[2022-08-07 15:38:56,197] In train:p&d10.npy.
[2022-08-07 15:38:56,198] One Channel
[2022-08-07 15:38:56,198] With Normal data.
[2022-08-07 15:38:56,199] Nunber of classes:10.
[2022-08-07 15:38:56,199] Nunber of ViT channels:1.
[2022-08-07 15:38:56,442] Totol epochs: 15
[2022-08-07 15:38:56,445] Epoch 1---------------
[2022-08-07 15:38:56,445] lr: 2.000000e-03
[2022-08-07 15:38:57,446] loss: 2.390104  [    0/ 4748]
[2022-08-07 15:39:12,436] loss: 2.349664  [  960/ 4748]
[2022-08-07 15:39:27,423] loss: 1.400775  [ 1920/ 4748]
[2022-08-07 15:39:42,411] loss: 1.699358  [ 2880/ 4748]
[2022-08-07 15:39:57,400] loss: 0.257531  [ 3840/ 4748]
[2022-08-07 15:40:37,460] Train Error: Accuracy: 89.090%, Avg loss: 0.336905
[2022-08-07 15:40:48,969] Test  Error: Accuracy: 88.452%, Avg loss: 0.361022
[2022-08-07 15:40:48,970] Epoch 2---------------
[2022-08-07 15:40:48,971] lr: 1.900000e-03
[2022-08-07 15:40:49,973] loss: 0.239177  [    0/ 4748]
[2022-08-07 15:41:04,963] loss: 0.189264  [  960/ 4748]
[2022-08-07 15:41:19,954] loss: 0.068845  [ 1920/ 4748]
[2022-08-07 15:41:34,945] loss: 0.150040  [ 2880/ 4748]
[2022-08-07 15:41:49,935] loss: 0.027448  [ 3840/ 4748]
[2022-08-07 15:42:29,997] Train Error: Accuracy: 99.495%, Avg loss: 0.027242
[2022-08-07 15:42:41,506] Test  Error: Accuracy: 99.312%, Avg loss: 0.031147
[2022-08-07 15:42:41,507] Epoch 3---------------
[2022-08-07 15:42:41,508] lr: 1.805000e-03
[2022-08-07 15:42:42,509] loss: 0.036102  [    0/ 4748]
[2022-08-07 15:42:57,498] loss: 0.015172  [  960/ 4748]
[2022-08-07 15:43:12,488] loss: 0.007143  [ 1920/ 4748]
[2022-08-07 15:43:27,477] loss: 0.058067  [ 2880/ 4748]
[2022-08-07 15:43:42,466] loss: 0.040619  [ 3840/ 4748]
[2022-08-07 15:44:22,534] Train Error: Accuracy: 99.747%, Avg loss: 0.019451
[2022-08-07 15:44:34,046] Test  Error: Accuracy: 99.312%, Avg loss: 0.027165
[2022-08-07 15:44:34,046] Epoch 4---------------
[2022-08-07 15:44:34,047] lr: 1.714750e-03
[2022-08-07 15:44:35,049] loss: 0.012244  [    0/ 4748]
[2022-08-07 15:44:50,037] loss: 0.053503  [  960/ 4748]
[2022-08-07 15:45:05,025] loss: 0.028099  [ 1920/ 4748]
[2022-08-07 15:45:20,014] loss: 0.019236  [ 2880/ 4748]
[2022-08-07 15:45:35,001] loss: 0.076027  [ 3840/ 4748]
[2022-08-07 15:46:15,063] Train Error: Accuracy: 94.819%, Avg loss: 0.252876
[2022-08-07 15:46:26,575] Test  Error: Accuracy: 94.595%, Avg loss: 0.272551
[2022-08-07 15:46:26,575] Epoch 5---------------
[2022-08-07 15:46:26,576] lr: 1.197474e-03
[2022-08-07 15:46:27,577] loss: 0.429074  [    0/ 4748]
[2022-08-07 15:46:42,567] loss: 0.014754  [  960/ 4748]
[2022-08-07 15:46:57,555] loss: 0.006090  [ 1920/ 4748]
[2022-08-07 15:47:12,543] loss: 0.008410  [ 2880/ 4748]
[2022-08-07 15:47:27,533] loss: 0.039094  [ 3840/ 4748]
[2022-08-07 15:48:07,595] Train Error: Accuracy: 99.853%, Avg loss: 0.010248
[2022-08-07 15:48:19,108] Test  Error: Accuracy: 99.607%, Avg loss: 0.014826
[2022-08-07 15:48:19,109] Epoch 6---------------
[2022-08-07 15:48:19,110] lr: 1.137600e-03
[2022-08-07 15:48:20,111] loss: 0.018934  [    0/ 4748]
[2022-08-07 15:48:35,101] loss: 0.002344  [  960/ 4748]
[2022-08-07 15:48:50,090] loss: 0.002625  [ 1920/ 4748]
[2022-08-07 15:49:05,079] loss: 0.006829  [ 2880/ 4748]
[2022-08-07 15:49:20,069] loss: 0.001434  [ 3840/ 4748]
[2022-08-07 15:50:00,140] Train Error: Accuracy: 99.684%, Avg loss: 0.010165
[2022-08-07 15:50:11,650] Test  Error: Accuracy: 99.754%, Avg loss: 0.012775
[2022-08-07 15:50:11,651] Epoch 7---------------
[2022-08-07 15:50:11,651] lr: 1.080720e-03
[2022-08-07 15:50:12,651] loss: 0.003025  [    0/ 4748]
[2022-08-07 15:50:27,640] loss: 0.035898  [  960/ 4748]
[2022-08-07 15:50:42,629] loss: 0.002990  [ 1920/ 4748]
[2022-08-07 15:50:57,619] loss: 0.003245  [ 2880/ 4748]
[2022-08-07 15:51:12,607] loss: 0.003049  [ 3840/ 4748]
[2022-08-07 15:51:52,671] Train Error: Accuracy: 99.789%, Avg loss: 0.008706
[2022-08-07 15:52:04,182] Test  Error: Accuracy: 99.656%, Avg loss: 0.009646
[2022-08-07 15:52:04,182] Epoch 8---------------
[2022-08-07 15:52:04,183] lr: 1.026684e-03
[2022-08-07 15:52:05,183] loss: 0.004242  [    0/ 4748]
[2022-08-07 15:52:20,172] loss: 0.002432  [  960/ 4748]
[2022-08-07 15:52:35,160] loss: 0.002701  [ 1920/ 4748]
[2022-08-07 15:53:12,858] loss: 0.001790  [ 2880/ 4748]
[2022-08-07 15:53:27,739] loss: 0.079787  [ 3840/ 4748]
[2022-08-07 15:54:07,513] Train Error: Accuracy: 99.916%, Avg loss: 0.005321
[2022-08-07 15:54:18,942] Test  Error: Accuracy: 99.754%, Avg loss: 0.008661
[2022-08-07 15:54:18,942] Epoch 9---------------
[2022-08-07 15:54:18,943] lr: 9.753500e-04
[2022-08-07 15:54:19,937] loss: 0.002458  [    0/ 4748]
[2022-08-07 15:54:34,818] loss: 0.001196  [  960/ 4748]
[2022-08-07 15:54:49,699] loss: 0.001611  [ 1920/ 4748]
[2022-08-07 15:55:04,580] loss: 0.001039  [ 2880/ 4748]
[2022-08-07 15:55:19,460] loss: 0.001273  [ 3840/ 4748]
[2022-08-07 15:55:59,485] Train Error: Accuracy: 99.979%, Avg loss: 0.002136
[2022-08-07 15:56:11,000] Test  Error: Accuracy: 99.951%, Avg loss: 0.003306
[2022-08-07 15:56:11,000] Epoch 10---------------
[2022-08-07 15:56:11,001] lr: 9.265825e-04
[2022-08-07 15:56:12,003] loss: 0.001036  [    0/ 4748]
[2022-08-07 15:56:26,994] loss: 0.001540  [  960/ 4748]
[2022-08-07 15:56:41,982] loss: 0.000866  [ 1920/ 4748]
[2022-08-07 15:56:56,972] loss: 0.002298  [ 2880/ 4748]
[2022-08-07 15:57:11,962] loss: 0.005731  [ 3840/ 4748]
[2022-08-07 15:57:52,024] Train Error: Accuracy: 100.000%, Avg loss: 0.001292
[2022-08-07 15:58:03,533] Test  Error: Accuracy: 99.951%, Avg loss: 0.004520
[2022-08-07 15:58:03,534] Epoch 11---------------
[2022-08-07 15:58:03,534] lr: 6.470671e-04
[2022-08-07 15:58:04,536] loss: 0.000765  [    0/ 4748]
[2022-08-07 15:58:19,526] loss: 0.000700  [  960/ 4748]
[2022-08-07 15:58:34,513] loss: 0.000668  [ 1920/ 4748]
[2022-08-07 15:58:49,502] loss: 0.000828  [ 2880/ 4748]
[2022-08-07 15:59:04,490] loss: 0.001720  [ 3840/ 4748]
[2022-08-07 15:59:44,542] Train Error: Accuracy: 99.895%, Avg loss: 0.003842
[2022-08-07 15:59:56,049] Test  Error: Accuracy: 99.853%, Avg loss: 0.006816
[2022-08-07 15:59:56,050] Epoch 12---------------
[2022-08-07 15:59:56,051] lr: 4.518711e-04
[2022-08-07 15:59:57,052] loss: 0.001158  [    0/ 4748]
[2022-08-07 16:00:12,040] loss: 0.006804  [  960/ 4748]
[2022-08-07 16:00:27,027] loss: 0.000713  [ 1920/ 4748]
[2022-08-07 16:00:42,016] loss: 0.000687  [ 2880/ 4748]
[2022-08-07 16:00:57,003] loss: 0.000527  [ 3840/ 4748]
[2022-08-07 16:01:37,059] Train Error: Accuracy: 99.979%, Avg loss: 0.001351
[2022-08-07 16:01:48,569] Test  Error: Accuracy: 99.951%, Avg loss: 0.003957
[2022-08-07 16:01:48,569] Epoch 13---------------
[2022-08-07 16:01:48,570] lr: 4.292775e-04
[2022-08-07 16:01:49,571] loss: 0.000828  [    0/ 4748]
[2022-08-07 16:02:04,560] loss: 0.001604  [  960/ 4748]
[2022-08-07 16:02:19,550] loss: 0.000585  [ 1920/ 4748]
[2022-08-07 16:02:34,539] loss: 0.000730  [ 2880/ 4748]
[2022-08-07 16:02:49,527] loss: 0.000687  [ 3840/ 4748]
[2022-08-07 16:03:29,584] Train Error: Accuracy: 100.000%, Avg loss: 0.000953
[2022-08-07 16:03:41,093] Test  Error: Accuracy: 99.902%, Avg loss: 0.004062
[2022-08-07 16:03:41,094] Epoch 14---------------
[2022-08-07 16:03:41,095] lr: 3.680518e-04
[2022-08-07 16:03:42,095] loss: 0.000834  [    0/ 4748]
[2022-08-07 16:03:57,085] loss: 0.000544  [  960/ 4748]
[2022-08-07 16:04:12,075] loss: 0.000692  [ 1920/ 4748]
[2022-08-07 16:04:27,064] loss: 0.000555  [ 2880/ 4748]
[2022-08-07 16:04:42,054] loss: 0.000843  [ 3840/ 4748]
[2022-08-07 16:05:22,113] Train Error: Accuracy: 100.000%, Avg loss: 0.000738
[2022-08-07 16:05:33,622] Test  Error: Accuracy: 99.951%, Avg loss: 0.003116
[2022-08-07 16:05:33,623] Epoch 15---------------
[2022-08-07 16:05:33,624] lr: 3.496492e-04
[2022-08-07 16:05:34,625] loss: 0.000705  [    0/ 4748]
[2022-08-07 16:05:49,614] loss: 0.000479  [  960/ 4748]
[2022-08-07 16:06:04,602] loss: 0.000789  [ 1920/ 4748]
[2022-08-07 16:06:19,591] loss: 0.000803  [ 2880/ 4748]
[2022-08-07 16:06:34,580] loss: 0.000955  [ 3840/ 4748]
[2022-08-07 16:07:14,644] Train Error: Accuracy: 100.000%, Avg loss: 0.000758
[2022-08-07 16:07:26,150] Test  Error: Accuracy: 99.951%, Avg loss: 0.003663
[2022-08-07 16:07:26,151] Done!
[2022-08-07 16:07:26,154] Number of parameters:2146058
[2022-08-07 16:07:26,154] ## end time: 2022-08-07 16:07:26.151774
[2022-08-07 16:07:26,154] ## used time: 0:28:30.097707
