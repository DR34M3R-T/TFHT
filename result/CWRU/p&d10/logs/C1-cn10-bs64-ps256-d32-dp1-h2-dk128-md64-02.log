[2022-08-06 15:22:35,701] ## start time: 2022-08-06 15:22:35.576984
[2022-08-06 15:22:35,702] Using cuda device
[2022-08-06 15:22:35,703] In train:p&d10.npy.
[2022-08-06 15:22:35,704] One Channel
[2022-08-06 15:22:35,705] With Normal data.
[2022-08-06 15:22:35,705] Nunber of classes:10.
[2022-08-06 15:22:35,705] Nunber of ViT channels:1.
[2022-08-06 15:22:35,892] Totol epochs: 10
[2022-08-06 15:22:35,893] Epoch 1---------------
[2022-08-06 15:22:35,895] lr: 2.000000e-03
[2022-08-06 15:22:35,907] loss: 2.470198  [    0/ 4748]
[2022-08-06 15:22:36,064] loss: 1.859100  [  960/ 4748]
[2022-08-06 15:22:36,224] loss: 1.189031  [ 1920/ 4748]
[2022-08-06 15:22:36,377] loss: 0.759646  [ 2880/ 4748]
[2022-08-06 15:22:36,526] loss: 0.986574  [ 3840/ 4748]
[2022-08-06 15:22:36,949] Train Error: Accuracy: 85.341%, Avg loss: 0.495809
[2022-08-06 15:22:37,067] Test  Error: Accuracy: 85.111%, Avg loss: 0.503157
[2022-08-06 15:22:37,068] Epoch 2---------------
[2022-08-06 15:22:37,070] lr: 1.900000e-03
[2022-08-06 15:22:37,081] loss: 0.346248  [    0/ 4748]
[2022-08-06 15:22:37,231] loss: 0.209176  [  960/ 4748]
[2022-08-06 15:22:37,383] loss: 0.165997  [ 1920/ 4748]
[2022-08-06 15:22:37,535] loss: 0.113943  [ 2880/ 4748]
[2022-08-06 15:22:37,683] loss: 0.219898  [ 3840/ 4748]
[2022-08-06 15:22:38,101] Train Error: Accuracy: 95.409%, Avg loss: 0.171709
[2022-08-06 15:22:38,220] Test  Error: Accuracy: 94.644%, Avg loss: 0.198169
[2022-08-06 15:22:38,220] Epoch 3---------------
[2022-08-06 15:22:38,222] lr: 1.805000e-03
[2022-08-06 15:22:38,233] loss: 0.092851  [    0/ 4748]
[2022-08-06 15:22:38,382] loss: 0.102024  [  960/ 4748]
[2022-08-06 15:22:38,533] loss: 0.081092  [ 1920/ 4748]
[2022-08-06 15:22:38,683] loss: 0.095860  [ 2880/ 4748]
[2022-08-06 15:22:38,832] loss: 0.093459  [ 3840/ 4748]
[2022-08-06 15:22:39,248] Train Error: Accuracy: 99.347%, Avg loss: 0.047139
[2022-08-06 15:22:39,366] Test  Error: Accuracy: 98.526%, Avg loss: 0.072618
[2022-08-06 15:22:39,366] Epoch 4---------------
[2022-08-06 15:22:39,367] lr: 1.714750e-03
[2022-08-06 15:22:39,379] loss: 0.060351  [    0/ 4748]
[2022-08-06 15:22:39,530] loss: 0.094954  [  960/ 4748]
[2022-08-06 15:22:39,679] loss: 0.073795  [ 1920/ 4748]
[2022-08-06 15:22:39,830] loss: 0.024918  [ 2880/ 4748]
[2022-08-06 15:22:39,981] loss: 0.049172  [ 3840/ 4748]
[2022-08-06 15:22:40,398] Train Error: Accuracy: 99.473%, Avg loss: 0.033056
[2022-08-06 15:22:40,518] Test  Error: Accuracy: 99.066%, Avg loss: 0.043406
[2022-08-06 15:22:40,518] Epoch 5---------------
[2022-08-06 15:22:40,519] lr: 1.629012e-03
[2022-08-06 15:22:40,531] loss: 0.028548  [    0/ 4748]
[2022-08-06 15:22:40,685] loss: 0.027288  [  960/ 4748]
[2022-08-06 15:22:40,837] loss: 0.043877  [ 1920/ 4748]
[2022-08-06 15:22:40,986] loss: 0.028509  [ 2880/ 4748]
[2022-08-06 15:22:41,136] loss: 0.019410  [ 3840/ 4748]
[2022-08-06 15:22:41,552] Train Error: Accuracy: 99.263%, Avg loss: 0.040301
[2022-08-06 15:22:41,670] Test  Error: Accuracy: 98.477%, Avg loss: 0.060814
[2022-08-06 15:22:41,670] Epoch 6---------------
[2022-08-06 15:22:41,671] lr: 1.137600e-03
[2022-08-06 15:22:41,684] loss: 0.053854  [    0/ 4748]
[2022-08-06 15:22:41,838] loss: 0.023571  [  960/ 4748]
[2022-08-06 15:22:41,989] loss: 0.016634  [ 1920/ 4748]
[2022-08-06 15:22:42,139] loss: 0.009242  [ 2880/ 4748]
[2022-08-06 15:22:42,293] loss: 0.009745  [ 3840/ 4748]
[2022-08-06 15:22:42,706] Train Error: Accuracy: 99.726%, Avg loss: 0.016178
[2022-08-06 15:22:42,832] Test  Error: Accuracy: 99.312%, Avg loss: 0.029233
[2022-08-06 15:22:42,832] Epoch 7---------------
[2022-08-06 15:22:42,833] lr: 1.080720e-03
[2022-08-06 15:22:42,846] loss: 0.021708  [    0/ 4748]
[2022-08-06 15:22:42,996] loss: 0.015166  [  960/ 4748]
[2022-08-06 15:22:43,146] loss: 0.014481  [ 1920/ 4748]
[2022-08-06 15:22:43,298] loss: 0.008215  [ 2880/ 4748]
[2022-08-06 15:22:43,449] loss: 0.010747  [ 3840/ 4748]
[2022-08-06 15:22:43,867] Train Error: Accuracy: 99.874%, Avg loss: 0.010685
[2022-08-06 15:22:43,990] Test  Error: Accuracy: 99.410%, Avg loss: 0.022089
[2022-08-06 15:22:43,991] Epoch 8---------------
[2022-08-06 15:22:43,992] lr: 1.026684e-03
[2022-08-06 15:22:44,004] loss: 0.007982  [    0/ 4748]
[2022-08-06 15:22:44,153] loss: 0.012794  [  960/ 4748]
[2022-08-06 15:22:44,302] loss: 0.078084  [ 1920/ 4748]
[2022-08-06 15:22:44,455] loss: 0.003329  [ 2880/ 4748]
[2022-08-06 15:22:44,605] loss: 0.004604  [ 3840/ 4748]
[2022-08-06 15:22:45,020] Train Error: Accuracy: 99.916%, Avg loss: 0.009153
[2022-08-06 15:22:45,142] Test  Error: Accuracy: 99.361%, Avg loss: 0.025620
[2022-08-06 15:22:45,142] Epoch 9---------------
[2022-08-06 15:22:45,143] lr: 7.944286e-04
[2022-08-06 15:22:45,154] loss: 0.010724  [    0/ 4748]
[2022-08-06 15:22:45,305] loss: 0.008953  [  960/ 4748]
[2022-08-06 15:22:45,455] loss: 0.003747  [ 1920/ 4748]
[2022-08-06 15:22:45,608] loss: 0.011944  [ 2880/ 4748]
[2022-08-06 15:22:45,758] loss: 0.004080  [ 3840/ 4748]
[2022-08-06 15:22:46,175] Train Error: Accuracy: 99.895%, Avg loss: 0.010471
[2022-08-06 15:22:46,294] Test  Error: Accuracy: 99.509%, Avg loss: 0.019920
[2022-08-06 15:22:46,294] Epoch 10---------------
[2022-08-06 15:22:46,295] lr: 7.547072e-04
[2022-08-06 15:22:46,307] loss: 0.005621  [    0/ 4748]
[2022-08-06 15:22:46,459] loss: 0.005796  [  960/ 4748]
[2022-08-06 15:22:46,612] loss: 0.005436  [ 1920/ 4748]
[2022-08-06 15:22:46,761] loss: 0.007605  [ 2880/ 4748]
[2022-08-06 15:22:46,913] loss: 0.049988  [ 3840/ 4748]
[2022-08-06 15:22:47,329] Train Error: Accuracy: 99.747%, Avg loss: 0.012461
[2022-08-06 15:22:47,447] Test  Error: Accuracy: 99.656%, Avg loss: 0.021183
[2022-08-06 15:22:47,448] Done!
[2022-08-06 15:22:47,449] Number of parameters:92106
[2022-08-06 15:22:47,450] ## end time: 2022-08-06 15:22:47.448824
[2022-08-06 15:22:47,450] ## used time: 0:00:11.871840
