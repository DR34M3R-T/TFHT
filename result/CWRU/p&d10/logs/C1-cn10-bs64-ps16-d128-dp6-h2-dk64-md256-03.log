[2022-08-06 17:20:32,648] ## start time: 2022-08-06 17:20:32.508786
[2022-08-06 17:20:32,649] Using cuda device
[2022-08-06 17:20:32,650] In train:p&d10.npy.
[2022-08-06 17:20:32,651] One Channel
[2022-08-06 17:20:32,652] With Normal data.
[2022-08-06 17:20:32,652] Nunber of classes:10.
[2022-08-06 17:20:32,652] Nunber of ViT channels:1.
[2022-08-06 17:20:32,876] Totol epochs: 15
[2022-08-06 17:20:32,879] Epoch 1---------------
[2022-08-06 17:20:32,879] lr: 2.000000e-03
[2022-08-06 17:20:33,596] loss: 2.363411  [    0/ 4746]
[2022-08-06 17:20:44,314] loss: 1.614614  [  960/ 4746]
[2022-08-06 17:20:55,032] loss: 1.422367  [ 1920/ 4746]
[2022-08-06 17:21:05,751] loss: 1.235380  [ 2880/ 4746]
[2022-08-06 17:21:16,469] loss: 0.704006  [ 3840/ 4746]
[2022-08-06 17:21:45,651] Train Error: Accuracy: 81.985%, Avg loss: 0.498390
[2022-08-06 17:21:54,132] Test  Error: Accuracy: 83.162%, Avg loss: 0.499035
[2022-08-06 17:21:54,132] Epoch 2---------------
[2022-08-06 17:21:54,133] lr: 1.900000e-03
[2022-08-06 17:21:54,851] loss: 0.458416  [    0/ 4746]
[2022-08-06 17:22:05,568] loss: 0.338628  [  960/ 4746]
[2022-08-06 17:22:16,285] loss: 0.166446  [ 1920/ 4746]
[2022-08-06 17:22:27,003] loss: 0.180831  [ 2880/ 4746]
[2022-08-06 17:22:37,722] loss: 0.268066  [ 3840/ 4746]
[2022-08-06 17:23:06,898] Train Error: Accuracy: 88.875%, Avg loss: 0.319132
[2022-08-06 17:23:15,377] Test  Error: Accuracy: 87.482%, Avg loss: 0.347690
[2022-08-06 17:23:15,378] Epoch 3---------------
[2022-08-06 17:23:15,378] lr: 1.805000e-03
[2022-08-06 17:23:16,096] loss: 0.233895  [    0/ 4746]
[2022-08-06 17:23:26,812] loss: 0.131639  [  960/ 4746]
[2022-08-06 17:23:37,530] loss: 0.200437  [ 1920/ 4746]
[2022-08-06 17:23:48,248] loss: 0.153456  [ 2880/ 4746]
[2022-08-06 17:23:58,965] loss: 0.019183  [ 3840/ 4746]
[2022-08-06 17:24:28,140] Train Error: Accuracy: 99.726%, Avg loss: 0.017087
[2022-08-06 17:24:36,618] Test  Error: Accuracy: 99.362%, Avg loss: 0.030404
[2022-08-06 17:24:36,619] Epoch 4---------------
[2022-08-06 17:24:36,621] lr: 1.714750e-03
[2022-08-06 17:24:37,336] loss: 0.017809  [    0/ 4746]
[2022-08-06 17:24:48,054] loss: 0.013276  [  960/ 4746]
[2022-08-06 17:24:58,773] loss: 0.354734  [ 1920/ 4746]
[2022-08-06 17:25:09,491] loss: 0.207364  [ 2880/ 4746]
[2022-08-06 17:25:20,208] loss: 0.076552  [ 3840/ 4746]
[2022-08-06 17:25:49,388] Train Error: Accuracy: 98.673%, Avg loss: 0.051803
[2022-08-06 17:25:57,866] Test  Error: Accuracy: 98.675%, Avg loss: 0.052332
[2022-08-06 17:25:57,867] Epoch 5---------------
[2022-08-06 17:25:57,868] lr: 1.197474e-03
[2022-08-06 17:25:58,585] loss: 0.021474  [    0/ 4746]
[2022-08-06 17:26:09,304] loss: 0.036784  [  960/ 4746]
[2022-08-06 17:26:20,022] loss: 0.021198  [ 1920/ 4746]
[2022-08-06 17:26:30,743] loss: 0.033369  [ 2880/ 4746]
[2022-08-06 17:26:41,464] loss: 0.039748  [ 3840/ 4746]
[2022-08-06 17:27:10,642] Train Error: Accuracy: 99.747%, Avg loss: 0.012526
[2022-08-06 17:27:19,122] Test  Error: Accuracy: 99.558%, Avg loss: 0.017497
[2022-08-06 17:27:19,123] Epoch 6---------------
[2022-08-06 17:27:19,124] lr: 1.137600e-03
[2022-08-06 17:27:19,842] loss: 0.020475  [    0/ 4746]
[2022-08-06 17:27:30,558] loss: 0.008182  [  960/ 4746]
[2022-08-06 17:27:41,277] loss: 0.004048  [ 1920/ 4746]
[2022-08-06 17:27:51,993] loss: 0.007483  [ 2880/ 4746]
[2022-08-06 17:28:02,711] loss: 0.019780  [ 3840/ 4746]
[2022-08-06 17:28:31,893] Train Error: Accuracy: 99.916%, Avg loss: 0.007843
[2022-08-06 17:28:40,373] Test  Error: Accuracy: 99.607%, Avg loss: 0.016822
[2022-08-06 17:28:40,373] Epoch 7---------------
[2022-08-06 17:28:40,374] lr: 1.080720e-03
[2022-08-06 17:28:41,091] loss: 0.008456  [    0/ 4746]
[2022-08-06 17:28:51,808] loss: 0.006415  [  960/ 4746]
[2022-08-06 17:29:02,525] loss: 0.007856  [ 1920/ 4746]
[2022-08-06 17:29:13,243] loss: 0.004518  [ 2880/ 4746]
[2022-08-06 17:29:23,959] loss: 0.008056  [ 3840/ 4746]
[2022-08-06 17:29:53,138] Train Error: Accuracy: 99.916%, Avg loss: 0.007848
[2022-08-06 17:30:01,616] Test  Error: Accuracy: 99.607%, Avg loss: 0.015100
[2022-08-06 17:30:01,617] Epoch 8---------------
[2022-08-06 17:30:01,618] lr: 1.026684e-03
[2022-08-06 17:30:02,336] loss: 0.002328  [    0/ 4746]
[2022-08-06 17:30:13,052] loss: 0.001824  [  960/ 4746]
[2022-08-06 17:30:23,770] loss: 0.002770  [ 1920/ 4746]
[2022-08-06 17:30:34,488] loss: 0.004843  [ 2880/ 4746]
[2022-08-06 17:30:45,205] loss: 0.002998  [ 3840/ 4746]
[2022-08-06 17:31:14,381] Train Error: Accuracy: 99.916%, Avg loss: 0.005231
[2022-08-06 17:31:22,862] Test  Error: Accuracy: 99.607%, Avg loss: 0.013389
[2022-08-06 17:31:22,862] Epoch 9---------------
[2022-08-06 17:31:22,863] lr: 9.753500e-04
[2022-08-06 17:31:23,580] loss: 0.002742  [    0/ 4746]
[2022-08-06 17:31:34,297] loss: 0.001454  [  960/ 4746]
[2022-08-06 17:31:45,013] loss: 0.002632  [ 1920/ 4746]
[2022-08-06 17:31:55,731] loss: 0.002217  [ 2880/ 4746]
[2022-08-06 17:32:06,448] loss: 0.008800  [ 3840/ 4746]
[2022-08-06 17:32:35,631] Train Error: Accuracy: 99.958%, Avg loss: 0.005232
[2022-08-06 17:32:44,110] Test  Error: Accuracy: 99.755%, Avg loss: 0.012606
[2022-08-06 17:32:44,110] Epoch 10---------------
[2022-08-06 17:32:44,111] lr: 9.265825e-04
[2022-08-06 17:32:44,829] loss: 0.002324  [    0/ 4746]
[2022-08-06 17:32:55,547] loss: 0.003382  [  960/ 4746]
[2022-08-06 17:33:06,265] loss: 0.002159  [ 1920/ 4746]
[2022-08-06 17:33:16,984] loss: 0.003033  [ 2880/ 4746]
[2022-08-06 17:33:27,703] loss: 0.001622  [ 3840/ 4746]
[2022-08-06 17:33:56,880] Train Error: Accuracy: 99.916%, Avg loss: 0.003120
[2022-08-06 17:34:05,360] Test  Error: Accuracy: 99.755%, Avg loss: 0.009043
[2022-08-06 17:34:05,361] Epoch 11---------------
[2022-08-06 17:34:05,362] lr: 8.802533e-04
[2022-08-06 17:34:06,079] loss: 0.001019  [    0/ 4746]
[2022-08-06 17:34:16,798] loss: 0.002644  [  960/ 4746]
[2022-08-06 17:34:27,515] loss: 0.017099  [ 1920/ 4746]
[2022-08-06 17:34:38,233] loss: 0.003676  [ 2880/ 4746]
[2022-08-06 17:34:48,950] loss: 0.002297  [ 3840/ 4746]
[2022-08-06 17:35:18,110] Train Error: Accuracy: 99.853%, Avg loss: 0.007551
[2022-08-06 17:35:26,582] Test  Error: Accuracy: 99.558%, Avg loss: 0.016366
[2022-08-06 17:35:26,583] Epoch 12---------------
[2022-08-06 17:35:26,584] lr: 6.147137e-04
[2022-08-06 17:35:27,301] loss: 0.001675  [    0/ 4746]
[2022-08-06 17:35:38,018] loss: 0.003518  [  960/ 4746]
[2022-08-06 17:35:48,736] loss: 0.004057  [ 1920/ 4746]
[2022-08-06 17:35:59,455] loss: 0.008590  [ 2880/ 4746]
[2022-08-06 17:36:10,172] loss: 0.003345  [ 3840/ 4746]
[2022-08-06 17:36:39,336] Train Error: Accuracy: 99.747%, Avg loss: 0.009752
[2022-08-06 17:36:47,808] Test  Error: Accuracy: 99.607%, Avg loss: 0.015024
[2022-08-06 17:36:47,809] Epoch 13---------------
[2022-08-06 17:36:47,810] lr: 5.839780e-04
[2022-08-06 17:36:48,527] loss: 0.002869  [    0/ 4746]
[2022-08-06 17:36:59,246] loss: 0.002954  [  960/ 4746]
[2022-08-06 17:37:09,964] loss: 0.026073  [ 1920/ 4746]
[2022-08-06 17:37:20,682] loss: 0.002104  [ 2880/ 4746]
[2022-08-06 17:37:31,400] loss: 0.001700  [ 3840/ 4746]
[2022-08-06 17:38:00,564] Train Error: Accuracy: 99.831%, Avg loss: 0.007319
[2022-08-06 17:38:09,036] Test  Error: Accuracy: 99.705%, Avg loss: 0.011796
[2022-08-06 17:38:09,036] Epoch 14---------------
[2022-08-06 17:38:09,037] lr: 5.547791e-04
[2022-08-06 17:38:09,754] loss: 0.005560  [    0/ 4746]
[2022-08-06 17:38:20,472] loss: 0.001695  [  960/ 4746]
[2022-08-06 17:38:31,188] loss: 0.000955  [ 1920/ 4746]
[2022-08-06 17:38:41,907] loss: 0.003689  [ 2880/ 4746]
[2022-08-06 17:38:52,624] loss: 0.001470  [ 3840/ 4746]
[2022-08-06 17:39:21,799] Train Error: Accuracy: 100.000%, Avg loss: 0.002562
[2022-08-06 17:39:30,275] Test  Error: Accuracy: 99.705%, Avg loss: 0.010145
[2022-08-06 17:39:30,276] Epoch 15---------------
[2022-08-06 17:39:30,277] lr: 5.270402e-04
[2022-08-06 17:39:30,994] loss: 0.001875  [    0/ 4746]
[2022-08-06 17:39:41,712] loss: 0.000937  [  960/ 4746]
[2022-08-06 17:39:52,428] loss: 0.001306  [ 1920/ 4746]
[2022-08-06 17:40:03,146] loss: 0.001224  [ 2880/ 4746]
[2022-08-06 17:40:13,863] loss: 0.001181  [ 3840/ 4746]
[2022-08-06 17:40:43,042] Train Error: Accuracy: 99.979%, Avg loss: 0.002369
[2022-08-06 17:40:51,521] Test  Error: Accuracy: 99.853%, Avg loss: 0.008527
[2022-08-06 17:40:51,522] Done!
[2022-08-06 17:40:51,526] Number of parameters:1625866
[2022-08-06 17:40:51,526] ## end time: 2022-08-06 17:40:51.522382
[2022-08-06 17:40:51,527] ## used time: 0:20:19.013596
