[2022-08-06 15:21:13,425] ## start time: 2022-08-06 15:21:13.303859
[2022-08-06 15:21:13,426] Using cuda device
[2022-08-06 15:21:13,427] In train:p&d10.npy.
[2022-08-06 15:21:13,428] One Channel
[2022-08-06 15:21:13,429] With Normal data.
[2022-08-06 15:21:13,429] Nunber of classes:10.
[2022-08-06 15:21:13,430] Nunber of ViT channels:1.
[2022-08-06 15:21:13,617] Totol epochs: 10
[2022-08-06 15:21:13,618] Epoch 1---------------
[2022-08-06 15:21:13,618] lr: 2.000000e-03
[2022-08-06 15:21:13,631] loss: 2.445633  [    0/ 4668]
[2022-08-06 15:21:13,795] loss: 2.185476  [  960/ 4668]
[2022-08-06 15:21:13,956] loss: 1.839654  [ 1920/ 4668]
[2022-08-06 15:21:14,112] loss: 1.231329  [ 2880/ 4668]
[2022-08-06 15:21:14,264] loss: 0.841353  [ 3840/ 4668]
[2022-08-06 15:21:14,682] Train Error: Accuracy: 76.607%, Avg loss: 0.694113
[2022-08-06 15:21:14,808] Test  Error: Accuracy: 75.461%, Avg loss: 0.735667
[2022-08-06 15:21:14,808] Epoch 2---------------
[2022-08-06 15:21:14,809] lr: 1.900000e-03
[2022-08-06 15:21:14,820] loss: 0.634417  [    0/ 4668]
[2022-08-06 15:21:14,979] loss: 0.618335  [  960/ 4668]
[2022-08-06 15:21:15,136] loss: 0.358531  [ 1920/ 4668]
[2022-08-06 15:21:15,291] loss: 0.302675  [ 2880/ 4668]
[2022-08-06 15:21:15,442] loss: 0.200842  [ 3840/ 4668]
[2022-08-06 15:21:15,821] Train Error: Accuracy: 94.880%, Avg loss: 0.206462
[2022-08-06 15:21:15,941] Test  Error: Accuracy: 92.624%, Avg loss: 0.244273
[2022-08-06 15:21:15,941] Epoch 3---------------
[2022-08-06 15:21:15,942] lr: 1.805000e-03
[2022-08-06 15:21:15,953] loss: 0.176073  [    0/ 4668]
[2022-08-06 15:21:16,106] loss: 0.173413  [  960/ 4668]
[2022-08-06 15:21:16,259] loss: 0.163623  [ 1920/ 4668]
[2022-08-06 15:21:16,409] loss: 0.072016  [ 2880/ 4668]
[2022-08-06 15:21:16,559] loss: 0.064580  [ 3840/ 4668]
[2022-08-06 15:21:16,941] Train Error: Accuracy: 98.693%, Avg loss: 0.080452
[2022-08-06 15:21:17,064] Test  Error: Accuracy: 98.156%, Avg loss: 0.100108
[2022-08-06 15:21:17,064] Epoch 4---------------
[2022-08-06 15:21:17,067] lr: 1.714750e-03
[2022-08-06 15:21:17,078] loss: 0.050579  [    0/ 4668]
[2022-08-06 15:21:17,231] loss: 0.079769  [  960/ 4668]
[2022-08-06 15:21:17,384] loss: 0.040050  [ 1920/ 4668]
[2022-08-06 15:21:17,539] loss: 0.031563  [ 2880/ 4668]
[2022-08-06 15:21:17,690] loss: 0.038495  [ 3840/ 4668]
[2022-08-06 15:21:18,071] Train Error: Accuracy: 99.250%, Avg loss: 0.042076
[2022-08-06 15:21:18,192] Test  Error: Accuracy: 98.582%, Avg loss: 0.055017
[2022-08-06 15:21:18,192] Epoch 5---------------
[2022-08-06 15:21:18,193] lr: 1.629012e-03
[2022-08-06 15:21:18,205] loss: 0.063505  [    0/ 4668]
[2022-08-06 15:21:18,356] loss: 0.107656  [  960/ 4668]
[2022-08-06 15:21:18,506] loss: 0.079641  [ 1920/ 4668]
[2022-08-06 15:21:18,655] loss: 0.023420  [ 2880/ 4668]
[2022-08-06 15:21:18,802] loss: 0.098277  [ 3840/ 4668]
[2022-08-06 15:21:19,180] Train Error: Accuracy: 99.186%, Avg loss: 0.035611
[2022-08-06 15:21:19,302] Test  Error: Accuracy: 98.534%, Avg loss: 0.055763
[2022-08-06 15:21:19,302] Epoch 6---------------
[2022-08-06 15:21:19,303] lr: 1.396675e-03
[2022-08-06 15:21:19,315] loss: 0.034477  [    0/ 4668]
[2022-08-06 15:21:19,467] loss: 0.010148  [  960/ 4668]
[2022-08-06 15:21:19,615] loss: 0.033267  [ 1920/ 4668]
[2022-08-06 15:21:19,763] loss: 0.041791  [ 2880/ 4668]
[2022-08-06 15:21:19,915] loss: 0.016557  [ 3840/ 4668]
[2022-08-06 15:21:20,291] Train Error: Accuracy: 99.679%, Avg loss: 0.021664
[2022-08-06 15:21:20,413] Test  Error: Accuracy: 99.149%, Avg loss: 0.038652
[2022-08-06 15:21:20,413] Epoch 7---------------
[2022-08-06 15:21:20,414] lr: 1.326841e-03
[2022-08-06 15:21:20,426] loss: 0.008090  [    0/ 4668]
[2022-08-06 15:21:20,575] loss: 0.020321  [  960/ 4668]
[2022-08-06 15:21:20,724] loss: 0.018688  [ 1920/ 4668]
[2022-08-06 15:21:20,871] loss: 0.007812  [ 2880/ 4668]
[2022-08-06 15:21:21,021] loss: 0.008009  [ 3840/ 4668]
[2022-08-06 15:21:21,398] Train Error: Accuracy: 99.743%, Avg loss: 0.016153
[2022-08-06 15:21:21,520] Test  Error: Accuracy: 99.102%, Avg loss: 0.032989
[2022-08-06 15:21:21,521] Epoch 8---------------
[2022-08-06 15:21:21,522] lr: 1.260499e-03
[2022-08-06 15:21:21,533] loss: 0.014485  [    0/ 4668]
[2022-08-06 15:21:21,683] loss: 0.017962  [  960/ 4668]
[2022-08-06 15:21:21,834] loss: 0.011283  [ 1920/ 4668]
[2022-08-06 15:21:21,986] loss: 0.020020  [ 2880/ 4668]
[2022-08-06 15:21:22,135] loss: 0.010258  [ 3840/ 4668]
[2022-08-06 15:21:22,512] Train Error: Accuracy: 99.614%, Avg loss: 0.022963
[2022-08-06 15:21:22,633] Test  Error: Accuracy: 98.913%, Avg loss: 0.040812
[2022-08-06 15:21:22,633] Epoch 9---------------
[2022-08-06 15:21:22,634] lr: 9.753500e-04
[2022-08-06 15:21:22,646] loss: 0.016524  [    0/ 4668]
[2022-08-06 15:21:22,797] loss: 0.009854  [  960/ 4668]
[2022-08-06 15:21:22,950] loss: 0.008618  [ 1920/ 4668]
[2022-08-06 15:21:23,100] loss: 0.031221  [ 2880/ 4668]
[2022-08-06 15:21:23,253] loss: 0.004907  [ 3840/ 4668]
[2022-08-06 15:21:23,630] Train Error: Accuracy: 99.850%, Avg loss: 0.009977
[2022-08-06 15:21:23,750] Test  Error: Accuracy: 99.149%, Avg loss: 0.026634
[2022-08-06 15:21:23,750] Epoch 10---------------
[2022-08-06 15:21:23,751] lr: 9.265825e-04
[2022-08-06 15:21:23,763] loss: 0.008346  [    0/ 4668]
[2022-08-06 15:21:23,912] loss: 0.007349  [  960/ 4668]
[2022-08-06 15:21:24,061] loss: 0.009014  [ 1920/ 4668]
[2022-08-06 15:21:24,209] loss: 0.003218  [ 2880/ 4668]
[2022-08-06 15:21:24,357] loss: 0.004466  [ 3840/ 4668]
[2022-08-06 15:21:24,737] Train Error: Accuracy: 99.893%, Avg loss: 0.008206
[2022-08-06 15:21:24,855] Test  Error: Accuracy: 99.196%, Avg loss: 0.024161
[2022-08-06 15:21:24,856] Done!
[2022-08-06 15:21:24,858] Number of parameters:34762
[2022-08-06 15:21:24,859] ## end time: 2022-08-06 15:21:24.856884
[2022-08-06 15:21:24,859] ## used time: 0:00:11.553025
