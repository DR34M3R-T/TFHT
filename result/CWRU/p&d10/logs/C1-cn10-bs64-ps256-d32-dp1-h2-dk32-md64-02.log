[2022-08-06 15:22:00,271] ## start time: 2022-08-06 15:22:00.146039
[2022-08-06 15:22:00,272] Using cuda device
[2022-08-06 15:22:00,273] In train:p&d10.npy.
[2022-08-06 15:22:00,274] One Channel
[2022-08-06 15:22:00,275] With Normal data.
[2022-08-06 15:22:00,275] Nunber of classes:10.
[2022-08-06 15:22:00,276] Nunber of ViT channels:1.
[2022-08-06 15:22:00,466] Totol epochs: 10
[2022-08-06 15:22:00,468] Epoch 1---------------
[2022-08-06 15:22:00,468] lr: 2.000000e-03
[2022-08-06 15:22:00,482] loss: 2.358026  [    0/ 4737]
[2022-08-06 15:22:00,640] loss: 2.022938  [  960/ 4737]
[2022-08-06 15:22:00,799] loss: 1.653761  [ 1920/ 4737]
[2022-08-06 15:22:00,953] loss: 1.457562  [ 2880/ 4737]
[2022-08-06 15:22:01,103] loss: 0.695965  [ 3840/ 4737]
[2022-08-06 15:22:01,509] Train Error: Accuracy: 67.363%, Avg loss: 0.875848
[2022-08-06 15:22:01,624] Test  Error: Accuracy: 65.885%, Avg loss: 0.919401
[2022-08-06 15:22:01,624] Epoch 2---------------
[2022-08-06 15:22:01,625] lr: 1.900000e-03
[2022-08-06 15:22:01,638] loss: 0.811905  [    0/ 4737]
[2022-08-06 15:22:01,789] loss: 0.253850  [  960/ 4737]
[2022-08-06 15:22:01,940] loss: 0.277748  [ 1920/ 4737]
[2022-08-06 15:22:02,090] loss: 0.191834  [ 2880/ 4737]
[2022-08-06 15:22:02,241] loss: 0.227463  [ 3840/ 4737]
[2022-08-06 15:22:02,644] Train Error: Accuracy: 95.968%, Avg loss: 0.167207
[2022-08-06 15:22:02,757] Test  Error: Accuracy: 95.552%, Avg loss: 0.176526
[2022-08-06 15:22:02,757] Epoch 3---------------
[2022-08-06 15:22:02,758] lr: 1.805000e-03
[2022-08-06 15:22:02,771] loss: 0.184097  [    0/ 4737]
[2022-08-06 15:22:02,923] loss: 0.091063  [  960/ 4737]
[2022-08-06 15:22:03,071] loss: 0.191984  [ 1920/ 4737]
[2022-08-06 15:22:03,220] loss: 0.057694  [ 2880/ 4737]
[2022-08-06 15:22:03,374] loss: 0.030627  [ 3840/ 4737]
[2022-08-06 15:22:03,780] Train Error: Accuracy: 96.855%, Avg loss: 0.105717
[2022-08-06 15:22:03,893] Test  Error: Accuracy: 96.481%, Avg loss: 0.115644
[2022-08-06 15:22:03,894] Epoch 4---------------
[2022-08-06 15:22:03,895] lr: 1.714750e-03
[2022-08-06 15:22:03,906] loss: 0.029403  [    0/ 4737]
[2022-08-06 15:22:04,055] loss: 0.027779  [  960/ 4737]
[2022-08-06 15:22:04,206] loss: 0.021751  [ 1920/ 4737]
[2022-08-06 15:22:04,358] loss: 0.032687  [ 2880/ 4737]
[2022-08-06 15:22:04,512] loss: 0.059561  [ 3840/ 4737]
[2022-08-06 15:22:04,917] Train Error: Accuracy: 99.620%, Avg loss: 0.029934
[2022-08-06 15:22:05,031] Test  Error: Accuracy: 99.267%, Avg loss: 0.038228
[2022-08-06 15:22:05,031] Epoch 5---------------
[2022-08-06 15:22:05,032] lr: 1.629012e-03
[2022-08-06 15:22:05,044] loss: 0.021788  [    0/ 4737]
[2022-08-06 15:22:05,194] loss: 0.016189  [  960/ 4737]
[2022-08-06 15:22:05,343] loss: 0.040079  [ 1920/ 4737]
[2022-08-06 15:22:05,495] loss: 0.033105  [ 2880/ 4737]
[2022-08-06 15:22:05,647] loss: 0.010274  [ 3840/ 4737]
[2022-08-06 15:22:06,048] Train Error: Accuracy: 99.198%, Avg loss: 0.033473
[2022-08-06 15:22:06,163] Test  Error: Accuracy: 99.022%, Avg loss: 0.040146
[2022-08-06 15:22:06,163] Epoch 6---------------
[2022-08-06 15:22:06,164] lr: 1.396675e-03
[2022-08-06 15:22:06,177] loss: 0.016560  [    0/ 4737]
[2022-08-06 15:22:06,328] loss: 0.010051  [  960/ 4737]
[2022-08-06 15:22:06,476] loss: 0.035727  [ 1920/ 4737]
[2022-08-06 15:22:06,630] loss: 0.008800  [ 2880/ 4737]
[2022-08-06 15:22:06,781] loss: 0.021944  [ 3840/ 4737]
[2022-08-06 15:22:07,184] Train Error: Accuracy: 99.789%, Avg loss: 0.013810
[2022-08-06 15:22:07,298] Test  Error: Accuracy: 99.560%, Avg loss: 0.018697
[2022-08-06 15:22:07,298] Epoch 7---------------
[2022-08-06 15:22:07,299] lr: 1.326841e-03
[2022-08-06 15:22:07,311] loss: 0.013006  [    0/ 4737]
[2022-08-06 15:22:07,462] loss: 0.057036  [  960/ 4737]
[2022-08-06 15:22:07,610] loss: 0.023815  [ 1920/ 4737]
[2022-08-06 15:22:07,763] loss: 0.008227  [ 2880/ 4737]
[2022-08-06 15:22:07,911] loss: 0.004181  [ 3840/ 4737]
[2022-08-06 15:22:08,313] Train Error: Accuracy: 99.937%, Avg loss: 0.009010
[2022-08-06 15:22:08,426] Test  Error: Accuracy: 99.511%, Avg loss: 0.019499
[2022-08-06 15:22:08,426] Epoch 8---------------
[2022-08-06 15:22:08,429] lr: 1.137600e-03
[2022-08-06 15:22:08,440] loss: 0.005625  [    0/ 4737]
[2022-08-06 15:22:08,591] loss: 0.016241  [  960/ 4737]
[2022-08-06 15:22:08,744] loss: 0.005975  [ 1920/ 4737]
[2022-08-06 15:22:08,894] loss: 0.005595  [ 2880/ 4737]
[2022-08-06 15:22:09,045] loss: 0.007346  [ 3840/ 4737]
[2022-08-06 15:22:09,443] Train Error: Accuracy: 99.113%, Avg loss: 0.027561
[2022-08-06 15:22:09,557] Test  Error: Accuracy: 98.974%, Avg loss: 0.033887
[2022-08-06 15:22:09,557] Epoch 9---------------
[2022-08-06 15:22:09,558] lr: 7.944286e-04
[2022-08-06 15:22:09,571] loss: 0.005578  [    0/ 4737]
[2022-08-06 15:22:09,721] loss: 0.005455  [  960/ 4737]
[2022-08-06 15:22:09,872] loss: 0.004825  [ 1920/ 4737]
[2022-08-06 15:22:10,023] loss: 0.016287  [ 2880/ 4737]
[2022-08-06 15:22:10,172] loss: 0.004039  [ 3840/ 4737]
[2022-08-06 15:22:10,571] Train Error: Accuracy: 99.979%, Avg loss: 0.005943
[2022-08-06 15:22:10,685] Test  Error: Accuracy: 99.902%, Avg loss: 0.009658
[2022-08-06 15:22:10,685] Epoch 10---------------
[2022-08-06 15:22:10,686] lr: 7.547072e-04
[2022-08-06 15:22:10,699] loss: 0.003250  [    0/ 4737]
[2022-08-06 15:22:10,849] loss: 0.005329  [  960/ 4737]
[2022-08-06 15:22:11,001] loss: 0.003392  [ 1920/ 4737]
[2022-08-06 15:22:11,152] loss: 0.005470  [ 2880/ 4737]
[2022-08-06 15:22:11,301] loss: 0.016359  [ 3840/ 4737]
[2022-08-06 15:22:11,704] Train Error: Accuracy: 99.937%, Avg loss: 0.007033
[2022-08-06 15:22:11,817] Test  Error: Accuracy: 99.658%, Avg loss: 0.014719
[2022-08-06 15:22:11,818] Done!
[2022-08-06 15:22:11,820] Number of parameters:42954
[2022-08-06 15:22:11,820] ## end time: 2022-08-06 15:22:11.818145
[2022-08-06 15:22:11,820] ## used time: 0:00:11.672106
