[2022-08-06 15:17:30,082] ## start time: 2022-08-06 15:17:29.944145
[2022-08-06 15:17:30,082] Using cuda device
[2022-08-06 15:17:30,084] In train:p&d10.npy.
[2022-08-06 15:17:30,085] One Channel
[2022-08-06 15:17:30,085] With Normal data.
[2022-08-06 15:17:30,086] Nunber of classes:10.
[2022-08-06 15:17:30,086] Nunber of ViT channels:1.
[2022-08-06 15:17:30,268] Totol epochs: 10
[2022-08-06 15:17:30,269] Epoch 1---------------
[2022-08-06 15:17:30,270] lr: 2.000000e-03
[2022-08-06 15:17:30,284] loss: 2.437419  [    0/ 4766]
[2022-08-06 15:17:30,441] loss: 1.874481  [  960/ 4766]
[2022-08-06 15:17:30,604] loss: 1.661204  [ 1920/ 4766]
[2022-08-06 15:17:30,762] loss: 1.135560  [ 2880/ 4766]
[2022-08-06 15:17:30,918] loss: 0.827212  [ 3840/ 4766]
[2022-08-06 15:17:31,375] Train Error: Accuracy: 91.943%, Avg loss: 0.399378
[2022-08-06 15:17:31,500] Test  Error: Accuracy: 91.671%, Avg loss: 0.419239
[2022-08-06 15:17:31,501] Epoch 2---------------
[2022-08-06 15:17:31,502] lr: 1.900000e-03
[2022-08-06 15:17:31,514] loss: 0.341603  [    0/ 4766]
[2022-08-06 15:17:31,671] loss: 0.261373  [  960/ 4766]
[2022-08-06 15:17:31,834] loss: 0.122271  [ 1920/ 4766]
[2022-08-06 15:17:31,995] loss: 0.177563  [ 2880/ 4766]
[2022-08-06 15:17:32,153] loss: 0.141873  [ 3840/ 4766]
[2022-08-06 15:17:32,585] Train Error: Accuracy: 95.258%, Avg loss: 0.185615
[2022-08-06 15:17:32,708] Test  Error: Accuracy: 95.340%, Avg loss: 0.197658
[2022-08-06 15:17:32,709] Epoch 3---------------
[2022-08-06 15:17:32,710] lr: 1.805000e-03
[2022-08-06 15:17:32,723] loss: 0.165844  [    0/ 4766]
[2022-08-06 15:17:32,873] loss: 0.039501  [  960/ 4766]
[2022-08-06 15:17:33,026] loss: 0.051767  [ 1920/ 4766]
[2022-08-06 15:17:33,178] loss: 0.076250  [ 2880/ 4766]
[2022-08-06 15:17:33,330] loss: 0.046110  [ 3840/ 4766]
[2022-08-06 15:17:33,754] Train Error: Accuracy: 99.769%, Avg loss: 0.028310
[2022-08-06 15:17:33,875] Test  Error: Accuracy: 99.306%, Avg loss: 0.041099
[2022-08-06 15:17:33,876] Epoch 4---------------
[2022-08-06 15:17:33,877] lr: 1.714750e-03
[2022-08-06 15:17:33,888] loss: 0.022682  [    0/ 4766]
[2022-08-06 15:17:34,043] loss: 0.022699  [  960/ 4766]
[2022-08-06 15:17:34,194] loss: 0.011828  [ 1920/ 4766]
[2022-08-06 15:17:34,348] loss: 0.020907  [ 2880/ 4766]
[2022-08-06 15:17:34,498] loss: 0.014655  [ 3840/ 4766]
[2022-08-06 15:17:34,920] Train Error: Accuracy: 99.622%, Avg loss: 0.025780
[2022-08-06 15:17:35,040] Test  Error: Accuracy: 99.306%, Avg loss: 0.033048
[2022-08-06 15:17:35,041] Epoch 5---------------
[2022-08-06 15:17:35,042] lr: 1.629012e-03
[2022-08-06 15:17:35,054] loss: 0.024182  [    0/ 4766]
[2022-08-06 15:17:35,209] loss: 0.010167  [  960/ 4766]
[2022-08-06 15:17:35,359] loss: 0.017009  [ 1920/ 4766]
[2022-08-06 15:17:35,512] loss: 0.015800  [ 2880/ 4766]
[2022-08-06 15:17:35,664] loss: 0.021696  [ 3840/ 4766]
[2022-08-06 15:17:36,084] Train Error: Accuracy: 76.185%, Avg loss: 1.049429
[2022-08-06 15:17:36,207] Test  Error: Accuracy: 73.079%, Avg loss: 1.225472
[2022-08-06 15:17:36,208] Epoch 6---------------
[2022-08-06 15:17:36,208] lr: 1.137600e-03
[2022-08-06 15:17:36,220] loss: 0.586905  [    0/ 4766]
[2022-08-06 15:17:36,376] loss: 0.015895  [  960/ 4766]
[2022-08-06 15:17:36,531] loss: 0.011337  [ 1920/ 4766]
[2022-08-06 15:17:36,684] loss: 0.010195  [ 2880/ 4766]
[2022-08-06 15:17:36,837] loss: 0.018606  [ 3840/ 4766]
[2022-08-06 15:17:37,264] Train Error: Accuracy: 99.853%, Avg loss: 0.013707
[2022-08-06 15:17:37,383] Test  Error: Accuracy: 99.703%, Avg loss: 0.021762
[2022-08-06 15:17:37,384] Epoch 7---------------
[2022-08-06 15:17:37,385] lr: 1.080720e-03
[2022-08-06 15:17:37,397] loss: 0.012898  [    0/ 4766]
[2022-08-06 15:17:37,547] loss: 0.009123  [  960/ 4766]
[2022-08-06 15:17:37,696] loss: 0.006494  [ 1920/ 4766]
[2022-08-06 15:17:37,846] loss: 0.009425  [ 2880/ 4766]
[2022-08-06 15:17:37,997] loss: 0.007222  [ 3840/ 4766]
[2022-08-06 15:17:38,418] Train Error: Accuracy: 99.937%, Avg loss: 0.007913
[2022-08-06 15:17:38,537] Test  Error: Accuracy: 99.703%, Avg loss: 0.014924
[2022-08-06 15:17:38,538] Epoch 8---------------
[2022-08-06 15:17:38,539] lr: 1.026684e-03
[2022-08-06 15:17:38,550] loss: 0.007114  [    0/ 4766]
[2022-08-06 15:17:38,701] loss: 0.005026  [  960/ 4766]
[2022-08-06 15:17:38,850] loss: 0.004274  [ 1920/ 4766]
[2022-08-06 15:17:39,001] loss: 0.003364  [ 2880/ 4766]
[2022-08-06 15:17:39,151] loss: 0.008099  [ 3840/ 4766]
[2022-08-06 15:17:39,575] Train Error: Accuracy: 99.916%, Avg loss: 0.006387
[2022-08-06 15:17:39,699] Test  Error: Accuracy: 99.802%, Avg loss: 0.012843
[2022-08-06 15:17:39,699] Epoch 9---------------
[2022-08-06 15:17:39,700] lr: 9.753500e-04
[2022-08-06 15:17:39,712] loss: 0.003870  [    0/ 4766]
[2022-08-06 15:17:39,864] loss: 0.003993  [  960/ 4766]
[2022-08-06 15:17:40,015] loss: 0.004055  [ 1920/ 4766]
[2022-08-06 15:17:40,166] loss: 0.005940  [ 2880/ 4766]
[2022-08-06 15:17:40,320] loss: 0.003830  [ 3840/ 4766]
[2022-08-06 15:17:40,747] Train Error: Accuracy: 99.853%, Avg loss: 0.008044
[2022-08-06 15:17:40,867] Test  Error: Accuracy: 99.703%, Avg loss: 0.015992
[2022-08-06 15:17:40,867] Epoch 10---------------
[2022-08-06 15:17:40,868] lr: 7.547072e-04
[2022-08-06 15:17:40,881] loss: 0.015009  [    0/ 4766]
[2022-08-06 15:17:41,031] loss: 0.004480  [  960/ 4766]
[2022-08-06 15:17:41,181] loss: 0.003050  [ 1920/ 4766]
[2022-08-06 15:17:41,331] loss: 0.012153  [ 2880/ 4766]
[2022-08-06 15:17:41,485] loss: 0.005887  [ 3840/ 4766]
[2022-08-06 15:17:41,913] Train Error: Accuracy: 99.958%, Avg loss: 0.005478
[2022-08-06 15:17:42,035] Test  Error: Accuracy: 99.901%, Avg loss: 0.008959
[2022-08-06 15:17:42,035] Done!
[2022-08-06 15:17:42,037] Number of parameters:92106
[2022-08-06 15:17:42,037] ## end time: 2022-08-06 15:17:42.035370
[2022-08-06 15:17:42,037] ## used time: 0:00:12.091225
