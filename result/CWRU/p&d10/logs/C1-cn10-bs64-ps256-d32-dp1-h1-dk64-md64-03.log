[2022-08-06 15:16:54,406] ## start time: 2022-08-06 15:16:54.283225
[2022-08-06 15:16:54,407] Using cuda device
[2022-08-06 15:16:54,408] In train:p&d10.npy.
[2022-08-06 15:16:54,409] One Channel
[2022-08-06 15:16:54,409] With Normal data.
[2022-08-06 15:16:54,410] Nunber of classes:10.
[2022-08-06 15:16:54,410] Nunber of ViT channels:1.
[2022-08-06 15:16:54,598] Totol epochs: 10
[2022-08-06 15:16:54,599] Epoch 1---------------
[2022-08-06 15:16:54,600] lr: 2.000000e-03
[2022-08-06 15:16:54,612] loss: 2.571889  [    0/ 4749]
[2022-08-06 15:16:54,771] loss: 1.982905  [  960/ 4749]
[2022-08-06 15:16:54,930] loss: 1.684444  [ 1920/ 4749]
[2022-08-06 15:16:55,083] loss: 1.365205  [ 2880/ 4749]
[2022-08-06 15:16:55,232] loss: 1.056503  [ 3840/ 4749]
[2022-08-06 15:16:55,645] Train Error: Accuracy: 71.699%, Avg loss: 0.888251
[2022-08-06 15:16:55,758] Test  Error: Accuracy: 71.583%, Avg loss: 0.893255
[2022-08-06 15:16:55,759] Epoch 2---------------
[2022-08-06 15:16:55,759] lr: 1.900000e-03
[2022-08-06 15:16:55,770] loss: 0.857770  [    0/ 4749]
[2022-08-06 15:16:55,923] loss: 0.638076  [  960/ 4749]
[2022-08-06 15:16:56,076] loss: 0.621315  [ 1920/ 4749]
[2022-08-06 15:16:56,229] loss: 0.276317  [ 2880/ 4749]
[2022-08-06 15:16:56,380] loss: 0.314136  [ 3840/ 4749]
[2022-08-06 15:16:56,776] Train Error: Accuracy: 91.093%, Avg loss: 0.298874
[2022-08-06 15:16:56,887] Test  Error: Accuracy: 91.003%, Avg loss: 0.310917
[2022-08-06 15:16:56,887] Epoch 3---------------
[2022-08-06 15:16:56,888] lr: 1.805000e-03
[2022-08-06 15:16:56,900] loss: 0.233528  [    0/ 4749]
[2022-08-06 15:16:57,047] loss: 0.294358  [  960/ 4749]
[2022-08-06 15:16:57,193] loss: 0.326332  [ 1920/ 4749]
[2022-08-06 15:16:57,340] loss: 0.132705  [ 2880/ 4749]
[2022-08-06 15:16:57,492] loss: 0.310429  [ 3840/ 4749]
[2022-08-06 15:16:57,884] Train Error: Accuracy: 97.979%, Avg loss: 0.105366
[2022-08-06 15:16:57,994] Test  Error: Accuracy: 97.148%, Avg loss: 0.129460
[2022-08-06 15:16:57,994] Epoch 4---------------
[2022-08-06 15:16:57,996] lr: 1.714750e-03
[2022-08-06 15:16:58,008] loss: 0.169683  [    0/ 4749]
[2022-08-06 15:16:58,155] loss: 0.112804  [  960/ 4749]
[2022-08-06 15:16:58,302] loss: 0.124011  [ 1920/ 4749]
[2022-08-06 15:16:58,449] loss: 0.070536  [ 2880/ 4749]
[2022-08-06 15:16:58,599] loss: 0.034112  [ 3840/ 4749]
[2022-08-06 15:16:58,997] Train Error: Accuracy: 94.799%, Avg loss: 0.176122
[2022-08-06 15:16:59,106] Test  Error: Accuracy: 94.297%, Avg loss: 0.191051
[2022-08-06 15:16:59,106] Epoch 5---------------
[2022-08-06 15:16:59,107] lr: 1.197474e-03
[2022-08-06 15:16:59,118] loss: 0.341623  [    0/ 4749]
[2022-08-06 15:16:59,268] loss: 0.030652  [  960/ 4749]
[2022-08-06 15:16:59,413] loss: 0.083482  [ 1920/ 4749]
[2022-08-06 15:16:59,563] loss: 0.027003  [ 2880/ 4749]
[2022-08-06 15:16:59,720] loss: 0.048663  [ 3840/ 4749]
[2022-08-06 15:17:00,122] Train Error: Accuracy: 99.200%, Avg loss: 0.046020
[2022-08-06 15:17:00,234] Test  Error: Accuracy: 98.820%, Avg loss: 0.057235
[2022-08-06 15:17:00,234] Epoch 6---------------
[2022-08-06 15:17:00,235] lr: 1.137600e-03
[2022-08-06 15:17:00,247] loss: 0.036739  [    0/ 4749]
[2022-08-06 15:17:00,395] loss: 0.024781  [  960/ 4749]
[2022-08-06 15:17:00,541] loss: 0.080446  [ 1920/ 4749]
[2022-08-06 15:17:00,692] loss: 0.033554  [ 2880/ 4749]
[2022-08-06 15:17:00,839] loss: 0.030354  [ 3840/ 4749]
[2022-08-06 15:17:01,231] Train Error: Accuracy: 95.094%, Avg loss: 0.171097
[2022-08-06 15:17:01,340] Test  Error: Accuracy: 94.248%, Avg loss: 0.198541
[2022-08-06 15:17:01,340] Epoch 7---------------
[2022-08-06 15:17:01,341] lr: 7.944286e-04
[2022-08-06 15:17:01,353] loss: 0.250636  [    0/ 4749]
[2022-08-06 15:17:01,498] loss: 0.051727  [  960/ 4749]
[2022-08-06 15:17:01,645] loss: 0.043113  [ 1920/ 4749]
[2022-08-06 15:17:01,801] loss: 0.025051  [ 2880/ 4749]
[2022-08-06 15:17:01,950] loss: 0.019708  [ 3840/ 4749]
[2022-08-06 15:17:02,340] Train Error: Accuracy: 99.600%, Avg loss: 0.026150
[2022-08-06 15:17:02,450] Test  Error: Accuracy: 99.164%, Avg loss: 0.041094
[2022-08-06 15:17:02,451] Epoch 8---------------
[2022-08-06 15:17:02,452] lr: 7.547072e-04
[2022-08-06 15:17:02,463] loss: 0.020278  [    0/ 4749]
[2022-08-06 15:17:02,613] loss: 0.010422  [  960/ 4749]
[2022-08-06 15:17:02,762] loss: 0.011374  [ 1920/ 4749]
[2022-08-06 15:17:02,913] loss: 0.015801  [ 2880/ 4749]
[2022-08-06 15:17:03,063] loss: 0.038987  [ 3840/ 4749]
[2022-08-06 15:17:03,454] Train Error: Accuracy: 99.642%, Avg loss: 0.024327
[2022-08-06 15:17:03,562] Test  Error: Accuracy: 99.017%, Avg loss: 0.036824
[2022-08-06 15:17:03,563] Epoch 9---------------
[2022-08-06 15:17:03,564] lr: 7.169718e-04
[2022-08-06 15:17:03,575] loss: 0.013630  [    0/ 4749]
[2022-08-06 15:17:03,721] loss: 0.023283  [  960/ 4749]
[2022-08-06 15:17:03,871] loss: 0.015791  [ 1920/ 4749]
[2022-08-06 15:17:04,020] loss: 0.048311  [ 2880/ 4749]
[2022-08-06 15:17:04,169] loss: 0.015552  [ 3840/ 4749]
[2022-08-06 15:17:04,564] Train Error: Accuracy: 99.810%, Avg loss: 0.020861
[2022-08-06 15:17:04,674] Test  Error: Accuracy: 99.115%, Avg loss: 0.038587
[2022-08-06 15:17:04,674] Epoch 10---------------
[2022-08-06 15:17:04,675] lr: 6.147137e-04
[2022-08-06 15:17:04,688] loss: 0.028726  [    0/ 4749]
[2022-08-06 15:17:04,834] loss: 0.025074  [  960/ 4749]
[2022-08-06 15:17:04,986] loss: 0.016348  [ 1920/ 4749]
[2022-08-06 15:17:05,133] loss: 0.005699  [ 2880/ 4749]
[2022-08-06 15:17:05,280] loss: 0.011236  [ 3840/ 4749]
[2022-08-06 15:17:05,671] Train Error: Accuracy: 99.537%, Avg loss: 0.020851
[2022-08-06 15:17:05,782] Test  Error: Accuracy: 99.263%, Avg loss: 0.035471
[2022-08-06 15:17:05,782] Done!
[2022-08-06 15:17:05,784] Number of parameters:42954
[2022-08-06 15:17:05,784] ## end time: 2022-08-06 15:17:05.782781
[2022-08-06 15:17:05,784] ## used time: 0:00:11.499556
