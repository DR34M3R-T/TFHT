[2022-08-06 15:21:48,450] ## start time: 2022-08-06 15:21:48.329434
[2022-08-06 15:21:48,450] Using cuda device
[2022-08-06 15:21:48,451] In train:p&d10.npy.
[2022-08-06 15:21:48,453] One Channel
[2022-08-06 15:21:48,453] With Normal data.
[2022-08-06 15:21:48,453] Nunber of classes:10.
[2022-08-06 15:21:48,454] Nunber of ViT channels:1.
[2022-08-06 15:21:48,644] Totol epochs: 10
[2022-08-06 15:21:48,645] Epoch 1---------------
[2022-08-06 15:21:48,645] lr: 2.000000e-03
[2022-08-06 15:21:48,658] loss: 2.525767  [    0/ 4744]
[2022-08-06 15:21:48,823] loss: 1.895939  [  960/ 4744]
[2022-08-06 15:21:48,988] loss: 1.553905  [ 1920/ 4744]
[2022-08-06 15:21:49,148] loss: 1.098548  [ 2880/ 4744]
[2022-08-06 15:21:49,299] loss: 1.135497  [ 3840/ 4744]
[2022-08-06 15:21:49,753] Train Error: Accuracy: 85.076%, Avg loss: 0.580167
[2022-08-06 15:21:49,871] Test  Error: Accuracy: 84.895%, Avg loss: 0.587330
[2022-08-06 15:21:49,872] Epoch 2---------------
[2022-08-06 15:21:49,873] lr: 1.900000e-03
[2022-08-06 15:21:49,884] loss: 0.523003  [    0/ 4744]
[2022-08-06 15:21:50,040] loss: 0.325808  [  960/ 4744]
[2022-08-06 15:21:50,196] loss: 0.208744  [ 1920/ 4744]
[2022-08-06 15:21:50,348] loss: 0.207469  [ 2880/ 4744]
[2022-08-06 15:21:50,503] loss: 0.207354  [ 3840/ 4744]
[2022-08-06 15:21:50,909] Train Error: Accuracy: 98.229%, Avg loss: 0.104682
[2022-08-06 15:21:51,023] Test  Error: Accuracy: 97.793%, Avg loss: 0.113654
[2022-08-06 15:21:51,024] Epoch 3---------------
[2022-08-06 15:21:51,025] lr: 1.805000e-03
[2022-08-06 15:21:51,038] loss: 0.101062  [    0/ 4744]
[2022-08-06 15:21:51,189] loss: 0.063360  [  960/ 4744]
[2022-08-06 15:21:51,340] loss: 0.163463  [ 1920/ 4744]
[2022-08-06 15:21:51,490] loss: 0.150980  [ 2880/ 4744]
[2022-08-06 15:21:51,642] loss: 0.056794  [ 3840/ 4744]
[2022-08-06 15:21:52,045] Train Error: Accuracy: 93.128%, Avg loss: 0.356485
[2022-08-06 15:21:52,157] Test  Error: Accuracy: 91.810%, Avg loss: 0.363200
[2022-08-06 15:21:52,158] Epoch 4---------------
[2022-08-06 15:21:52,159] lr: 1.260499e-03
[2022-08-06 15:21:52,172] loss: 0.432309  [    0/ 4744]
[2022-08-06 15:21:52,325] loss: 0.104328  [  960/ 4744]
[2022-08-06 15:21:52,474] loss: 0.041394  [ 1920/ 4744]
[2022-08-06 15:21:52,627] loss: 0.043747  [ 2880/ 4744]
[2022-08-06 15:21:52,779] loss: 0.048041  [ 3840/ 4744]
[2022-08-06 15:21:53,181] Train Error: Accuracy: 97.597%, Avg loss: 0.079376
[2022-08-06 15:21:53,293] Test  Error: Accuracy: 96.910%, Avg loss: 0.102924
[2022-08-06 15:21:53,294] Epoch 5---------------
[2022-08-06 15:21:53,296] lr: 1.197474e-03
[2022-08-06 15:21:53,307] loss: 0.045669  [    0/ 4744]
[2022-08-06 15:21:53,463] loss: 0.017188  [  960/ 4744]
[2022-08-06 15:21:53,613] loss: 0.018822  [ 1920/ 4744]
[2022-08-06 15:21:53,766] loss: 0.018909  [ 2880/ 4744]
[2022-08-06 15:21:53,918] loss: 0.019084  [ 3840/ 4744]
[2022-08-06 15:21:54,327] Train Error: Accuracy: 99.747%, Avg loss: 0.026293
[2022-08-06 15:21:54,440] Test  Error: Accuracy: 99.068%, Avg loss: 0.045135
[2022-08-06 15:21:54,440] Epoch 6---------------
[2022-08-06 15:21:54,441] lr: 1.137600e-03
[2022-08-06 15:21:54,454] loss: 0.030671  [    0/ 4744]
[2022-08-06 15:21:54,608] loss: 0.014416  [  960/ 4744]
[2022-08-06 15:21:54,759] loss: 0.014631  [ 1920/ 4744]
[2022-08-06 15:21:54,910] loss: 0.022313  [ 2880/ 4744]
[2022-08-06 15:21:55,059] loss: 0.017115  [ 3840/ 4744]
[2022-08-06 15:21:55,463] Train Error: Accuracy: 99.768%, Avg loss: 0.014261
[2022-08-06 15:21:55,581] Test  Error: Accuracy: 99.706%, Avg loss: 0.022393
[2022-08-06 15:21:55,581] Epoch 7---------------
[2022-08-06 15:21:55,582] lr: 1.080720e-03
[2022-08-06 15:21:55,594] loss: 0.009747  [    0/ 4744]
[2022-08-06 15:21:55,745] loss: 0.014015  [  960/ 4744]
[2022-08-06 15:21:55,896] loss: 0.020896  [ 1920/ 4744]
[2022-08-06 15:21:56,046] loss: 0.039037  [ 2880/ 4744]
[2022-08-06 15:21:56,195] loss: 0.029117  [ 3840/ 4744]
[2022-08-06 15:21:56,596] Train Error: Accuracy: 99.916%, Avg loss: 0.010253
[2022-08-06 15:21:56,709] Test  Error: Accuracy: 99.657%, Avg loss: 0.020315
[2022-08-06 15:21:56,709] Epoch 8---------------
[2022-08-06 15:21:56,710] lr: 1.026684e-03
[2022-08-06 15:21:56,722] loss: 0.010598  [    0/ 4744]
[2022-08-06 15:21:56,877] loss: 0.006042  [  960/ 4744]
[2022-08-06 15:21:57,027] loss: 0.009422  [ 1920/ 4744]
[2022-08-06 15:21:57,178] loss: 0.006118  [ 2880/ 4744]
[2022-08-06 15:21:57,327] loss: 0.011949  [ 3840/ 4744]
[2022-08-06 15:21:57,726] Train Error: Accuracy: 99.937%, Avg loss: 0.008665
[2022-08-06 15:21:57,838] Test  Error: Accuracy: 99.853%, Avg loss: 0.011748
[2022-08-06 15:21:57,839] Epoch 9---------------
[2022-08-06 15:21:57,840] lr: 9.753500e-04
[2022-08-06 15:21:57,851] loss: 0.008212  [    0/ 4744]
[2022-08-06 15:21:58,003] loss: 0.009245  [  960/ 4744]
[2022-08-06 15:21:58,152] loss: 0.019905  [ 1920/ 4744]
[2022-08-06 15:21:58,303] loss: 0.004257  [ 2880/ 4744]
[2022-08-06 15:21:58,453] loss: 0.004974  [ 3840/ 4744]
[2022-08-06 15:21:58,852] Train Error: Accuracy: 99.852%, Avg loss: 0.009322
[2022-08-06 15:21:58,966] Test  Error: Accuracy: 99.657%, Avg loss: 0.015052
[2022-08-06 15:21:58,966] Epoch 10---------------
[2022-08-06 15:21:58,968] lr: 6.811233e-04
[2022-08-06 15:21:58,979] loss: 0.005031  [    0/ 4744]
[2022-08-06 15:21:59,132] loss: 0.004575  [  960/ 4744]
[2022-08-06 15:21:59,282] loss: 0.009330  [ 1920/ 4744]
[2022-08-06 15:21:59,432] loss: 0.003566  [ 2880/ 4744]
[2022-08-06 15:21:59,582] loss: 0.005261  [ 3840/ 4744]
[2022-08-06 15:21:59,984] Train Error: Accuracy: 99.937%, Avg loss: 0.006991
[2022-08-06 15:22:00,107] Test  Error: Accuracy: 99.755%, Avg loss: 0.011041
[2022-08-06 15:22:00,107] Done!
[2022-08-06 15:22:00,109] Number of parameters:42954
[2022-08-06 15:22:00,109] ## end time: 2022-08-06 15:22:00.107031
[2022-08-06 15:22:00,110] ## used time: 0:00:11.777597
