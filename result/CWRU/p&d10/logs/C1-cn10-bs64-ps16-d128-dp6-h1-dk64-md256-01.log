[2022-08-06 15:56:26,958] ## start time: 2022-08-06 15:56:26.816916
[2022-08-06 15:56:26,958] Using cuda device
[2022-08-06 15:56:26,959] In train:p&d10.npy.
[2022-08-06 15:56:26,959] One Channel
[2022-08-06 15:56:26,959] With Normal data.
[2022-08-06 15:56:26,959] Nunber of classes:10.
[2022-08-06 15:56:26,960] Nunber of ViT channels:1.
[2022-08-06 15:56:28,032] Totol epochs: 15
[2022-08-06 15:56:28,035] Epoch 1---------------
[2022-08-06 15:56:28,035] lr: 2.000000e-03
[2022-08-06 15:56:30,098] loss: 2.465408  [    0/ 4703]
[2022-08-06 15:56:37,585] loss: 1.748486  [  960/ 4703]
[2022-08-06 15:56:45,071] loss: 1.697081  [ 1920/ 4703]
[2022-08-06 15:56:52,482] loss: 1.424677  [ 2880/ 4703]
[2022-08-06 15:56:59,893] loss: 0.983093  [ 3840/ 4703]
[2022-08-06 15:57:20,224] Train Error: Accuracy: 72.060%, Avg loss: 0.719507
[2022-08-06 15:57:26,505] Test  Error: Accuracy: 71.298%, Avg loss: 0.717912
[2022-08-06 15:57:26,506] Epoch 2---------------
[2022-08-06 15:57:26,506] lr: 1.900000e-03
[2022-08-06 15:57:27,005] loss: 0.731133  [    0/ 4703]
[2022-08-06 15:57:34,465] loss: 0.775168  [  960/ 4703]
[2022-08-06 15:57:41,925] loss: 0.204362  [ 1920/ 4703]
[2022-08-06 15:57:49,384] loss: 0.237963  [ 2880/ 4703]
[2022-08-06 15:57:56,843] loss: 0.246058  [ 3840/ 4703]
[2022-08-06 15:58:17,305] Train Error: Accuracy: 88.837%, Avg loss: 0.338172
[2022-08-06 15:58:23,613] Test  Error: Accuracy: 87.837%, Avg loss: 0.365853
[2022-08-06 15:58:23,614] Epoch 3---------------
[2022-08-06 15:58:23,615] lr: 1.805000e-03
[2022-08-06 15:58:24,117] loss: 0.268279  [    0/ 4703]
[2022-08-06 15:58:31,606] loss: 0.274008  [  960/ 4703]
[2022-08-06 15:58:39,095] loss: 0.075609  [ 1920/ 4703]
[2022-08-06 15:58:46,583] loss: 0.032897  [ 2880/ 4703]
[2022-08-06 15:58:54,072] loss: 0.182120  [ 3840/ 4703]
[2022-08-06 15:59:14,575] Train Error: Accuracy: 92.282%, Avg loss: 0.235796
[2022-08-06 15:59:20,882] Test  Error: Accuracy: 91.346%, Avg loss: 0.276253
[2022-08-06 15:59:20,882] Epoch 4---------------
[2022-08-06 15:59:20,883] lr: 1.714750e-03
[2022-08-06 15:59:21,385] loss: 0.289932  [    0/ 4703]
[2022-08-06 15:59:28,875] loss: 0.220953  [  960/ 4703]
[2022-08-06 15:59:36,363] loss: 0.469741  [ 1920/ 4703]
[2022-08-06 15:59:43,853] loss: 0.116179  [ 2880/ 4703]
[2022-08-06 15:59:51,341] loss: 0.044016  [ 3840/ 4703]
[2022-08-06 16:00:11,841] Train Error: Accuracy: 97.491%, Avg loss: 0.080883
[2022-08-06 16:00:18,145] Test  Error: Accuracy: 97.212%, Avg loss: 0.090496
[2022-08-06 16:00:18,145] Epoch 5---------------
[2022-08-06 16:00:18,146] lr: 1.629012e-03
[2022-08-06 16:00:18,650] loss: 0.068993  [    0/ 4703]
[2022-08-06 16:00:26,141] loss: 0.074790  [  960/ 4703]
[2022-08-06 16:00:33,630] loss: 0.071098  [ 1920/ 4703]
[2022-08-06 16:00:41,158] loss: 0.175349  [ 2880/ 4703]
[2022-08-06 16:00:48,700] loss: 0.083326  [ 3840/ 4703]
[2022-08-06 16:01:09,347] Train Error: Accuracy: 98.554%, Avg loss: 0.051415
[2022-08-06 16:01:15,695] Test  Error: Accuracy: 98.317%, Avg loss: 0.077411
[2022-08-06 16:01:15,695] Epoch 6---------------
[2022-08-06 16:01:15,696] lr: 1.547562e-03
[2022-08-06 16:01:16,202] loss: 0.034965  [    0/ 4703]
[2022-08-06 16:01:23,742] loss: 0.037616  [  960/ 4703]
[2022-08-06 16:01:31,283] loss: 0.011322  [ 1920/ 4703]
[2022-08-06 16:01:38,825] loss: 0.042188  [ 2880/ 4703]
[2022-08-06 16:01:46,365] loss: 0.013324  [ 3840/ 4703]
[2022-08-06 16:02:06,991] Train Error: Accuracy: 95.216%, Avg loss: 0.136588
[2022-08-06 16:02:13,334] Test  Error: Accuracy: 94.567%, Avg loss: 0.145845
[2022-08-06 16:02:13,335] Epoch 7---------------
[2022-08-06 16:02:13,338] lr: 1.080720e-03
[2022-08-06 16:02:13,843] loss: 0.140754  [    0/ 4703]
[2022-08-06 16:02:21,382] loss: 0.102302  [  960/ 4703]
[2022-08-06 16:02:28,921] loss: 0.033228  [ 1920/ 4703]
[2022-08-06 16:02:36,460] loss: 0.009131  [ 2880/ 4703]
[2022-08-06 16:02:44,000] loss: 0.075553  [ 3840/ 4703]
[2022-08-06 16:03:04,637] Train Error: Accuracy: 99.490%, Avg loss: 0.021509
[2022-08-06 16:03:10,982] Test  Error: Accuracy: 98.750%, Avg loss: 0.046309
[2022-08-06 16:03:10,982] Epoch 8---------------
[2022-08-06 16:03:10,983] lr: 1.026684e-03
[2022-08-06 16:03:11,490] loss: 0.012908  [    0/ 4703]
[2022-08-06 16:03:19,031] loss: 0.011935  [  960/ 4703]
[2022-08-06 16:03:26,573] loss: 0.005293  [ 1920/ 4703]
[2022-08-06 16:03:34,114] loss: 0.008215  [ 2880/ 4703]
[2022-08-06 16:03:41,653] loss: 0.006687  [ 3840/ 4703]
[2022-08-06 16:04:02,291] Train Error: Accuracy: 97.023%, Avg loss: 0.096991
[2022-08-06 16:04:08,640] Test  Error: Accuracy: 96.490%, Avg loss: 0.127447
[2022-08-06 16:04:08,641] Epoch 9---------------
[2022-08-06 16:04:08,642] lr: 7.169718e-04
[2022-08-06 16:04:09,148] loss: 0.059451  [    0/ 4703]
[2022-08-06 16:04:16,688] loss: 0.005393  [  960/ 4703]
[2022-08-06 16:04:24,227] loss: 0.008830  [ 1920/ 4703]
[2022-08-06 16:04:31,768] loss: 0.002683  [ 2880/ 4703]
[2022-08-06 16:04:39,310] loss: 0.009084  [ 3840/ 4703]
[2022-08-06 16:04:59,953] Train Error: Accuracy: 99.894%, Avg loss: 0.008344
[2022-08-06 16:05:06,301] Test  Error: Accuracy: 99.279%, Avg loss: 0.030472
[2022-08-06 16:05:06,301] Epoch 10---------------
[2022-08-06 16:05:06,304] lr: 6.811233e-04
[2022-08-06 16:05:06,808] loss: 0.002042  [    0/ 4703]
[2022-08-06 16:05:14,348] loss: 0.004474  [  960/ 4703]
[2022-08-06 16:05:21,887] loss: 0.007488  [ 1920/ 4703]
[2022-08-06 16:05:29,428] loss: 0.002902  [ 2880/ 4703]
[2022-08-06 16:05:36,968] loss: 0.002437  [ 3840/ 4703]
[2022-08-06 16:05:57,603] Train Error: Accuracy: 99.851%, Avg loss: 0.007653
[2022-08-06 16:06:03,951] Test  Error: Accuracy: 99.423%, Avg loss: 0.026831
[2022-08-06 16:06:03,951] Epoch 11---------------
[2022-08-06 16:06:03,952] lr: 6.470671e-04
[2022-08-06 16:06:04,458] loss: 0.002226  [    0/ 4703]
[2022-08-06 16:06:11,999] loss: 0.006157  [  960/ 4703]
[2022-08-06 16:06:19,541] loss: 0.017737  [ 1920/ 4703]
[2022-08-06 16:06:27,080] loss: 0.008018  [ 2880/ 4703]
[2022-08-06 16:06:34,621] loss: 0.011342  [ 3840/ 4703]
[2022-08-06 16:06:55,261] Train Error: Accuracy: 98.873%, Avg loss: 0.034999
[2022-08-06 16:07:01,608] Test  Error: Accuracy: 98.942%, Avg loss: 0.045486
[2022-08-06 16:07:01,609] Epoch 12---------------
[2022-08-06 16:07:01,610] lr: 4.518711e-04
[2022-08-06 16:07:02,115] loss: 0.020018  [    0/ 4703]
[2022-08-06 16:07:09,655] loss: 0.005848  [  960/ 4703]
[2022-08-06 16:07:17,195] loss: 0.003222  [ 1920/ 4703]
[2022-08-06 16:07:24,735] loss: 0.006906  [ 2880/ 4703]
[2022-08-06 16:07:32,275] loss: 0.002014  [ 3840/ 4703]
[2022-08-06 16:07:52,915] Train Error: Accuracy: 99.915%, Avg loss: 0.005235
[2022-08-06 16:07:59,266] Test  Error: Accuracy: 99.135%, Avg loss: 0.031183
[2022-08-06 16:07:59,266] Epoch 13---------------
[2022-08-06 16:07:59,267] lr: 4.292775e-04
[2022-08-06 16:07:59,773] loss: 0.002637  [    0/ 4703]
[2022-08-06 16:08:07,312] loss: 0.006217  [  960/ 4703]
[2022-08-06 16:08:14,852] loss: 0.001992  [ 1920/ 4703]
[2022-08-06 16:08:22,395] loss: 0.002231  [ 2880/ 4703]
[2022-08-06 16:08:29,934] loss: 0.007107  [ 3840/ 4703]
[2022-08-06 16:08:50,584] Train Error: Accuracy: 99.957%, Avg loss: 0.004115
[2022-08-06 16:08:56,934] Test  Error: Accuracy: 99.423%, Avg loss: 0.025739
[2022-08-06 16:08:56,934] Epoch 14---------------
[2022-08-06 16:08:56,935] lr: 4.078137e-04
[2022-08-06 16:08:57,442] loss: 0.005344  [    0/ 4703]
[2022-08-06 16:09:04,982] loss: 0.001648  [  960/ 4703]
[2022-08-06 16:09:12,523] loss: 0.001079  [ 1920/ 4703]
[2022-08-06 16:09:20,063] loss: 0.005359  [ 2880/ 4703]
[2022-08-06 16:09:27,604] loss: 0.001608  [ 3840/ 4703]
[2022-08-06 16:09:48,237] Train Error: Accuracy: 99.894%, Avg loss: 0.003963
[2022-08-06 16:09:54,581] Test  Error: Accuracy: 99.471%, Avg loss: 0.020774
[2022-08-06 16:09:54,582] Epoch 15---------------
[2022-08-06 16:09:54,583] lr: 3.874230e-04
[2022-08-06 16:09:55,088] loss: 0.001801  [    0/ 4703]
[2022-08-06 16:10:02,630] loss: 0.000814  [  960/ 4703]
[2022-08-06 16:10:10,169] loss: 0.001356  [ 1920/ 4703]
[2022-08-06 16:10:17,711] loss: 0.002473  [ 2880/ 4703]
[2022-08-06 16:10:25,254] loss: 0.019958  [ 3840/ 4703]
[2022-08-06 16:10:45,901] Train Error: Accuracy: 99.766%, Avg loss: 0.007656
[2022-08-06 16:10:52,249] Test  Error: Accuracy: 99.231%, Avg loss: 0.027953
[2022-08-06 16:10:52,250] Done!
[2022-08-06 16:10:52,256] Number of parameters:1232650
[2022-08-06 16:10:52,256] ## end time: 2022-08-06 16:10:52.250754
[2022-08-06 16:10:52,257] ## used time: 0:14:25.433838
