[2022-08-06 19:52:50,315] ## start time: 2022-08-06 19:52:50.176499
[2022-08-06 19:52:50,316] Using cuda device
[2022-08-06 19:52:50,317] In train:p&d10.npy.
[2022-08-06 19:52:50,318] One Channel
[2022-08-06 19:52:50,319] With Normal data.
[2022-08-06 19:52:50,319] Nunber of classes:10.
[2022-08-06 19:52:50,320] Nunber of ViT channels:1.
[2022-08-06 19:52:50,559] Totol epochs: 15
[2022-08-06 19:52:50,562] Epoch 1---------------
[2022-08-06 19:52:50,562] lr: 2.000000e-03
[2022-08-06 19:52:51,648] loss: 2.376070  [    0/ 4710]
[2022-08-06 19:53:07,906] loss: 1.751564  [  960/ 4710]
[2022-08-06 19:53:24,164] loss: 1.639168  [ 1920/ 4710]
[2022-08-06 19:53:40,479] loss: 1.013678  [ 2880/ 4710]
[2022-08-06 19:53:56,802] loss: 0.621567  [ 3840/ 4710]
[2022-08-06 19:54:40,246] Train Error: Accuracy: 76.858%, Avg loss: 0.640676
[2022-08-06 19:54:53,337] Test  Error: Accuracy: 75.446%, Avg loss: 0.670548
[2022-08-06 19:54:53,338] Epoch 2---------------
[2022-08-06 19:54:53,340] lr: 1.900000e-03
[2022-08-06 19:54:54,429] loss: 0.714542  [    0/ 4710]
[2022-08-06 19:55:10,751] loss: 0.284098  [  960/ 4710]
[2022-08-06 19:55:27,074] loss: 0.182341  [ 1920/ 4710]
[2022-08-06 19:55:43,394] loss: 0.077101  [ 2880/ 4710]
[2022-08-06 19:55:59,716] loss: 0.148090  [ 3840/ 4710]
[2022-08-06 19:56:43,159] Train Error: Accuracy: 98.981%, Avg loss: 0.050560
[2022-08-06 19:56:56,245] Test  Error: Accuracy: 98.842%, Avg loss: 0.062475
[2022-08-06 19:56:56,245] Epoch 3---------------
[2022-08-06 19:56:56,246] lr: 1.805000e-03
[2022-08-06 19:56:57,336] loss: 0.038862  [    0/ 4710]
[2022-08-06 19:57:13,659] loss: 0.020394  [  960/ 4710]
[2022-08-06 19:57:29,982] loss: 0.068762  [ 1920/ 4710]
[2022-08-06 19:57:46,302] loss: 0.019468  [ 2880/ 4710]
[2022-08-06 19:58:02,624] loss: 0.430791  [ 3840/ 4710]
[2022-08-06 19:58:46,067] Train Error: Accuracy: 91.635%, Avg loss: 0.270069
[2022-08-06 19:58:59,156] Test  Error: Accuracy: 91.027%, Avg loss: 0.277647
[2022-08-06 19:58:59,157] Epoch 4---------------
[2022-08-06 19:58:59,158] lr: 1.260499e-03
[2022-08-06 19:59:00,248] loss: 0.206365  [    0/ 4710]
[2022-08-06 19:59:16,575] loss: 0.097712  [  960/ 4710]
[2022-08-06 19:59:32,901] loss: 0.032710  [ 1920/ 4710]
[2022-08-06 19:59:49,228] loss: 0.058369  [ 2880/ 4710]
[2022-08-06 20:00:05,550] loss: 0.030753  [ 3840/ 4710]
[2022-08-06 20:00:48,992] Train Error: Accuracy: 99.682%, Avg loss: 0.020502
[2022-08-06 20:04:10,282] Test  Error: Accuracy: 99.083%, Avg loss: 0.033300
[2022-08-06 20:04:10,283] Epoch 5---------------
[2022-08-06 20:04:10,284] lr: 1.197474e-03
[2022-08-06 20:04:11,359] loss: 0.016194  [    0/ 4710]
[2022-08-06 20:04:27,464] loss: 0.070495  [  960/ 4710]
[2022-08-06 20:04:43,609] loss: 0.010456  [ 1920/ 4710]
[2022-08-06 20:04:59,756] loss: 0.030462  [ 2880/ 4710]
[2022-08-06 20:05:15,953] loss: 0.008124  [ 3840/ 4710]
[2022-08-06 20:05:59,217] Train Error: Accuracy: 99.427%, Avg loss: 0.028778
[2022-08-06 20:06:12,250] Test  Error: Accuracy: 98.746%, Avg loss: 0.049715
[2022-08-06 20:06:12,250] Epoch 6---------------
[2022-08-06 20:06:12,251] lr: 8.362407e-04
[2022-08-06 20:06:13,337] loss: 0.029224  [    0/ 4710]
[2022-08-06 20:06:29,594] loss: 0.037351  [  960/ 4710]
[2022-08-06 20:06:45,850] loss: 0.013845  [ 1920/ 4710]
[2022-08-06 20:07:02,108] loss: 0.026553  [ 2880/ 4710]
[2022-08-06 20:07:18,365] loss: 0.046033  [ 3840/ 4710]
[2022-08-06 20:08:01,631] Train Error: Accuracy: 99.724%, Avg loss: 0.012299
[2022-08-06 20:08:14,662] Test  Error: Accuracy: 99.662%, Avg loss: 0.018267
[2022-08-06 20:08:14,662] Epoch 7---------------
[2022-08-06 20:08:14,663] lr: 7.944286e-04
[2022-08-06 20:08:15,750] loss: 0.007539  [    0/ 4710]
[2022-08-06 20:08:32,008] loss: 0.002843  [  960/ 4710]
[2022-08-06 20:08:48,264] loss: 0.003029  [ 1920/ 4710]
[2022-08-06 20:09:04,520] loss: 0.001221  [ 2880/ 4710]
[2022-08-06 20:09:20,776] loss: 0.012086  [ 3840/ 4710]
[2022-08-06 20:10:04,051] Train Error: Accuracy: 99.894%, Avg loss: 0.005333
[2022-08-06 20:10:17,133] Test  Error: Accuracy: 99.325%, Avg loss: 0.025061
[2022-08-06 20:10:17,134] Epoch 8---------------
[2022-08-06 20:10:17,135] lr: 5.547791e-04
[2022-08-06 20:10:18,225] loss: 0.002935  [    0/ 4710]
[2022-08-06 20:10:34,548] loss: 0.001552  [  960/ 4710]
[2022-08-06 20:10:50,870] loss: 0.047287  [ 1920/ 4710]
[2022-08-06 20:11:07,192] loss: 0.006277  [ 2880/ 4710]
[2022-08-06 20:11:23,514] loss: 0.001726  [ 3840/ 4710]
[2022-08-06 20:12:06,952] Train Error: Accuracy: 99.915%, Avg loss: 0.004200
[2022-08-06 20:12:20,032] Test  Error: Accuracy: 99.518%, Avg loss: 0.018488
[2022-08-06 20:12:20,033] Epoch 9---------------
[2022-08-06 20:12:20,035] lr: 5.270402e-04
[2022-08-06 20:12:21,125] loss: 0.003724  [    0/ 4710]
[2022-08-06 20:12:37,446] loss: 0.004959  [  960/ 4710]
[2022-08-06 20:12:53,767] loss: 0.011144  [ 1920/ 4710]
[2022-08-06 20:13:10,093] loss: 0.004001  [ 2880/ 4710]
[2022-08-06 20:13:26,415] loss: 0.005137  [ 3840/ 4710]
[2022-08-06 20:14:09,854] Train Error: Accuracy: 99.979%, Avg loss: 0.003568
[2022-08-06 20:14:22,935] Test  Error: Accuracy: 99.421%, Avg loss: 0.016391
[2022-08-06 20:14:22,936] Epoch 10---------------
[2022-08-06 20:14:22,937] lr: 5.006882e-04
[2022-08-06 20:14:24,027] loss: 0.001241  [    0/ 4710]
[2022-08-06 20:14:40,349] loss: 0.002443  [  960/ 4710]
[2022-08-06 20:14:56,672] loss: 0.003157  [ 1920/ 4710]
[2022-08-06 20:15:12,993] loss: 0.001756  [ 2880/ 4710]
[2022-08-06 20:15:29,315] loss: 0.002214  [ 3840/ 4710]
[2022-08-06 20:16:12,747] Train Error: Accuracy: 99.979%, Avg loss: 0.002794
[2022-08-06 20:16:25,840] Test  Error: Accuracy: 99.662%, Avg loss: 0.016486
[2022-08-06 20:16:25,840] Epoch 11---------------
[2022-08-06 20:16:25,841] lr: 4.292775e-04
[2022-08-06 20:16:26,932] loss: 0.002317  [    0/ 4710]
[2022-08-06 20:16:43,256] loss: 0.004636  [  960/ 4710]
[2022-08-06 20:16:59,580] loss: 0.001541  [ 1920/ 4710]
[2022-08-06 20:17:15,902] loss: 0.001789  [ 2880/ 4710]
[2022-08-06 20:17:32,225] loss: 0.002035  [ 3840/ 4710]
[2022-08-06 20:18:15,658] Train Error: Accuracy: 99.979%, Avg loss: 0.002303
[2022-08-06 20:18:28,744] Test  Error: Accuracy: 99.807%, Avg loss: 0.013433
[2022-08-06 20:18:28,744] Epoch 12---------------
[2022-08-06 20:18:28,745] lr: 4.078137e-04
[2022-08-06 20:18:29,835] loss: 0.003063  [    0/ 4710]
[2022-08-06 20:18:46,159] loss: 0.001222  [  960/ 4710]
[2022-08-06 20:19:02,483] loss: 0.004507  [ 1920/ 4710]
[2022-08-06 20:19:18,805] loss: 0.001050  [ 2880/ 4710]
[2022-08-06 20:19:35,127] loss: 0.004682  [ 3840/ 4710]
[2022-08-06 20:20:18,562] Train Error: Accuracy: 99.979%, Avg loss: 0.002250
[2022-08-06 20:20:31,648] Test  Error: Accuracy: 99.807%, Avg loss: 0.010817
[2022-08-06 20:20:31,648] Epoch 13---------------
[2022-08-06 20:20:31,649] lr: 3.874230e-04
[2022-08-06 20:20:32,740] loss: 0.001889  [    0/ 4710]
[2022-08-06 20:20:49,062] loss: 0.002895  [  960/ 4710]
[2022-08-06 20:21:05,385] loss: 0.001480  [ 1920/ 4710]
[2022-08-06 20:21:21,708] loss: 0.001189  [ 2880/ 4710]
[2022-08-06 20:21:38,031] loss: 0.001294  [ 3840/ 4710]
[2022-08-06 20:22:21,465] Train Error: Accuracy: 99.809%, Avg loss: 0.005816
[2022-08-06 20:22:34,547] Test  Error: Accuracy: 99.469%, Avg loss: 0.018676
[2022-08-06 20:22:34,548] Epoch 14---------------
[2022-08-06 20:22:34,549] lr: 2.705519e-04
[2022-08-06 20:22:35,641] loss: 0.001487  [    0/ 4710]
[2022-08-06 20:22:51,963] loss: 0.003063  [  960/ 4710]
[2022-08-06 20:23:08,284] loss: 0.002272  [ 1920/ 4710]
[2022-08-06 20:23:24,605] loss: 0.004065  [ 2880/ 4710]
[2022-08-06 20:23:40,928] loss: 0.003604  [ 3840/ 4710]
[2022-08-06 20:24:24,371] Train Error: Accuracy: 99.915%, Avg loss: 0.003353
[2022-08-06 20:24:37,458] Test  Error: Accuracy: 99.614%, Avg loss: 0.013166
[2022-08-06 20:24:37,458] Epoch 15---------------
[2022-08-06 20:24:37,459] lr: 2.570243e-04
[2022-08-06 20:24:38,549] loss: 0.009383  [    0/ 4710]
[2022-08-06 20:24:54,870] loss: 0.003078  [  960/ 4710]
[2022-08-06 20:25:11,192] loss: 0.002413  [ 1920/ 4710]
[2022-08-06 20:25:27,512] loss: 0.015689  [ 2880/ 4710]
[2022-08-06 20:25:43,835] loss: 0.001139  [ 3840/ 4710]
[2022-08-06 20:26:27,269] Train Error: Accuracy: 99.979%, Avg loss: 0.002335
[2022-08-06 20:26:40,350] Test  Error: Accuracy: 99.518%, Avg loss: 0.015527
[2022-08-06 20:26:40,351] Done!
[2022-08-06 20:26:40,355] Number of parameters:2412298
[2022-08-06 20:26:40,355] ## end time: 2022-08-06 20:26:40.351984
[2022-08-06 20:26:40,356] ## used time: 0:33:50.175485
