[2022-08-07 15:10:31,179] ## start time: 2022-08-07 15:10:31.051122
[2022-08-07 15:10:31,179] Using cuda device
[2022-08-07 15:10:31,180] In train:p&d10.npy.
[2022-08-07 15:10:31,181] One Channel
[2022-08-07 15:10:31,182] With Normal data.
[2022-08-07 15:10:31,182] Nunber of classes:10.
[2022-08-07 15:10:31,183] Nunber of ViT channels:1.
[2022-08-07 15:10:31,392] Totol epochs: 15
[2022-08-07 15:10:31,393] Epoch 1---------------
[2022-08-07 15:10:31,394] lr: 2.000000e-03
[2022-08-07 15:10:31,898] loss: 2.315559  [    0/ 4778]
[2022-08-07 15:10:39,429] loss: 1.545393  [  960/ 4778]
[2022-08-07 15:10:46,961] loss: 1.177530  [ 1920/ 4778]
[2022-08-07 15:10:54,490] loss: 0.878069  [ 2880/ 4778]
[2022-08-07 15:11:02,021] loss: 0.282184  [ 3840/ 4778]
[2022-08-07 15:11:22,538] Train Error: Accuracy: 91.084%, Avg loss: 0.275474
[2022-08-07 15:11:28,273] Test  Error: Accuracy: 91.272%, Avg loss: 0.276188
[2022-08-07 15:11:28,274] Epoch 2---------------
[2022-08-07 15:11:28,275] lr: 1.900000e-03
[2022-08-07 15:11:28,780] loss: 0.204906  [    0/ 4778]
[2022-08-07 15:11:36,311] loss: 0.390476  [  960/ 4778]
[2022-08-07 15:11:43,841] loss: 0.103703  [ 1920/ 4778]
[2022-08-07 15:11:51,372] loss: 0.111923  [ 2880/ 4778]
[2022-08-07 15:11:58,903] loss: 0.044887  [ 3840/ 4778]
[2022-08-07 15:12:19,421] Train Error: Accuracy: 98.870%, Avg loss: 0.051552
[2022-08-07 15:12:25,156] Test  Error: Accuracy: 98.504%, Avg loss: 0.064372
[2022-08-07 15:12:25,156] Epoch 3---------------
[2022-08-07 15:12:25,158] lr: 1.805000e-03
[2022-08-07 15:12:25,662] loss: 0.078288  [    0/ 4778]
[2022-08-07 15:12:33,193] loss: 0.068725  [  960/ 4778]
[2022-08-07 15:12:40,723] loss: 0.114845  [ 1920/ 4778]
[2022-08-07 15:12:48,254] loss: 0.055467  [ 2880/ 4778]
[2022-08-07 15:12:55,784] loss: 0.058248  [ 3840/ 4778]
[2022-08-07 15:13:16,295] Train Error: Accuracy: 94.830%, Avg loss: 0.163942
[2022-08-07 15:13:22,027] Test  Error: Accuracy: 94.963%, Avg loss: 0.174147
[2022-08-07 15:13:22,027] Epoch 4---------------
[2022-08-07 15:13:22,028] lr: 1.260499e-03
[2022-08-07 15:13:22,533] loss: 0.077654  [    0/ 4778]
[2022-08-07 15:13:30,063] loss: 0.023781  [  960/ 4778]
[2022-08-07 15:13:37,594] loss: 0.013697  [ 1920/ 4778]
[2022-08-07 15:13:45,125] loss: 0.045273  [ 2880/ 4778]
[2022-08-07 15:13:52,656] loss: 0.009107  [ 3840/ 4778]
[2022-08-07 15:14:13,170] Train Error: Accuracy: 99.456%, Avg loss: 0.024298
[2022-08-07 15:14:18,904] Test  Error: Accuracy: 98.703%, Avg loss: 0.047987
[2022-08-07 15:14:18,904] Epoch 5---------------
[2022-08-07 15:14:18,905] lr: 1.197474e-03
[2022-08-07 15:14:19,409] loss: 0.016366  [    0/ 4778]
[2022-08-07 15:14:26,940] loss: 0.013941  [  960/ 4778]
[2022-08-07 15:14:34,470] loss: 0.004377  [ 1920/ 4778]
[2022-08-07 15:14:42,000] loss: 0.005429  [ 2880/ 4778]
[2022-08-07 15:14:49,528] loss: 0.007981  [ 3840/ 4778]
[2022-08-07 15:15:10,042] Train Error: Accuracy: 99.812%, Avg loss: 0.007767
[2022-08-07 15:15:15,774] Test  Error: Accuracy: 99.401%, Avg loss: 0.022013
[2022-08-07 15:15:15,774] Epoch 6---------------
[2022-08-07 15:15:15,775] lr: 1.137600e-03
[2022-08-07 15:15:16,279] loss: 0.015173  [    0/ 4778]
[2022-08-07 15:15:23,808] loss: 0.003108  [  960/ 4778]
[2022-08-07 15:15:31,338] loss: 0.005447  [ 1920/ 4778]
[2022-08-07 15:15:38,867] loss: 0.002842  [ 2880/ 4778]
[2022-08-07 15:15:46,397] loss: 0.003770  [ 3840/ 4778]
[2022-08-07 15:16:06,914] Train Error: Accuracy: 99.163%, Avg loss: 0.023657
[2022-08-07 15:16:12,647] Test  Error: Accuracy: 98.653%, Avg loss: 0.037686
[2022-08-07 15:16:12,648] Epoch 7---------------
[2022-08-07 15:16:12,649] lr: 7.944286e-04
[2022-08-07 15:16:13,155] loss: 0.001999  [    0/ 4778]
[2022-08-07 15:16:20,686] loss: 0.004170  [  960/ 4778]
[2022-08-07 15:16:28,216] loss: 0.013961  [ 1920/ 4778]
[2022-08-07 15:16:35,746] loss: 0.009777  [ 2880/ 4778]
[2022-08-07 15:16:43,278] loss: 0.001921  [ 3840/ 4778]
[2022-08-07 15:17:03,792] Train Error: Accuracy: 99.874%, Avg loss: 0.005966
[2022-08-07 15:17:09,525] Test  Error: Accuracy: 99.651%, Avg loss: 0.015733
[2022-08-07 15:17:09,525] Epoch 8---------------
[2022-08-07 15:17:09,526] lr: 7.547072e-04
[2022-08-07 15:17:10,031] loss: 0.002036  [    0/ 4778]
[2022-08-07 15:17:17,562] loss: 0.010799  [  960/ 4778]
[2022-08-07 15:17:25,092] loss: 0.001932  [ 1920/ 4778]
[2022-08-07 15:17:32,623] loss: 0.015445  [ 2880/ 4778]
[2022-08-07 15:17:40,154] loss: 0.017432  [ 3840/ 4778]
[2022-08-07 15:18:00,672] Train Error: Accuracy: 99.874%, Avg loss: 0.004790
[2022-08-07 15:18:06,406] Test  Error: Accuracy: 99.651%, Avg loss: 0.016226
[2022-08-07 15:18:06,407] Epoch 9---------------
[2022-08-07 15:18:06,408] lr: 6.470671e-04
[2022-08-07 15:18:06,912] loss: 0.006688  [    0/ 4778]
[2022-08-07 15:18:14,441] loss: 0.006068  [  960/ 4778]
[2022-08-07 15:18:21,972] loss: 0.003071  [ 1920/ 4778]
[2022-08-07 15:18:29,503] loss: 0.013524  [ 2880/ 4778]
[2022-08-07 15:18:37,033] loss: 0.006969  [ 3840/ 4778]
[2022-08-07 15:18:57,550] Train Error: Accuracy: 99.937%, Avg loss: 0.004738
[2022-08-07 15:19:03,284] Test  Error: Accuracy: 99.651%, Avg loss: 0.015665
[2022-08-07 15:19:03,284] Epoch 10---------------
[2022-08-07 15:19:03,285] lr: 6.147137e-04
[2022-08-07 15:19:03,790] loss: 0.001166  [    0/ 4778]
[2022-08-07 15:19:11,321] loss: 0.003679  [  960/ 4778]
[2022-08-07 15:19:18,850] loss: 0.001478  [ 1920/ 4778]
[2022-08-07 15:19:26,380] loss: 0.001019  [ 2880/ 4778]
[2022-08-07 15:19:33,911] loss: 0.002675  [ 3840/ 4778]
[2022-08-07 15:19:54,425] Train Error: Accuracy: 99.979%, Avg loss: 0.003491
[2022-08-07 15:20:00,158] Test  Error: Accuracy: 99.651%, Avg loss: 0.015400
[2022-08-07 15:20:00,158] Epoch 11---------------
[2022-08-07 15:20:00,159] lr: 5.839780e-04
[2022-08-07 15:20:00,664] loss: 0.004473  [    0/ 4778]
[2022-08-07 15:20:08,195] loss: 0.003223  [  960/ 4778]
[2022-08-07 15:20:15,723] loss: 0.001272  [ 1920/ 4778]
[2022-08-07 15:20:23,253] loss: 0.001297  [ 2880/ 4778]
[2022-08-07 15:20:30,783] loss: 0.059884  [ 3840/ 4778]
[2022-08-07 15:20:51,296] Train Error: Accuracy: 99.874%, Avg loss: 0.008096
[2022-08-07 15:20:57,030] Test  Error: Accuracy: 99.501%, Avg loss: 0.025532
[2022-08-07 15:20:57,030] Epoch 12---------------
[2022-08-07 15:20:57,031] lr: 4.078137e-04
[2022-08-07 15:20:57,536] loss: 0.015249  [    0/ 4778]
[2022-08-07 15:21:05,067] loss: 0.005259  [  960/ 4778]
[2022-08-07 15:21:12,597] loss: 0.001102  [ 1920/ 4778]
[2022-08-07 15:21:20,129] loss: 0.001423  [ 2880/ 4778]
[2022-08-07 15:21:27,658] loss: 0.013423  [ 3840/ 4778]
[2022-08-07 15:21:50,258] Train Error: Accuracy: 99.916%, Avg loss: 0.004505
[2022-08-07 15:21:55,989] Test  Error: Accuracy: 99.451%, Avg loss: 0.014604
[2022-08-07 15:21:55,990] Epoch 13---------------
[2022-08-07 15:21:55,991] lr: 3.874230e-04
[2022-08-07 15:21:56,496] loss: 0.003575  [    0/ 4778]
[2022-08-07 15:22:04,025] loss: 0.009954  [  960/ 4778]
[2022-08-07 15:22:11,557] loss: 0.001982  [ 1920/ 4778]
[2022-08-07 15:22:19,086] loss: 0.011886  [ 2880/ 4778]
[2022-08-07 15:22:26,617] loss: 0.002445  [ 3840/ 4778]
[2022-08-07 15:22:47,131] Train Error: Accuracy: 99.958%, Avg loss: 0.003391
[2022-08-07 15:22:52,864] Test  Error: Accuracy: 99.601%, Avg loss: 0.012197
[2022-08-07 15:22:52,864] Epoch 14---------------
[2022-08-07 15:22:52,866] lr: 3.680518e-04
[2022-08-07 15:22:53,371] loss: 0.024238  [    0/ 4778]
[2022-08-07 15:23:00,900] loss: 0.004737  [  960/ 4778]
[2022-08-07 15:23:08,432] loss: 0.001233  [ 1920/ 4778]
[2022-08-07 15:23:15,961] loss: 0.001189  [ 2880/ 4778]
[2022-08-07 15:23:23,492] loss: 0.002153  [ 3840/ 4778]
[2022-08-07 15:23:44,003] Train Error: Accuracy: 99.958%, Avg loss: 0.002929
[2022-08-07 15:23:49,738] Test  Error: Accuracy: 99.551%, Avg loss: 0.014139
[2022-08-07 15:23:49,738] Epoch 15---------------
[2022-08-07 15:23:49,739] lr: 2.847915e-04
[2022-08-07 15:23:50,243] loss: 0.000865  [    0/ 4778]
[2022-08-07 15:23:57,776] loss: 0.001006  [  960/ 4778]
[2022-08-07 15:24:05,306] loss: 0.002463  [ 1920/ 4778]
[2022-08-07 15:24:12,837] loss: 0.000824  [ 2880/ 4778]
[2022-08-07 15:24:20,367] loss: 0.000852  [ 3840/ 4778]
[2022-08-07 15:24:40,881] Train Error: Accuracy: 99.958%, Avg loss: 0.001892
[2022-08-07 15:24:46,615] Test  Error: Accuracy: 99.701%, Avg loss: 0.012439
[2022-08-07 15:24:46,615] Done!
[2022-08-07 15:24:46,618] Number of parameters:1093386
[2022-08-07 15:24:46,618] ## end time: 2022-08-07 15:24:46.615353
[2022-08-07 15:24:46,618] ## used time: 0:14:15.564231
