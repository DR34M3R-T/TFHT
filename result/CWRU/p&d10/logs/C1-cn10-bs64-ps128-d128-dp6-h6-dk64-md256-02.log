[2022-08-03 16:53:14,611] ## start time: 2022-08-03 16:53:14.457912
[2022-08-03 16:53:14,612] Using cuda device
[2022-08-03 16:53:14,613] In train:p&d10.npy.
[2022-08-03 16:53:14,613] One Channel
[2022-08-03 16:53:14,614] With Normal data.
[2022-08-03 16:53:14,614] Nunber of classes:10.
[2022-08-03 16:53:14,615] Nunber of ViT channels:1.
[2022-08-03 16:53:14,877] Totol epochs: 15
[2022-08-03 16:53:14,882] Epoch 1---------------
[2022-08-03 16:53:14,882] lr: 2.000000e-03
[2022-08-03 16:53:15,056] loss: 2.512479  [    0/ 4691]
[2022-08-03 16:53:17,638] loss: 1.853854  [  960/ 4691]
[2022-08-03 16:53:20,220] loss: 1.519131  [ 1920/ 4691]
[2022-08-03 16:53:22,800] loss: 0.428448  [ 2880/ 4691]
[2022-08-03 16:53:25,380] loss: 0.065523  [ 3840/ 4691]
[2022-08-03 16:53:29,413] Test Error: Accuracy: 99.809%, Avg loss: 0.031456
[2022-08-03 16:53:29,414] Epoch 2---------------
[2022-08-03 16:53:29,415] lr: 1.900000e-03
[2022-08-03 16:53:29,589] loss: 0.052570  [    0/ 4691]
[2022-08-03 16:53:32,170] loss: 0.018796  [  960/ 4691]
[2022-08-03 16:53:34,749] loss: 0.007418  [ 1920/ 4691]
[2022-08-03 16:53:37,329] loss: 0.022875  [ 2880/ 4691]
[2022-08-03 16:53:39,909] loss: 0.004488  [ 3840/ 4691]
[2022-08-03 16:53:43,949] Test Error: Accuracy: 68.499%, Avg loss: 1.197894
[2022-08-03 16:53:43,950] Epoch 3---------------
[2022-08-03 16:53:43,951] lr: 1.326841e-03
[2022-08-03 16:53:44,125] loss: 1.204976  [    0/ 4691]
[2022-08-03 16:53:46,708] loss: 0.032097  [  960/ 4691]
[2022-08-03 16:53:49,291] loss: 0.008708  [ 1920/ 4691]
[2022-08-03 16:53:51,872] loss: 0.008751  [ 2880/ 4691]
[2022-08-03 16:53:54,453] loss: 0.004876  [ 3840/ 4691]
[2022-08-03 16:53:58,488] Test Error: Accuracy: 100.000%, Avg loss: 0.005554
[2022-08-03 16:53:58,488] Epoch 4---------------
[2022-08-03 16:53:58,489] lr: 1.260499e-03
[2022-08-03 16:53:58,664] loss: 0.004169  [    0/ 4691]
[2022-08-03 16:54:01,247] loss: 0.003493  [  960/ 4691]
[2022-08-03 16:54:03,827] loss: 0.004096  [ 1920/ 4691]
[2022-08-03 16:54:06,409] loss: 0.002666  [ 2880/ 4691]
[2022-08-03 16:54:08,990] loss: 0.003354  [ 3840/ 4691]
[2022-08-03 16:54:13,021] Test Error: Accuracy: 99.952%, Avg loss: 0.004961
[2022-08-03 16:54:13,021] Epoch 5---------------
[2022-08-03 16:54:13,022] lr: 1.197474e-03
[2022-08-03 16:54:13,197] loss: 0.006221  [    0/ 4691]
[2022-08-03 16:54:15,778] loss: 0.002576  [  960/ 4691]
[2022-08-03 16:54:18,359] loss: 0.002241  [ 1920/ 4691]
[2022-08-03 16:54:20,939] loss: 0.003077  [ 2880/ 4691]
[2022-08-03 16:54:23,523] loss: 0.002649  [ 3840/ 4691]
[2022-08-03 16:54:27,551] Test Error: Accuracy: 100.000%, Avg loss: 0.002436
[2022-08-03 16:54:27,552] Epoch 6---------------
[2022-08-03 16:54:27,552] lr: 1.137600e-03
[2022-08-03 16:54:27,726] loss: 0.001574  [    0/ 4691]
[2022-08-03 16:54:30,306] loss: 0.001883  [  960/ 4691]
[2022-08-03 16:54:32,887] loss: 0.001536  [ 1920/ 4691]
[2022-08-03 16:54:35,469] loss: 0.001479  [ 2880/ 4691]
[2022-08-03 16:54:38,050] loss: 0.001383  [ 3840/ 4691]
[2022-08-03 16:55:28,367] Test Error: Accuracy: 99.952%, Avg loss: 0.002317
[2022-08-03 16:55:28,367] Epoch 7---------------
[2022-08-03 16:55:28,367] lr: 1.080720e-03
[2022-08-03 16:55:28,540] loss: 0.001502  [    0/ 4691]
[2022-08-03 16:55:31,111] loss: 0.001656  [  960/ 4691]
[2022-08-03 16:55:33,680] loss: 0.001174  [ 1920/ 4691]
[2022-08-03 16:55:36,251] loss: 0.001035  [ 2880/ 4691]
[2022-08-03 16:55:38,821] loss: 0.001039  [ 3840/ 4691]
[2022-08-03 16:55:42,837] Test Error: Accuracy: 100.000%, Avg loss: 0.001551
[2022-08-03 16:55:42,837] Epoch 8---------------
[2022-08-03 16:55:42,838] lr: 1.026684e-03
[2022-08-03 16:55:43,012] loss: 0.001048  [    0/ 4691]
[2022-08-03 16:55:45,584] loss: 0.001198  [  960/ 4691]
[2022-08-03 16:55:48,153] loss: 0.001040  [ 1920/ 4691]
[2022-08-03 16:55:50,723] loss: 0.000944  [ 2880/ 4691]
[2022-08-03 16:55:53,294] loss: 0.000969  [ 3840/ 4691]
[2022-08-03 16:55:57,325] Test Error: Accuracy: 100.000%, Avg loss: 0.001375
[2022-08-03 16:55:57,326] Epoch 9---------------
[2022-08-03 16:55:57,326] lr: 9.753500e-04
[2022-08-03 16:55:57,501] loss: 0.000929  [    0/ 4691]
[2022-08-03 16:56:00,084] loss: 0.000925  [  960/ 4691]
[2022-08-03 16:56:02,665] loss: 0.001774  [ 1920/ 4691]
[2022-08-03 16:56:05,251] loss: 0.000857  [ 2880/ 4691]
[2022-08-03 16:56:07,833] loss: 0.000918  [ 3840/ 4691]
[2022-08-03 16:56:11,873] Test Error: Accuracy: 99.952%, Avg loss: 0.001722
[2022-08-03 16:56:11,874] Epoch 10---------------
[2022-08-03 16:56:11,875] lr: 6.811233e-04
[2022-08-03 16:56:12,049] loss: 0.000893  [    0/ 4691]
[2022-08-03 16:56:14,632] loss: 0.000784  [  960/ 4691]
[2022-08-03 16:56:17,215] loss: 0.001193  [ 1920/ 4691]
[2022-08-03 16:56:19,797] loss: 0.000951  [ 2880/ 4691]
[2022-08-03 16:56:22,378] loss: 0.000870  [ 3840/ 4691]
[2022-08-03 16:56:26,421] Test Error: Accuracy: 100.000%, Avg loss: 0.001143
[2022-08-03 16:56:26,422] Epoch 11---------------
[2022-08-03 16:56:26,423] lr: 6.470671e-04
[2022-08-03 16:56:26,597] loss: 0.000986  [    0/ 4691]
[2022-08-03 16:56:29,181] loss: 0.000762  [  960/ 4691]
[2022-08-03 16:56:31,760] loss: 0.000867  [ 1920/ 4691]
[2022-08-03 16:56:34,342] loss: 0.000741  [ 2880/ 4691]
[2022-08-03 16:56:36,926] loss: 0.000903  [ 3840/ 4691]
[2022-08-03 16:56:40,959] Test Error: Accuracy: 99.952%, Avg loss: 0.002418
[2022-08-03 16:56:40,960] Epoch 12---------------
[2022-08-03 16:56:40,961] lr: 4.518711e-04
[2022-08-03 16:56:41,136] loss: 0.000721  [    0/ 4691]
[2022-08-03 16:56:43,717] loss: 0.000876  [  960/ 4691]
[2022-08-03 16:56:46,298] loss: 0.000838  [ 1920/ 4691]
[2022-08-03 16:56:48,880] loss: 0.000747  [ 2880/ 4691]
[2022-08-03 16:56:51,462] loss: 0.000682  [ 3840/ 4691]
[2022-08-03 16:56:55,498] Test Error: Accuracy: 99.952%, Avg loss: 0.001248
[2022-08-03 16:56:55,499] Epoch 13---------------
[2022-08-03 16:56:55,500] lr: 4.292775e-04
[2022-08-03 16:56:55,675] loss: 0.000696  [    0/ 4691]
[2022-08-03 16:56:58,257] loss: 0.000625  [  960/ 4691]
[2022-08-03 16:57:00,839] loss: 0.000836  [ 1920/ 4691]
[2022-08-03 16:57:03,420] loss: 0.000737  [ 2880/ 4691]
[2022-08-03 16:57:06,002] loss: 0.000825  [ 3840/ 4691]
[2022-08-03 16:57:10,042] Test Error: Accuracy: 100.000%, Avg loss: 0.000923
[2022-08-03 16:57:10,042] Epoch 14---------------
[2022-08-03 16:57:10,044] lr: 4.078137e-04
[2022-08-03 16:57:10,218] loss: 0.000659  [    0/ 4691]
[2022-08-03 16:57:12,800] loss: 0.000711  [  960/ 4691]
[2022-08-03 16:57:15,380] loss: 0.000786  [ 1920/ 4691]
[2022-08-03 16:57:17,960] loss: 0.000585  [ 2880/ 4691]
[2022-08-03 16:57:20,541] loss: 0.000765  [ 3840/ 4691]
[2022-08-03 16:57:24,575] Test Error: Accuracy: 100.000%, Avg loss: 0.001474
[2022-08-03 16:57:24,576] Epoch 15---------------
[2022-08-03 16:57:24,577] lr: 2.847915e-04
[2022-08-03 16:57:24,751] loss: 0.000598  [    0/ 4691]
[2022-08-03 16:57:27,333] loss: 0.000803  [  960/ 4691]
[2022-08-03 16:57:29,912] loss: 0.000771  [ 1920/ 4691]
[2022-08-03 16:57:32,494] loss: 0.000831  [ 2880/ 4691]
[2022-08-03 16:57:35,075] loss: 0.000666  [ 3840/ 4691]
[2022-08-03 16:57:39,112] Test Error: Accuracy: 100.000%, Avg loss: 0.000943
[2022-08-03 16:57:39,112] Done!
[2022-08-03 16:57:39,117] Number of parameters:3198730
[2022-08-03 16:57:39,117] ## end time: 2022-08-03 16:57:39.112171
[2022-08-03 16:57:39,118] ## used time: 0:04:24.654259
