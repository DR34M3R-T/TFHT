[2022-08-06 15:21:01,760] ## start time: 2022-08-06 15:21:01.637651
[2022-08-06 15:21:01,761] Using cuda device
[2022-08-06 15:21:01,762] In train:p&d10.npy.
[2022-08-06 15:21:01,763] One Channel
[2022-08-06 15:21:01,763] With Normal data.
[2022-08-06 15:21:01,764] Nunber of classes:10.
[2022-08-06 15:21:01,764] Nunber of ViT channels:1.
[2022-08-06 15:21:01,951] Totol epochs: 10
[2022-08-06 15:21:01,952] Epoch 1---------------
[2022-08-06 15:21:01,953] lr: 2.000000e-03
[2022-08-06 15:21:01,967] loss: 2.495628  [    0/ 4726]
[2022-08-06 15:21:02,124] loss: 2.112576  [  960/ 4726]
[2022-08-06 15:21:02,283] loss: 1.823781  [ 1920/ 4726]
[2022-08-06 15:21:02,437] loss: 1.543496  [ 2880/ 4726]
[2022-08-06 15:21:02,589] loss: 1.254674  [ 3840/ 4726]
[2022-08-06 15:21:02,983] Train Error: Accuracy: 72.789%, Avg loss: 0.863279
[2022-08-06 15:21:03,103] Test  Error: Accuracy: 73.894%, Avg loss: 0.859736
[2022-08-06 15:21:03,103] Epoch 2---------------
[2022-08-06 15:21:03,104] lr: 1.900000e-03
[2022-08-06 15:21:03,116] loss: 0.859122  [    0/ 4726]
[2022-08-06 15:21:03,268] loss: 0.741424  [  960/ 4726]
[2022-08-06 15:21:03,417] loss: 0.648187  [ 1920/ 4726]
[2022-08-06 15:21:03,564] loss: 0.412622  [ 2880/ 4726]
[2022-08-06 15:21:03,712] loss: 0.309022  [ 3840/ 4726]
[2022-08-06 15:21:04,102] Train Error: Accuracy: 95.028%, Avg loss: 0.233499
[2022-08-06 15:21:04,219] Test  Error: Accuracy: 93.583%, Avg loss: 0.281536
[2022-08-06 15:21:04,219] Epoch 3---------------
[2022-08-06 15:21:04,220] lr: 1.805000e-03
[2022-08-06 15:21:04,231] loss: 0.223037  [    0/ 4726]
[2022-08-06 15:21:04,385] loss: 0.184403  [  960/ 4726]
[2022-08-06 15:21:04,536] loss: 0.182641  [ 1920/ 4726]
[2022-08-06 15:21:04,686] loss: 0.147671  [ 2880/ 4726]
[2022-08-06 15:21:04,837] loss: 0.166021  [ 3840/ 4726]
[2022-08-06 15:21:05,228] Train Error: Accuracy: 96.868%, Avg loss: 0.118991
[2022-08-06 15:21:05,346] Test  Error: Accuracy: 95.139%, Avg loss: 0.151235
[2022-08-06 15:21:05,347] Epoch 4---------------
[2022-08-06 15:21:05,348] lr: 1.714750e-03
[2022-08-06 15:21:05,359] loss: 0.109519  [    0/ 4726]
[2022-08-06 15:21:05,509] loss: 0.112942  [  960/ 4726]
[2022-08-06 15:21:05,659] loss: 0.117545  [ 1920/ 4726]
[2022-08-06 15:21:05,807] loss: 0.094573  [ 2880/ 4726]
[2022-08-06 15:21:05,955] loss: 0.152627  [ 3840/ 4726]
[2022-08-06 15:21:06,360] Train Error: Accuracy: 97.736%, Avg loss: 0.078022
[2022-08-06 15:21:06,480] Test  Error: Accuracy: 95.868%, Avg loss: 0.124096
[2022-08-06 15:21:06,481] Epoch 5---------------
[2022-08-06 15:21:06,482] lr: 1.629012e-03
[2022-08-06 15:21:06,494] loss: 0.085952  [    0/ 4726]
[2022-08-06 15:21:06,656] loss: 0.094747  [  960/ 4726]
[2022-08-06 15:21:06,807] loss: 0.063260  [ 1920/ 4726]
[2022-08-06 15:21:06,957] loss: 0.041408  [ 2880/ 4726]
[2022-08-06 15:21:07,108] loss: 0.068858  [ 3840/ 4726]
[2022-08-06 15:21:07,514] Train Error: Accuracy: 98.286%, Avg loss: 0.066215
[2022-08-06 15:21:07,631] Test  Error: Accuracy: 97.278%, Avg loss: 0.101208
[2022-08-06 15:21:07,632] Epoch 6---------------
[2022-08-06 15:21:07,633] lr: 1.547562e-03
[2022-08-06 15:21:07,645] loss: 0.086148  [    0/ 4726]
[2022-08-06 15:21:07,794] loss: 0.039755  [  960/ 4726]
[2022-08-06 15:21:07,942] loss: 0.026764  [ 1920/ 4726]
[2022-08-06 15:21:08,091] loss: 0.068128  [ 2880/ 4726]
[2022-08-06 15:21:08,239] loss: 0.016362  [ 3840/ 4726]
[2022-08-06 15:21:08,631] Train Error: Accuracy: 98.688%, Avg loss: 0.050867
[2022-08-06 15:21:08,747] Test  Error: Accuracy: 97.326%, Avg loss: 0.087435
[2022-08-06 15:21:08,747] Epoch 7---------------
[2022-08-06 15:21:08,748] lr: 1.470184e-03
[2022-08-06 15:21:08,760] loss: 0.064509  [    0/ 4726]
[2022-08-06 15:21:08,910] loss: 0.021491  [  960/ 4726]
[2022-08-06 15:21:09,058] loss: 0.014923  [ 1920/ 4726]
[2022-08-06 15:21:09,206] loss: 0.013518  [ 2880/ 4726]
[2022-08-06 15:21:09,356] loss: 0.048825  [ 3840/ 4726]
[2022-08-06 15:21:09,754] Train Error: Accuracy: 99.471%, Avg loss: 0.027400
[2022-08-06 15:21:09,870] Test  Error: Accuracy: 98.201%, Avg loss: 0.078015
[2022-08-06 15:21:09,870] Epoch 8---------------
[2022-08-06 15:21:09,872] lr: 1.396675e-03
[2022-08-06 15:21:09,884] loss: 0.027402  [    0/ 4726]
[2022-08-06 15:21:10,033] loss: 0.057181  [  960/ 4726]
[2022-08-06 15:21:10,180] loss: 0.016824  [ 1920/ 4726]
[2022-08-06 15:21:10,328] loss: 0.032492  [ 2880/ 4726]
[2022-08-06 15:21:10,478] loss: 0.054688  [ 3840/ 4726]
[2022-08-06 15:21:10,873] Train Error: Accuracy: 99.450%, Avg loss: 0.023881
[2022-08-06 15:21:10,989] Test  Error: Accuracy: 97.618%, Avg loss: 0.068683
[2022-08-06 15:21:10,989] Epoch 9---------------
[2022-08-06 15:21:10,990] lr: 1.326841e-03
[2022-08-06 15:21:11,002] loss: 0.049211  [    0/ 4726]
[2022-08-06 15:21:11,151] loss: 0.042051  [  960/ 4726]
[2022-08-06 15:21:11,303] loss: 0.022551  [ 1920/ 4726]
[2022-08-06 15:21:11,453] loss: 0.030861  [ 2880/ 4726]
[2022-08-06 15:21:11,600] loss: 0.008961  [ 3840/ 4726]
[2022-08-06 15:21:12,003] Train Error: Accuracy: 99.661%, Avg loss: 0.018784
[2022-08-06 15:21:12,122] Test  Error: Accuracy: 98.250%, Avg loss: 0.070541
[2022-08-06 15:21:12,123] Epoch 10---------------
[2022-08-06 15:21:12,124] lr: 1.137600e-03
[2022-08-06 15:21:12,136] loss: 0.011822  [    0/ 4726]
[2022-08-06 15:21:12,289] loss: 0.011905  [  960/ 4726]
[2022-08-06 15:21:12,438] loss: 0.062121  [ 1920/ 4726]
[2022-08-06 15:21:12,586] loss: 0.058819  [ 2880/ 4726]
[2022-08-06 15:21:12,734] loss: 0.006281  [ 3840/ 4726]
[2022-08-06 15:21:13,129] Train Error: Accuracy: 99.513%, Avg loss: 0.019144
[2022-08-06 15:21:13,247] Test  Error: Accuracy: 98.590%, Avg loss: 0.052445
[2022-08-06 15:21:13,248] Done!
[2022-08-06 15:21:13,249] Number of parameters:30666
[2022-08-06 15:21:13,250] ## end time: 2022-08-06 15:21:13.248648
[2022-08-06 15:21:13,250] ## used time: 0:00:11.610997
