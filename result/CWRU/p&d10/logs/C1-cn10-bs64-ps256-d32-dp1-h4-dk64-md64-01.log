[2022-08-06 15:17:05,962] ## start time: 2022-08-06 15:17:05.838795
[2022-08-06 15:17:05,962] Using cuda device
[2022-08-06 15:17:05,964] In train:p&d10.npy.
[2022-08-06 15:17:05,964] One Channel
[2022-08-06 15:17:05,965] With Normal data.
[2022-08-06 15:17:05,965] Nunber of classes:10.
[2022-08-06 15:17:05,966] Nunber of ViT channels:1.
[2022-08-06 15:17:06,154] Totol epochs: 10
[2022-08-06 15:17:06,155] Epoch 1---------------
[2022-08-06 15:17:06,156] lr: 2.000000e-03
[2022-08-06 15:17:06,169] loss: 2.481051  [    0/ 4761]
[2022-08-06 15:17:06,328] loss: 1.819989  [  960/ 4761]
[2022-08-06 15:17:06,485] loss: 1.705211  [ 1920/ 4761]
[2022-08-06 15:17:06,651] loss: 0.947407  [ 2880/ 4761]
[2022-08-06 15:17:06,807] loss: 0.553402  [ 3840/ 4761]
[2022-08-06 15:17:07,260] Train Error: Accuracy: 91.640%, Avg loss: 0.368590
[2022-08-06 15:17:07,383] Test  Error: Accuracy: 90.307%, Avg loss: 0.396094
[2022-08-06 15:17:07,383] Epoch 2---------------
[2022-08-06 15:17:07,384] lr: 1.900000e-03
[2022-08-06 15:17:07,396] loss: 0.341927  [    0/ 4761]
[2022-08-06 15:17:07,553] loss: 0.231961  [  960/ 4761]
[2022-08-06 15:17:07,711] loss: 0.205078  [ 1920/ 4761]
[2022-08-06 15:17:07,868] loss: 0.089439  [ 2880/ 4761]
[2022-08-06 15:17:08,018] loss: 0.118843  [ 3840/ 4761]
[2022-08-06 15:17:08,444] Train Error: Accuracy: 97.774%, Avg loss: 0.094672
[2022-08-06 15:17:08,564] Test  Error: Accuracy: 97.676%, Avg loss: 0.110185
[2022-08-06 15:17:08,564] Epoch 3---------------
[2022-08-06 15:17:08,565] lr: 1.805000e-03
[2022-08-06 15:17:08,578] loss: 0.190939  [    0/ 4761]
[2022-08-06 15:17:08,731] loss: 0.092308  [  960/ 4761]
[2022-08-06 15:17:08,884] loss: 0.054298  [ 1920/ 4761]
[2022-08-06 15:17:09,033] loss: 0.025882  [ 2880/ 4761]
[2022-08-06 15:17:09,183] loss: 0.073630  [ 3840/ 4761]
[2022-08-06 15:17:09,605] Train Error: Accuracy: 99.769%, Avg loss: 0.030637
[2022-08-06 15:17:09,725] Test  Error: Accuracy: 99.209%, Avg loss: 0.039938
[2022-08-06 15:17:09,725] Epoch 4---------------
[2022-08-06 15:17:09,727] lr: 1.714750e-03
[2022-08-06 15:17:09,738] loss: 0.043405  [    0/ 4761]
[2022-08-06 15:17:09,887] loss: 0.018155  [  960/ 4761]
[2022-08-06 15:17:10,042] loss: 0.018821  [ 1920/ 4761]
[2022-08-06 15:17:10,198] loss: 0.037008  [ 2880/ 4761]
[2022-08-06 15:17:10,350] loss: 0.018023  [ 3840/ 4761]
[2022-08-06 15:17:10,771] Train Error: Accuracy: 99.790%, Avg loss: 0.021182
[2022-08-06 15:17:10,890] Test  Error: Accuracy: 99.258%, Avg loss: 0.034445
[2022-08-06 15:17:10,890] Epoch 5---------------
[2022-08-06 15:17:10,891] lr: 1.629012e-03
[2022-08-06 15:17:10,903] loss: 0.016990  [    0/ 4761]
[2022-08-06 15:17:11,053] loss: 0.009208  [  960/ 4761]
[2022-08-06 15:17:11,202] loss: 0.013401  [ 1920/ 4761]
[2022-08-06 15:17:11,351] loss: 0.015682  [ 2880/ 4761]
[2022-08-06 15:17:11,504] loss: 0.007681  [ 3840/ 4761]
[2022-08-06 15:17:11,927] Train Error: Accuracy: 99.748%, Avg loss: 0.016486
[2022-08-06 15:17:12,047] Test  Error: Accuracy: 99.505%, Avg loss: 0.026200
[2022-08-06 15:17:12,047] Epoch 6---------------
[2022-08-06 15:17:12,048] lr: 1.547562e-03
[2022-08-06 15:17:12,059] loss: 0.036676  [    0/ 4761]
[2022-08-06 15:17:12,208] loss: 0.023983  [  960/ 4761]
[2022-08-06 15:17:12,358] loss: 0.006866  [ 1920/ 4761]
[2022-08-06 15:17:12,511] loss: 0.010235  [ 2880/ 4761]
[2022-08-06 15:17:12,663] loss: 0.010502  [ 3840/ 4761]
[2022-08-06 15:17:13,081] Train Error: Accuracy: 99.916%, Avg loss: 0.008114
[2022-08-06 15:17:13,199] Test  Error: Accuracy: 99.852%, Avg loss: 0.012562
[2022-08-06 15:17:13,200] Epoch 7---------------
[2022-08-06 15:17:13,201] lr: 1.470184e-03
[2022-08-06 15:17:13,213] loss: 0.017025  [    0/ 4761]
[2022-08-06 15:17:13,363] loss: 0.005505  [  960/ 4761]
[2022-08-06 15:17:13,514] loss: 0.094381  [ 1920/ 4761]
[2022-08-06 15:17:13,668] loss: 0.014034  [ 2880/ 4761]
[2022-08-06 15:17:13,817] loss: 0.016923  [ 3840/ 4761]
[2022-08-06 15:17:14,237] Train Error: Accuracy: 94.077%, Avg loss: 0.186609
[2022-08-06 15:17:14,356] Test  Error: Accuracy: 91.939%, Avg loss: 0.268610
[2022-08-06 15:17:14,356] Epoch 8---------------
[2022-08-06 15:17:14,357] lr: 1.026684e-03
[2022-08-06 15:17:14,369] loss: 0.244757  [    0/ 4761]
[2022-08-06 15:17:14,520] loss: 0.039400  [  960/ 4761]
[2022-08-06 15:17:14,673] loss: 0.005161  [ 1920/ 4761]
[2022-08-06 15:17:14,824] loss: 0.003539  [ 2880/ 4761]
[2022-08-06 15:17:14,973] loss: 0.008313  [ 3840/ 4761]
[2022-08-06 15:17:15,394] Train Error: Accuracy: 100.000%, Avg loss: 0.005867
[2022-08-06 15:17:15,514] Test  Error: Accuracy: 99.703%, Avg loss: 0.014990
[2022-08-06 15:17:15,515] Epoch 9---------------
[2022-08-06 15:17:15,515] lr: 9.753500e-04
[2022-08-06 15:17:15,528] loss: 0.005193  [    0/ 4761]
[2022-08-06 15:17:15,679] loss: 0.005013  [  960/ 4761]
[2022-08-06 15:17:15,832] loss: 0.007211  [ 1920/ 4761]
[2022-08-06 15:17:15,982] loss: 0.002340  [ 2880/ 4761]
[2022-08-06 15:17:16,133] loss: 0.002333  [ 3840/ 4761]
[2022-08-06 15:17:16,553] Train Error: Accuracy: 100.000%, Avg loss: 0.004427
[2022-08-06 15:17:16,672] Test  Error: Accuracy: 99.852%, Avg loss: 0.008401
[2022-08-06 15:17:16,673] Epoch 10---------------
[2022-08-06 15:17:16,674] lr: 9.265825e-04
[2022-08-06 15:17:16,686] loss: 0.003836  [    0/ 4761]
[2022-08-06 15:17:16,841] loss: 0.004492  [  960/ 4761]
[2022-08-06 15:17:16,991] loss: 0.002742  [ 1920/ 4761]
[2022-08-06 15:17:17,141] loss: 0.002109  [ 2880/ 4761]
[2022-08-06 15:17:17,291] loss: 0.003844  [ 3840/ 4761]
[2022-08-06 15:17:17,710] Train Error: Accuracy: 100.000%, Avg loss: 0.002996
[2022-08-06 15:17:17,830] Test  Error: Accuracy: 99.753%, Avg loss: 0.009533
[2022-08-06 15:17:17,830] Done!
[2022-08-06 15:17:17,832] Number of parameters:92106
[2022-08-06 15:17:17,832] ## end time: 2022-08-06 15:17:17.830951
[2022-08-06 15:17:17,833] ## used time: 0:00:11.992156
