[2022-08-06 16:40:05,458] ## start time: 2022-08-06 16:40:05.322185
[2022-08-06 16:40:05,458] Using cuda device
[2022-08-06 16:40:05,459] In train:p&d10.npy.
[2022-08-06 16:40:05,461] One Channel
[2022-08-06 16:40:05,461] With Normal data.
[2022-08-06 16:40:05,462] Nunber of classes:10.
[2022-08-06 16:40:05,462] Nunber of ViT channels:1.
[2022-08-06 16:40:05,708] Totol epochs: 15
[2022-08-06 16:40:05,710] Epoch 1---------------
[2022-08-06 16:40:05,710] lr: 2.000000e-03
[2022-08-06 16:40:06,427] loss: 2.612453  [    0/ 4681]
[2022-08-06 16:40:17,144] loss: 1.899269  [  960/ 4681]
[2022-08-06 16:40:27,862] loss: 1.627376  [ 1920/ 4681]
[2022-08-06 16:40:38,580] loss: 1.769107  [ 2880/ 4681]
[2022-08-06 16:40:49,298] loss: 0.887362  [ 3840/ 4681]
[2022-08-06 16:41:17,479] Train Error: Accuracy: 64.153%, Avg loss: 0.979674
[2022-08-06 16:41:26,226] Test  Error: Accuracy: 63.035%, Avg loss: 1.010190
[2022-08-06 16:41:26,227] Epoch 2---------------
[2022-08-06 16:41:26,228] lr: 1.900000e-03
[2022-08-06 16:41:26,945] loss: 1.132132  [    0/ 4681]
[2022-08-06 16:41:37,665] loss: 0.606284  [  960/ 4681]
[2022-08-06 16:41:48,384] loss: 0.460789  [ 1920/ 4681]
[2022-08-06 16:41:59,103] loss: 0.395772  [ 2880/ 4681]
[2022-08-06 16:42:09,821] loss: 0.355332  [ 3840/ 4681]
[2022-08-06 16:42:38,010] Train Error: Accuracy: 81.628%, Avg loss: 0.695725
[2022-08-06 16:42:46,758] Test  Error: Accuracy: 81.494%, Avg loss: 0.730283
[2022-08-06 16:42:46,758] Epoch 3---------------
[2022-08-06 16:42:46,759] lr: 1.805000e-03
[2022-08-06 16:42:47,477] loss: 0.457524  [    0/ 4681]
[2022-08-06 16:42:58,195] loss: 0.343436  [  960/ 4681]
[2022-08-06 16:43:08,913] loss: 0.095758  [ 1920/ 4681]
[2022-08-06 16:43:19,630] loss: 0.092294  [ 2880/ 4681]
[2022-08-06 16:43:30,348] loss: 0.173218  [ 3840/ 4681]
[2022-08-06 16:43:58,536] Train Error: Accuracy: 89.084%, Avg loss: 0.341395
[2022-08-06 16:44:07,285] Test  Error: Accuracy: 88.107%, Avg loss: 0.392604
[2022-08-06 16:44:07,286] Epoch 4---------------
[2022-08-06 16:44:07,288] lr: 1.714750e-03
[2022-08-06 16:44:08,004] loss: 0.425118  [    0/ 4681]
[2022-08-06 16:44:18,721] loss: 0.053482  [  960/ 4681]
[2022-08-06 16:44:29,438] loss: 0.040141  [ 1920/ 4681]
[2022-08-06 16:44:40,156] loss: 0.070138  [ 2880/ 4681]
[2022-08-06 16:44:50,873] loss: 0.128462  [ 3840/ 4681]
[2022-08-06 16:45:19,055] Train Error: Accuracy: 99.188%, Avg loss: 0.036955
[2022-08-06 16:45:27,803] Test  Error: Accuracy: 98.573%, Avg loss: 0.058887
[2022-08-06 16:45:27,803] Epoch 5---------------
[2022-08-06 16:45:27,804] lr: 1.629012e-03
[2022-08-06 16:45:28,521] loss: 0.029482  [    0/ 4681]
[2022-08-06 16:45:39,239] loss: 0.009770  [  960/ 4681]
[2022-08-06 16:45:49,957] loss: 0.006414  [ 1920/ 4681]
[2022-08-06 16:46:00,676] loss: 0.006024  [ 2880/ 4681]
[2022-08-06 16:46:11,393] loss: 0.115398  [ 3840/ 4681]
[2022-08-06 16:46:39,583] Train Error: Accuracy: 97.394%, Avg loss: 0.083233
[2022-08-06 16:46:48,332] Test  Error: Accuracy: 96.575%, Avg loss: 0.114087
[2022-08-06 16:46:48,333] Epoch 6---------------
[2022-08-06 16:46:48,334] lr: 1.137600e-03
[2022-08-06 16:46:49,051] loss: 0.033476  [    0/ 4681]
[2022-08-06 16:46:59,769] loss: 0.012160  [  960/ 4681]
[2022-08-06 16:47:10,488] loss: 0.008293  [ 1920/ 4681]
[2022-08-06 16:47:21,206] loss: 0.021065  [ 2880/ 4681]
[2022-08-06 16:47:31,925] loss: 0.028463  [ 3840/ 4681]
[2022-08-06 16:48:00,112] Train Error: Accuracy: 99.744%, Avg loss: 0.016838
[2022-08-06 16:48:08,860] Test  Error: Accuracy: 99.382%, Avg loss: 0.024521
[2022-08-06 16:48:08,860] Epoch 7---------------
[2022-08-06 16:48:08,861] lr: 1.080720e-03
[2022-08-06 16:48:09,578] loss: 0.025455  [    0/ 4681]
[2022-08-06 16:48:20,297] loss: 0.005738  [  960/ 4681]
[2022-08-06 16:48:31,017] loss: 0.138320  [ 1920/ 4681]
[2022-08-06 16:48:41,734] loss: 0.006663  [ 2880/ 4681]
[2022-08-06 16:48:52,453] loss: 0.003749  [ 3840/ 4681]
[2022-08-06 16:49:20,635] Train Error: Accuracy: 99.850%, Avg loss: 0.009799
[2022-08-06 16:49:29,381] Test  Error: Accuracy: 99.382%, Avg loss: 0.020847
[2022-08-06 16:49:29,382] Epoch 8---------------
[2022-08-06 16:49:29,383] lr: 1.026684e-03
[2022-08-06 16:49:30,101] loss: 0.002338  [    0/ 4681]
[2022-08-06 16:49:40,818] loss: 0.004133  [  960/ 4681]
[2022-08-06 16:49:51,535] loss: 0.004582  [ 1920/ 4681]
[2022-08-06 16:50:02,252] loss: 0.013006  [ 2880/ 4681]
[2022-08-06 16:50:12,970] loss: 0.007387  [ 3840/ 4681]
[2022-08-06 16:50:41,134] Train Error: Accuracy: 99.872%, Avg loss: 0.010875
[2022-08-06 16:50:49,873] Test  Error: Accuracy: 99.334%, Avg loss: 0.027453
[2022-08-06 16:50:49,873] Epoch 9---------------
[2022-08-06 16:50:49,874] lr: 7.169718e-04
[2022-08-06 16:50:50,592] loss: 0.008088  [    0/ 4681]
[2022-08-06 16:51:01,309] loss: 0.004383  [  960/ 4681]
[2022-08-06 16:51:12,026] loss: 0.004157  [ 1920/ 4681]
[2022-08-06 16:51:22,742] loss: 0.011748  [ 2880/ 4681]
[2022-08-06 16:51:33,459] loss: 0.003179  [ 3840/ 4681]
[2022-08-06 16:52:01,627] Train Error: Accuracy: 99.957%, Avg loss: 0.005637
[2022-08-06 16:52:10,368] Test  Error: Accuracy: 99.524%, Avg loss: 0.016043
[2022-08-06 16:52:10,368] Epoch 10---------------
[2022-08-06 16:52:10,369] lr: 6.811233e-04
[2022-08-06 16:52:11,086] loss: 0.001875  [    0/ 4681]
[2022-08-06 16:52:21,804] loss: 0.004548  [  960/ 4681]
[2022-08-06 16:52:32,522] loss: 0.006213  [ 1920/ 4681]
[2022-08-06 16:52:43,239] loss: 0.002071  [ 2880/ 4681]
[2022-08-06 16:52:53,957] loss: 0.002761  [ 3840/ 4681]
[2022-08-06 16:53:22,123] Train Error: Accuracy: 99.915%, Avg loss: 0.004546
[2022-08-06 16:53:30,862] Test  Error: Accuracy: 99.667%, Avg loss: 0.010980
[2022-08-06 16:53:30,862] Epoch 11---------------
[2022-08-06 16:53:30,864] lr: 6.470671e-04
[2022-08-06 16:53:31,581] loss: 0.025043  [    0/ 4681]
[2022-08-06 16:53:42,299] loss: 0.001695  [  960/ 4681]
[2022-08-06 16:53:53,017] loss: 0.001828  [ 1920/ 4681]
[2022-08-06 16:54:03,735] loss: 0.024871  [ 2880/ 4681]
[2022-08-06 16:54:14,453] loss: 0.008279  [ 3840/ 4681]
[2022-08-06 16:54:42,636] Train Error: Accuracy: 99.936%, Avg loss: 0.003891
[2022-08-06 16:54:51,380] Test  Error: Accuracy: 99.905%, Avg loss: 0.007083
[2022-08-06 16:54:51,380] Epoch 12---------------
[2022-08-06 16:54:51,381] lr: 6.147137e-04
[2022-08-06 16:54:52,099] loss: 0.001095  [    0/ 4681]
[2022-08-06 16:55:02,817] loss: 0.000754  [  960/ 4681]
[2022-08-06 16:55:13,535] loss: 0.001607  [ 1920/ 4681]
[2022-08-06 16:55:24,252] loss: 0.001984  [ 2880/ 4681]
[2022-08-06 16:55:34,969] loss: 0.003809  [ 3840/ 4681]
[2022-08-06 16:56:03,137] Train Error: Accuracy: 99.979%, Avg loss: 0.003050
[2022-08-06 16:56:11,885] Test  Error: Accuracy: 99.667%, Avg loss: 0.010443
[2022-08-06 16:56:11,887] Epoch 13---------------
[2022-08-06 16:56:11,888] lr: 4.292775e-04
[2022-08-06 16:56:12,605] loss: 0.006552  [    0/ 4681]
[2022-08-06 16:56:23,322] loss: 0.001336  [  960/ 4681]
[2022-08-06 16:56:34,040] loss: 0.001818  [ 1920/ 4681]
[2022-08-06 16:56:44,758] loss: 0.009100  [ 2880/ 4681]
[2022-08-06 16:56:55,475] loss: 0.003364  [ 3840/ 4681]
[2022-08-06 16:57:23,656] Train Error: Accuracy: 99.979%, Avg loss: 0.001942
[2022-08-06 16:57:32,401] Test  Error: Accuracy: 99.810%, Avg loss: 0.007705
[2022-08-06 16:57:32,401] Epoch 14---------------
[2022-08-06 16:57:32,402] lr: 4.078137e-04
[2022-08-06 16:57:33,119] loss: 0.001640  [    0/ 4681]
[2022-08-06 16:57:43,839] loss: 0.001772  [  960/ 4681]
[2022-08-06 16:57:54,558] loss: 0.009761  [ 1920/ 4681]
[2022-08-06 16:58:05,276] loss: 0.001173  [ 2880/ 4681]
[2022-08-06 16:58:15,993] loss: 0.001672  [ 3840/ 4681]
[2022-08-06 16:58:44,179] Train Error: Accuracy: 99.957%, Avg loss: 0.002750
[2022-08-06 16:58:52,930] Test  Error: Accuracy: 99.667%, Avg loss: 0.010529
[2022-08-06 16:58:52,931] Epoch 15---------------
[2022-08-06 16:58:52,931] lr: 2.847915e-04
[2022-08-06 16:58:53,649] loss: 0.000906  [    0/ 4681]
[2022-08-06 16:59:04,366] loss: 0.006478  [  960/ 4681]
[2022-08-06 16:59:15,085] loss: 0.001426  [ 1920/ 4681]
[2022-08-06 16:59:25,803] loss: 0.001074  [ 2880/ 4681]
[2022-08-06 16:59:36,522] loss: 0.000791  [ 3840/ 4681]
[2022-08-06 17:00:04,706] Train Error: Accuracy: 99.957%, Avg loss: 0.003391
[2022-08-06 17:00:13,466] Test  Error: Accuracy: 99.762%, Avg loss: 0.009423
[2022-08-06 17:00:13,466] Done!
[2022-08-06 17:00:13,470] Number of parameters:1625866
[2022-08-06 17:00:13,470] ## end time: 2022-08-06 17:00:13.466408
[2022-08-06 17:00:13,471] ## used time: 0:20:08.144223
