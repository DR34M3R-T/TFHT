[2022-08-06 15:29:49,114] ## start time: 2022-08-06 15:29:48.993421
[2022-08-06 15:29:49,115] Using cuda device
[2022-08-06 15:29:49,116] In train:p&d10.npy.
[2022-08-06 15:29:49,117] One Channel
[2022-08-06 15:29:49,118] With Normal data.
[2022-08-06 15:29:49,118] Nunber of classes:10.
[2022-08-06 15:29:49,118] Nunber of ViT channels:1.
[2022-08-06 15:29:49,302] Totol epochs: 10
[2022-08-06 15:29:49,303] Epoch 1---------------
[2022-08-06 15:29:49,303] lr: 2.000000e-03
[2022-08-06 15:29:49,318] loss: 2.497017  [    0/ 4737]
[2022-08-06 15:29:49,477] loss: 1.956937  [  960/ 4737]
[2022-08-06 15:29:49,637] loss: 1.735030  [ 1920/ 4737]
[2022-08-06 15:29:49,791] loss: 1.548869  [ 2880/ 4737]
[2022-08-06 15:29:49,949] loss: 1.243268  [ 3840/ 4737]
[2022-08-06 15:29:50,365] Train Error: Accuracy: 55.330%, Avg loss: 1.356076
[2022-08-06 15:29:50,478] Test  Error: Accuracy: 54.497%, Avg loss: 1.407672
[2022-08-06 15:29:50,479] Epoch 2---------------
[2022-08-06 15:29:50,480] lr: 1.900000e-03
[2022-08-06 15:29:50,492] loss: 1.328515  [    0/ 4737]
[2022-08-06 15:29:50,643] loss: 0.833029  [  960/ 4737]
[2022-08-06 15:29:50,792] loss: 0.762293  [ 1920/ 4737]
[2022-08-06 15:29:50,947] loss: 0.640686  [ 2880/ 4737]
[2022-08-06 15:29:51,097] loss: 0.521364  [ 3840/ 4737]
[2022-08-06 15:29:51,499] Train Error: Accuracy: 72.535%, Avg loss: 0.825969
[2022-08-06 15:29:51,612] Test  Error: Accuracy: 72.874%, Avg loss: 0.834440
[2022-08-06 15:29:51,612] Epoch 3---------------
[2022-08-06 15:29:51,613] lr: 1.805000e-03
[2022-08-06 15:29:51,626] loss: 0.663765  [    0/ 4737]
[2022-08-06 15:29:51,775] loss: 0.391596  [  960/ 4737]
[2022-08-06 15:29:51,929] loss: 0.329346  [ 1920/ 4737]
[2022-08-06 15:29:52,080] loss: 0.226165  [ 2880/ 4737]
[2022-08-06 15:29:52,231] loss: 0.257385  [ 3840/ 4737]
[2022-08-06 15:29:52,631] Train Error: Accuracy: 94.237%, Avg loss: 0.252121
[2022-08-06 15:29:52,744] Test  Error: Accuracy: 92.962%, Avg loss: 0.268369
[2022-08-06 15:29:52,745] Epoch 4---------------
[2022-08-06 15:29:52,746] lr: 1.714750e-03
[2022-08-06 15:29:52,756] loss: 0.273280  [    0/ 4737]
[2022-08-06 15:29:52,906] loss: 0.267871  [  960/ 4737]
[2022-08-06 15:29:53,060] loss: 0.219477  [ 1920/ 4737]
[2022-08-06 15:29:53,211] loss: 0.145013  [ 2880/ 4737]
[2022-08-06 15:29:53,360] loss: 0.139111  [ 3840/ 4737]
[2022-08-06 15:29:53,760] Train Error: Accuracy: 95.546%, Avg loss: 0.207629
[2022-08-06 15:29:53,872] Test  Error: Accuracy: 94.868%, Avg loss: 0.221270
[2022-08-06 15:29:53,872] Epoch 5---------------
[2022-08-06 15:29:53,873] lr: 1.629012e-03
[2022-08-06 15:29:53,885] loss: 0.163291  [    0/ 4737]
[2022-08-06 15:29:54,036] loss: 0.130948  [  960/ 4737]
[2022-08-06 15:29:54,188] loss: 0.096350  [ 1920/ 4737]
[2022-08-06 15:29:54,338] loss: 0.122211  [ 2880/ 4737]
[2022-08-06 15:29:54,487] loss: 0.151710  [ 3840/ 4737]
[2022-08-06 15:29:54,890] Train Error: Accuracy: 96.538%, Avg loss: 0.140583
[2022-08-06 15:29:55,003] Test  Error: Accuracy: 94.673%, Avg loss: 0.184804
[2022-08-06 15:29:55,004] Epoch 6---------------
[2022-08-06 15:29:55,005] lr: 1.547562e-03
[2022-08-06 15:29:55,017] loss: 0.136282  [    0/ 4737]
[2022-08-06 15:29:55,169] loss: 0.223720  [  960/ 4737]
[2022-08-06 15:29:55,321] loss: 0.078159  [ 1920/ 4737]
[2022-08-06 15:29:55,477] loss: 0.093684  [ 2880/ 4737]
[2022-08-06 15:29:55,627] loss: 0.069967  [ 3840/ 4737]
[2022-08-06 15:29:56,028] Train Error: Accuracy: 98.417%, Avg loss: 0.081117
[2022-08-06 15:29:56,141] Test  Error: Accuracy: 97.361%, Avg loss: 0.112276
[2022-08-06 15:29:56,141] Epoch 7---------------
[2022-08-06 15:29:56,142] lr: 1.470184e-03
[2022-08-06 15:29:56,153] loss: 0.143142  [    0/ 4737]
[2022-08-06 15:29:56,307] loss: 0.080342  [  960/ 4737]
[2022-08-06 15:29:56,458] loss: 0.043545  [ 1920/ 4737]
[2022-08-06 15:29:56,609] loss: 0.073508  [ 2880/ 4737]
[2022-08-06 15:29:56,758] loss: 0.081857  [ 3840/ 4737]
[2022-08-06 15:29:57,158] Train Error: Accuracy: 98.185%, Avg loss: 0.073595
[2022-08-06 15:29:57,271] Test  Error: Accuracy: 97.312%, Avg loss: 0.097719
[2022-08-06 15:29:57,271] Epoch 8---------------
[2022-08-06 15:29:57,272] lr: 1.396675e-03
[2022-08-06 15:29:57,284] loss: 0.122475  [    0/ 4737]
[2022-08-06 15:29:57,437] loss: 0.059933  [  960/ 4737]
[2022-08-06 15:29:57,588] loss: 0.106525  [ 1920/ 4737]
[2022-08-06 15:29:57,739] loss: 0.069144  [ 2880/ 4737]
[2022-08-06 15:29:57,888] loss: 0.052654  [ 3840/ 4737]
[2022-08-06 15:29:58,295] Train Error: Accuracy: 98.776%, Avg loss: 0.060791
[2022-08-06 15:29:58,410] Test  Error: Accuracy: 97.654%, Avg loss: 0.086683
[2022-08-06 15:29:58,410] Epoch 9---------------
[2022-08-06 15:29:58,411] lr: 1.326841e-03
[2022-08-06 15:29:58,422] loss: 0.083169  [    0/ 4737]
[2022-08-06 15:29:58,573] loss: 0.045179  [  960/ 4737]
[2022-08-06 15:29:58,725] loss: 0.059469  [ 1920/ 4737]
[2022-08-06 15:29:58,875] loss: 0.033978  [ 2880/ 4737]
[2022-08-06 15:29:59,023] loss: 0.044777  [ 3840/ 4737]
[2022-08-06 15:29:59,427] Train Error: Accuracy: 99.282%, Avg loss: 0.042097
[2022-08-06 15:29:59,541] Test  Error: Accuracy: 98.338%, Avg loss: 0.069186
[2022-08-06 15:29:59,541] Epoch 10---------------
[2022-08-06 15:29:59,542] lr: 1.260499e-03
[2022-08-06 15:29:59,554] loss: 0.047871  [    0/ 4737]
[2022-08-06 15:29:59,706] loss: 0.029418  [  960/ 4737]
[2022-08-06 15:29:59,855] loss: 0.064154  [ 1920/ 4737]
[2022-08-06 15:30:00,004] loss: 0.067471  [ 2880/ 4737]
[2022-08-06 15:30:00,156] loss: 0.051258  [ 3840/ 4737]
[2022-08-06 15:30:00,559] Train Error: Accuracy: 98.733%, Avg loss: 0.053579
[2022-08-06 15:30:00,676] Test  Error: Accuracy: 97.654%, Avg loss: 0.088162
[2022-08-06 15:30:00,677] Done!
[2022-08-06 15:30:00,679] Number of parameters:27626
[2022-08-06 15:30:00,679] ## end time: 2022-08-06 15:30:00.677975
[2022-08-06 15:30:00,679] ## used time: 0:00:11.684554
