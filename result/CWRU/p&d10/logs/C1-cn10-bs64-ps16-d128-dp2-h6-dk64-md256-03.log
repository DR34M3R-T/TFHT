[2022-08-07 15:24:46,814] ## start time: 2022-08-07 15:24:46.686369
[2022-08-07 15:24:46,814] Using cuda device
[2022-08-07 15:24:46,815] In train:p&d10.npy.
[2022-08-07 15:24:46,816] One Channel
[2022-08-07 15:24:46,817] With Normal data.
[2022-08-07 15:24:46,817] Nunber of classes:10.
[2022-08-07 15:24:46,817] Nunber of ViT channels:1.
[2022-08-07 15:24:47,035] Totol epochs: 15
[2022-08-07 15:24:47,037] Epoch 1---------------
[2022-08-07 15:24:47,037] lr: 2.000000e-03
[2022-08-07 15:24:47,542] loss: 2.587114  [    0/ 4739]
[2022-08-07 15:24:55,073] loss: 1.807489  [  960/ 4739]
[2022-08-07 15:25:02,604] loss: 1.546730  [ 1920/ 4739]
[2022-08-07 15:25:10,134] loss: 0.659580  [ 2880/ 4739]
[2022-08-07 15:25:17,665] loss: 0.413299  [ 3840/ 4739]
[2022-08-07 15:25:37,776] Train Error: Accuracy: 93.248%, Avg loss: 0.238580
[2022-08-07 15:25:43,622] Test  Error: Accuracy: 93.346%, Avg loss: 0.232728
[2022-08-07 15:25:43,622] Epoch 2---------------
[2022-08-07 15:25:43,623] lr: 1.900000e-03
[2022-08-07 15:25:44,128] loss: 0.212340  [    0/ 4739]
[2022-08-07 15:25:51,659] loss: 0.266115  [  960/ 4739]
[2022-08-07 15:25:59,188] loss: 0.112665  [ 1920/ 4739]
[2022-08-07 15:26:06,719] loss: 0.076728  [ 2880/ 4739]
[2022-08-07 15:26:14,247] loss: 0.040194  [ 3840/ 4739]
[2022-08-07 15:26:34,358] Train Error: Accuracy: 97.426%, Avg loss: 0.106039
[2022-08-07 15:26:40,205] Test  Error: Accuracy: 97.603%, Avg loss: 0.111888
[2022-08-07 15:26:40,205] Epoch 3---------------
[2022-08-07 15:26:40,206] lr: 1.805000e-03
[2022-08-07 15:26:40,710] loss: 0.204891  [    0/ 4739]
[2022-08-07 15:26:48,241] loss: 0.026793  [  960/ 4739]
[2022-08-07 15:26:55,771] loss: 0.051190  [ 1920/ 4739]
[2022-08-07 15:27:03,301] loss: 0.020665  [ 2880/ 4739]
[2022-08-07 15:27:10,831] loss: 0.048943  [ 3840/ 4739]
[2022-08-07 15:27:30,944] Train Error: Accuracy: 87.613%, Avg loss: 0.502720
[2022-08-07 15:27:36,792] Test  Error: Accuracy: 87.818%, Avg loss: 0.495487
[2022-08-07 15:27:36,792] Epoch 4---------------
[2022-08-07 15:27:36,793] lr: 1.260499e-03
[2022-08-07 15:27:37,299] loss: 0.752697  [    0/ 4739]
[2022-08-07 15:27:44,830] loss: 0.023586  [  960/ 4739]
[2022-08-07 15:27:52,360] loss: 0.020572  [ 1920/ 4739]
[2022-08-07 15:27:59,890] loss: 0.013713  [ 2880/ 4739]
[2022-08-07 15:28:07,419] loss: 0.022921  [ 3840/ 4739]
[2022-08-07 15:28:27,531] Train Error: Accuracy: 99.198%, Avg loss: 0.033072
[2022-08-07 15:28:33,385] Test  Error: Accuracy: 98.875%, Avg loss: 0.047228
[2022-08-07 15:28:33,385] Epoch 5---------------
[2022-08-07 15:28:33,386] lr: 1.197474e-03
[2022-08-07 15:28:33,891] loss: 0.018678  [    0/ 4739]
[2022-08-07 15:28:41,421] loss: 0.011163  [  960/ 4739]
[2022-08-07 15:28:48,952] loss: 0.025233  [ 1920/ 4739]
[2022-08-07 15:28:56,483] loss: 0.006909  [ 2880/ 4739]
[2022-08-07 15:29:04,014] loss: 0.003826  [ 3840/ 4739]
[2022-08-07 15:29:24,144] Train Error: Accuracy: 99.747%, Avg loss: 0.013395
[2022-08-07 15:29:29,991] Test  Error: Accuracy: 99.315%, Avg loss: 0.032613
[2022-08-07 15:29:29,992] Epoch 6---------------
[2022-08-07 15:29:29,993] lr: 1.137600e-03
[2022-08-07 15:29:30,498] loss: 0.010727  [    0/ 4739]
[2022-08-07 15:29:38,028] loss: 0.088590  [  960/ 4739]
[2022-08-07 15:29:45,559] loss: 0.009363  [ 1920/ 4739]
[2022-08-07 15:29:53,088] loss: 0.007065  [ 2880/ 4739]
[2022-08-07 15:30:00,619] loss: 0.030186  [ 3840/ 4739]
[2022-08-07 15:30:20,738] Train Error: Accuracy: 96.961%, Avg loss: 0.107331
[2022-08-07 15:30:26,588] Test  Error: Accuracy: 95.793%, Avg loss: 0.142323
[2022-08-07 15:30:26,588] Epoch 7---------------
[2022-08-07 15:30:26,589] lr: 7.944286e-04
[2022-08-07 15:30:27,094] loss: 0.106715  [    0/ 4739]
[2022-08-07 15:30:34,626] loss: 0.004475  [  960/ 4739]
[2022-08-07 15:30:42,157] loss: 0.004074  [ 1920/ 4739]
[2022-08-07 15:30:49,687] loss: 0.003121  [ 2880/ 4739]
[2022-08-07 15:30:57,218] loss: 0.003373  [ 3840/ 4739]
[2022-08-07 15:31:17,337] Train Error: Accuracy: 99.852%, Avg loss: 0.007769
[2022-08-07 15:31:23,188] Test  Error: Accuracy: 99.266%, Avg loss: 0.030946
[2022-08-07 15:31:23,188] Epoch 8---------------
[2022-08-07 15:31:23,189] lr: 7.547072e-04
[2022-08-07 15:31:23,694] loss: 0.008946  [    0/ 4739]
[2022-08-07 15:31:31,225] loss: 0.006657  [  960/ 4739]
[2022-08-07 15:31:38,756] loss: 0.002386  [ 1920/ 4739]
[2022-08-07 15:31:46,288] loss: 0.004189  [ 2880/ 4739]
[2022-08-07 15:31:53,818] loss: 0.002175  [ 3840/ 4739]
[2022-08-07 15:32:13,944] Train Error: Accuracy: 99.916%, Avg loss: 0.007507
[2022-08-07 15:32:19,796] Test  Error: Accuracy: 99.364%, Avg loss: 0.022658
[2022-08-07 15:32:19,797] Epoch 9---------------
[2022-08-07 15:32:19,797] lr: 7.169718e-04
[2022-08-07 15:32:20,302] loss: 0.005713  [    0/ 4739]
[2022-08-07 15:32:27,833] loss: 0.013172  [  960/ 4739]
[2022-08-07 15:32:35,364] loss: 0.011308  [ 1920/ 4739]
[2022-08-07 15:32:42,896] loss: 0.002478  [ 2880/ 4739]
[2022-08-07 15:32:50,427] loss: 0.001519  [ 3840/ 4739]
[2022-08-07 15:33:10,549] Train Error: Accuracy: 99.916%, Avg loss: 0.004242
[2022-08-07 15:33:16,399] Test  Error: Accuracy: 99.658%, Avg loss: 0.017394
[2022-08-07 15:33:16,399] Epoch 10---------------
[2022-08-07 15:33:16,400] lr: 6.811233e-04
[2022-08-07 15:33:16,905] loss: 0.001688  [    0/ 4739]
[2022-08-07 15:33:24,434] loss: 0.003823  [  960/ 4739]
[2022-08-07 15:33:31,965] loss: 0.001193  [ 1920/ 4739]
[2022-08-07 15:33:39,497] loss: 0.001287  [ 2880/ 4739]
[2022-08-07 15:33:47,028] loss: 0.001677  [ 3840/ 4739]
[2022-08-07 15:34:07,152] Train Error: Accuracy: 100.000%, Avg loss: 0.002405
[2022-08-07 15:34:13,001] Test  Error: Accuracy: 99.609%, Avg loss: 0.017818
[2022-08-07 15:34:13,002] Epoch 11---------------
[2022-08-07 15:34:13,003] lr: 5.839780e-04
[2022-08-07 15:34:13,508] loss: 0.000764  [    0/ 4739]
[2022-08-07 15:34:21,038] loss: 0.002950  [  960/ 4739]
[2022-08-07 15:34:28,568] loss: 0.002317  [ 1920/ 4739]
[2022-08-07 15:34:36,097] loss: 0.003059  [ 2880/ 4739]
[2022-08-07 15:34:43,627] loss: 0.001055  [ 3840/ 4739]
[2022-08-07 15:35:03,743] Train Error: Accuracy: 100.000%, Avg loss: 0.001787
[2022-08-07 15:35:09,598] Test  Error: Accuracy: 99.609%, Avg loss: 0.018930
[2022-08-07 15:35:09,598] Epoch 12---------------
[2022-08-07 15:35:09,600] lr: 5.006882e-04
[2022-08-07 15:35:10,103] loss: 0.000911  [    0/ 4739]
[2022-08-07 15:35:17,633] loss: 0.001118  [  960/ 4739]
[2022-08-07 15:35:25,163] loss: 0.001308  [ 1920/ 4739]
[2022-08-07 15:35:32,693] loss: 0.001465  [ 2880/ 4739]
[2022-08-07 15:35:40,223] loss: 0.002043  [ 3840/ 4739]
[2022-08-07 15:36:00,338] Train Error: Accuracy: 100.000%, Avg loss: 0.001530
[2022-08-07 15:36:06,185] Test  Error: Accuracy: 99.560%, Avg loss: 0.015992
[2022-08-07 15:36:06,185] Epoch 13---------------
[2022-08-07 15:36:06,186] lr: 4.756538e-04
[2022-08-07 15:36:06,690] loss: 0.001465  [    0/ 4739]
[2022-08-07 15:36:14,221] loss: 0.001204  [  960/ 4739]
[2022-08-07 15:36:21,751] loss: 0.001248  [ 1920/ 4739]
[2022-08-07 15:36:29,281] loss: 0.003835  [ 2880/ 4739]
[2022-08-07 15:36:36,811] loss: 0.000916  [ 3840/ 4739]
[2022-08-07 15:36:56,924] Train Error: Accuracy: 100.000%, Avg loss: 0.001735
[2022-08-07 15:37:02,773] Test  Error: Accuracy: 99.560%, Avg loss: 0.017639
[2022-08-07 15:37:02,774] Epoch 14---------------
[2022-08-07 15:37:02,775] lr: 4.078137e-04
[2022-08-07 15:37:03,279] loss: 0.001008  [    0/ 4739]
[2022-08-07 15:37:10,810] loss: 0.000777  [  960/ 4739]
[2022-08-07 15:37:18,342] loss: 0.005058  [ 1920/ 4739]
[2022-08-07 15:37:25,873] loss: 0.000749  [ 2880/ 4739]
[2022-08-07 15:37:33,402] loss: 0.000576  [ 3840/ 4739]
[2022-08-07 15:37:53,518] Train Error: Accuracy: 99.979%, Avg loss: 0.001792
[2022-08-07 15:37:59,370] Test  Error: Accuracy: 99.658%, Avg loss: 0.018463
[2022-08-07 15:37:59,370] Epoch 15---------------
[2022-08-07 15:37:59,371] lr: 3.496492e-04
[2022-08-07 15:37:59,876] loss: 0.003760  [    0/ 4739]
[2022-08-07 15:38:07,406] loss: 0.000617  [  960/ 4739]
[2022-08-07 15:38:14,936] loss: 0.001010  [ 1920/ 4739]
[2022-08-07 15:38:22,466] loss: 0.001045  [ 2880/ 4739]
[2022-08-07 15:38:29,996] loss: 0.002338  [ 3840/ 4739]
[2022-08-07 15:38:50,114] Train Error: Accuracy: 99.979%, Avg loss: 0.001898
[2022-08-07 15:38:55,966] Test  Error: Accuracy: 99.413%, Avg loss: 0.018947
[2022-08-07 15:38:55,967] Done!
[2022-08-07 15:38:55,969] Number of parameters:1093386
[2022-08-07 15:38:55,969] ## end time: 2022-08-07 15:38:55.967145
[2022-08-07 15:38:55,970] ## used time: 0:14:09.280776
