[2022-08-06 15:22:11,983] ## start time: 2022-08-06 15:22:11.857155
[2022-08-06 15:22:11,984] Using cuda device
[2022-08-06 15:22:11,985] In train:p&d10.npy.
[2022-08-06 15:22:11,986] One Channel
[2022-08-06 15:22:11,987] With Normal data.
[2022-08-06 15:22:11,987] Nunber of classes:10.
[2022-08-06 15:22:11,987] Nunber of ViT channels:1.
[2022-08-06 15:22:12,175] Totol epochs: 10
[2022-08-06 15:22:12,176] Epoch 1---------------
[2022-08-06 15:22:12,176] lr: 2.000000e-03
[2022-08-06 15:22:12,190] loss: 2.695770  [    0/ 4701]
[2022-08-06 15:22:12,353] loss: 1.983740  [  960/ 4701]
[2022-08-06 15:22:12,512] loss: 1.693331  [ 1920/ 4701]
[2022-08-06 15:22:12,665] loss: 1.663321  [ 2880/ 4701]
[2022-08-06 15:22:12,817] loss: 1.082171  [ 3840/ 4701]
[2022-08-06 15:22:13,211] Train Error: Accuracy: 68.730%, Avg loss: 0.980641
[2022-08-06 15:22:13,331] Test  Error: Accuracy: 68.300%, Avg loss: 0.987505
[2022-08-06 15:22:13,331] Epoch 2---------------
[2022-08-06 15:22:13,332] lr: 1.900000e-03
[2022-08-06 15:22:13,344] loss: 1.080600  [    0/ 4701]
[2022-08-06 15:22:13,496] loss: 0.733200  [  960/ 4701]
[2022-08-06 15:22:13,652] loss: 0.516884  [ 1920/ 4701]
[2022-08-06 15:22:13,802] loss: 0.392396  [ 2880/ 4701]
[2022-08-06 15:22:13,952] loss: 0.421247  [ 3840/ 4701]
[2022-08-06 15:22:14,348] Train Error: Accuracy: 94.086%, Avg loss: 0.258289
[2022-08-06 15:22:14,467] Test  Error: Accuracy: 93.276%, Avg loss: 0.274943
[2022-08-06 15:22:14,468] Epoch 3---------------
[2022-08-06 15:22:14,469] lr: 1.805000e-03
[2022-08-06 15:22:14,480] loss: 0.212453  [    0/ 4701]
[2022-08-06 15:22:14,636] loss: 0.234965  [  960/ 4701]
[2022-08-06 15:22:14,787] loss: 0.102866  [ 1920/ 4701]
[2022-08-06 15:22:14,936] loss: 0.130651  [ 2880/ 4701]
[2022-08-06 15:22:15,084] loss: 0.098546  [ 3840/ 4701]
[2022-08-06 15:22:15,478] Train Error: Accuracy: 97.277%, Avg loss: 0.112145
[2022-08-06 15:22:15,597] Test  Error: Accuracy: 97.118%, Avg loss: 0.123399
[2022-08-06 15:22:15,597] Epoch 4---------------
[2022-08-06 15:22:15,598] lr: 1.714750e-03
[2022-08-06 15:22:15,609] loss: 0.154570  [    0/ 4701]
[2022-08-06 15:22:15,760] loss: 0.088605  [  960/ 4701]
[2022-08-06 15:22:15,909] loss: 0.049923  [ 1920/ 4701]
[2022-08-06 15:22:16,060] loss: 0.109836  [ 2880/ 4701]
[2022-08-06 15:22:16,210] loss: 0.079560  [ 3840/ 4701]
[2022-08-06 15:22:16,606] Train Error: Accuracy: 98.745%, Avg loss: 0.059266
[2022-08-06 15:22:16,725] Test  Error: Accuracy: 97.887%, Avg loss: 0.086113
[2022-08-06 15:22:16,725] Epoch 5---------------
[2022-08-06 15:22:16,726] lr: 1.629012e-03
[2022-08-06 15:22:16,737] loss: 0.067346  [    0/ 4701]
[2022-08-06 15:22:16,890] loss: 0.040778  [  960/ 4701]
[2022-08-06 15:22:17,040] loss: 0.050705  [ 1920/ 4701]
[2022-08-06 15:22:17,194] loss: 0.034489  [ 2880/ 4701]
[2022-08-06 15:22:17,345] loss: 0.025681  [ 3840/ 4701]
[2022-08-06 15:22:17,743] Train Error: Accuracy: 98.086%, Avg loss: 0.070092
[2022-08-06 15:22:17,862] Test  Error: Accuracy: 97.262%, Avg loss: 0.085127
[2022-08-06 15:22:17,862] Epoch 6---------------
[2022-08-06 15:22:17,864] lr: 1.547562e-03
[2022-08-06 15:22:17,875] loss: 0.123696  [    0/ 4701]
[2022-08-06 15:22:18,028] loss: 0.029823  [  960/ 4701]
[2022-08-06 15:22:18,178] loss: 0.038119  [ 1920/ 4701]
[2022-08-06 15:22:18,329] loss: 0.020927  [ 2880/ 4701]
[2022-08-06 15:22:18,482] loss: 0.017266  [ 3840/ 4701]
[2022-08-06 15:22:18,887] Train Error: Accuracy: 99.638%, Avg loss: 0.022966
[2022-08-06 15:22:19,004] Test  Error: Accuracy: 99.183%, Avg loss: 0.036247
[2022-08-06 15:22:19,005] Epoch 7---------------
[2022-08-06 15:22:19,005] lr: 1.470184e-03
[2022-08-06 15:22:19,018] loss: 0.038296  [    0/ 4701]
[2022-08-06 15:22:19,169] loss: 0.027112  [  960/ 4701]
[2022-08-06 15:22:19,319] loss: 0.037811  [ 1920/ 4701]
[2022-08-06 15:22:19,469] loss: 0.078198  [ 2880/ 4701]
[2022-08-06 15:22:19,623] loss: 0.020296  [ 3840/ 4701]
[2022-08-06 15:22:20,023] Train Error: Accuracy: 99.617%, Avg loss: 0.020271
[2022-08-06 15:22:20,142] Test  Error: Accuracy: 99.039%, Avg loss: 0.039268
[2022-08-06 15:22:20,142] Epoch 8---------------
[2022-08-06 15:22:20,143] lr: 1.260499e-03
[2022-08-06 15:22:20,155] loss: 0.007419  [    0/ 4701]
[2022-08-06 15:22:20,307] loss: 0.010528  [  960/ 4701]
[2022-08-06 15:22:20,458] loss: 0.014467  [ 1920/ 4701]
[2022-08-06 15:22:20,608] loss: 0.009100  [ 2880/ 4701]
[2022-08-06 15:22:20,762] loss: 0.007872  [ 3840/ 4701]
[2022-08-06 15:22:21,154] Train Error: Accuracy: 99.851%, Avg loss: 0.012198
[2022-08-06 15:22:21,270] Test  Error: Accuracy: 99.280%, Avg loss: 0.030324
[2022-08-06 15:22:21,271] Epoch 9---------------
[2022-08-06 15:22:21,272] lr: 1.197474e-03
[2022-08-06 15:22:21,283] loss: 0.016263  [    0/ 4701]
[2022-08-06 15:22:21,433] loss: 0.008271  [  960/ 4701]
[2022-08-06 15:22:21,582] loss: 0.003861  [ 1920/ 4701]
[2022-08-06 15:22:21,735] loss: 0.020692  [ 2880/ 4701]
[2022-08-06 15:22:21,889] loss: 0.006197  [ 3840/ 4701]
[2022-08-06 15:22:22,278] Train Error: Accuracy: 99.872%, Avg loss: 0.010774
[2022-08-06 15:22:22,396] Test  Error: Accuracy: 99.424%, Avg loss: 0.026523
[2022-08-06 15:22:22,396] Epoch 10---------------
[2022-08-06 15:22:22,398] lr: 1.137600e-03
[2022-08-06 15:22:22,409] loss: 0.018731  [    0/ 4701]
[2022-08-06 15:22:22,559] loss: 0.016674  [  960/ 4701]
[2022-08-06 15:22:22,711] loss: 0.004750  [ 1920/ 4701]
[2022-08-06 15:22:22,864] loss: 0.021721  [ 2880/ 4701]
[2022-08-06 15:22:23,013] loss: 0.003011  [ 3840/ 4701]
[2022-08-06 15:22:23,403] Train Error: Accuracy: 99.872%, Avg loss: 0.008680
[2022-08-06 15:22:23,519] Test  Error: Accuracy: 99.424%, Avg loss: 0.024033
[2022-08-06 15:22:23,520] Done!
[2022-08-06 15:22:23,522] Number of parameters:42954
[2022-08-06 15:22:23,522] ## end time: 2022-08-06 15:22:23.520479
[2022-08-06 15:22:23,522] ## used time: 0:00:11.663324
