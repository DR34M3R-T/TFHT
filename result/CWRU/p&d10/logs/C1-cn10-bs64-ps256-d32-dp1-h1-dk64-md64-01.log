[2022-08-06 15:16:28,765] ## start time: 2022-08-06 15:16:28.643859
[2022-08-06 15:16:28,766] Using cuda device
[2022-08-06 15:16:28,766] In train:p&d10.npy.
[2022-08-06 15:16:28,766] One Channel
[2022-08-06 15:16:28,767] With Normal data.
[2022-08-06 15:16:28,767] Nunber of classes:10.
[2022-08-06 15:16:28,767] Nunber of ViT channels:1.
[2022-08-06 15:16:29,780] Totol epochs: 10
[2022-08-06 15:16:29,781] Epoch 1---------------
[2022-08-06 15:16:29,781] lr: 2.000000e-03
[2022-08-06 15:16:31,291] loss: 2.344892  [    0/ 4763]
[2022-08-06 15:16:31,442] loss: 1.702036  [  960/ 4763]
[2022-08-06 15:16:31,595] loss: 1.262476  [ 1920/ 4763]
[2022-08-06 15:16:31,747] loss: 1.082837  [ 2880/ 4763]
[2022-08-06 15:16:31,902] loss: 0.889365  [ 3840/ 4763]
[2022-08-06 15:16:32,310] Train Error: Accuracy: 79.698%, Avg loss: 0.639949
[2022-08-06 15:16:32,422] Test  Error: Accuracy: 79.059%, Avg loss: 0.655561
[2022-08-06 15:16:32,422] Epoch 2---------------
[2022-08-06 15:16:32,423] lr: 1.900000e-03
[2022-08-06 15:16:32,434] loss: 0.538443  [    0/ 4763]
[2022-08-06 15:16:32,580] loss: 0.494685  [  960/ 4763]
[2022-08-06 15:16:32,743] loss: 0.296565  [ 1920/ 4763]
[2022-08-06 15:16:32,890] loss: 0.238126  [ 2880/ 4763]
[2022-08-06 15:16:33,042] loss: 0.214959  [ 3840/ 4763]
[2022-08-06 15:16:33,447] Train Error: Accuracy: 67.122%, Avg loss: 0.932939
[2022-08-06 15:16:33,562] Test  Error: Accuracy: 66.238%, Avg loss: 0.959985
[2022-08-06 15:16:33,562] Epoch 3---------------
[2022-08-06 15:16:33,563] lr: 1.326841e-03
[2022-08-06 15:16:33,574] loss: 1.298522  [    0/ 4763]
[2022-08-06 15:16:33,727] loss: 0.111195  [  960/ 4763]
[2022-08-06 15:16:33,881] loss: 0.074365  [ 1920/ 4763]
[2022-08-06 15:16:34,028] loss: 0.095506  [ 2880/ 4763]
[2022-08-06 15:16:34,187] loss: 0.082913  [ 3840/ 4763]
[2022-08-06 15:16:34,590] Train Error: Accuracy: 98.761%, Avg loss: 0.079050
[2022-08-06 15:16:34,705] Test  Error: Accuracy: 98.218%, Avg loss: 0.088756
[2022-08-06 15:16:34,705] Epoch 4---------------
[2022-08-06 15:16:34,706] lr: 1.260499e-03
[2022-08-06 15:16:34,719] loss: 0.074261  [    0/ 4763]
[2022-08-06 15:16:34,871] loss: 0.052454  [  960/ 4763]
[2022-08-06 15:16:35,021] loss: 0.080881  [ 1920/ 4763]
[2022-08-06 15:16:35,168] loss: 0.032414  [ 2880/ 4763]
[2022-08-06 15:16:35,317] loss: 0.037274  [ 3840/ 4763]
[2022-08-06 15:16:35,723] Train Error: Accuracy: 99.139%, Avg loss: 0.050380
[2022-08-06 15:16:35,842] Test  Error: Accuracy: 98.713%, Avg loss: 0.061213
[2022-08-06 15:16:35,842] Epoch 5---------------
[2022-08-06 15:16:35,843] lr: 1.197474e-03
[2022-08-06 15:16:35,855] loss: 0.028789  [    0/ 4763]
[2022-08-06 15:16:36,006] loss: 0.035463  [  960/ 4763]
[2022-08-06 15:16:36,157] loss: 0.031561  [ 1920/ 4763]
[2022-08-06 15:16:36,307] loss: 0.043322  [ 2880/ 4763]
[2022-08-06 15:16:36,456] loss: 0.022555  [ 3840/ 4763]
[2022-08-06 15:16:36,865] Train Error: Accuracy: 99.517%, Avg loss: 0.028580
[2022-08-06 15:16:36,980] Test  Error: Accuracy: 99.307%, Avg loss: 0.039380
[2022-08-06 15:16:36,980] Epoch 6---------------
[2022-08-06 15:16:36,981] lr: 1.137600e-03
[2022-08-06 15:16:36,995] loss: 0.020385  [    0/ 4763]
[2022-08-06 15:16:37,145] loss: 0.040750  [  960/ 4763]
[2022-08-06 15:16:37,299] loss: 0.012760  [ 1920/ 4763]
[2022-08-06 15:16:37,448] loss: 0.033371  [ 2880/ 4763]
[2022-08-06 15:16:37,597] loss: 0.011845  [ 3840/ 4763]
[2022-08-06 15:16:38,007] Train Error: Accuracy: 99.538%, Avg loss: 0.031032
[2022-08-06 15:16:38,127] Test  Error: Accuracy: 99.158%, Avg loss: 0.038576
[2022-08-06 15:16:38,128] Epoch 7---------------
[2022-08-06 15:16:38,129] lr: 1.080720e-03
[2022-08-06 15:16:38,140] loss: 0.030476  [    0/ 4763]
[2022-08-06 15:16:38,290] loss: 0.035888  [  960/ 4763]
[2022-08-06 15:16:38,440] loss: 0.009658  [ 1920/ 4763]
[2022-08-06 15:16:38,593] loss: 0.084045  [ 2880/ 4763]
[2022-08-06 15:16:38,743] loss: 0.028354  [ 3840/ 4763]
[2022-08-06 15:16:39,155] Train Error: Accuracy: 99.685%, Avg loss: 0.021589
[2022-08-06 15:16:39,272] Test  Error: Accuracy: 99.307%, Avg loss: 0.031917
[2022-08-06 15:16:39,273] Epoch 8---------------
[2022-08-06 15:16:39,274] lr: 1.026684e-03
[2022-08-06 15:16:39,286] loss: 0.021027  [    0/ 4763]
[2022-08-06 15:16:39,435] loss: 0.022037  [  960/ 4763]
[2022-08-06 15:16:39,587] loss: 0.009389  [ 1920/ 4763]
[2022-08-06 15:16:39,736] loss: 0.029727  [ 2880/ 4763]
[2022-08-06 15:16:39,884] loss: 0.011257  [ 3840/ 4763]
[2022-08-06 15:16:40,299] Train Error: Accuracy: 99.832%, Avg loss: 0.015265
[2022-08-06 15:16:40,412] Test  Error: Accuracy: 99.455%, Avg loss: 0.022495
[2022-08-06 15:16:40,413] Epoch 9---------------
[2022-08-06 15:16:40,414] lr: 9.753500e-04
[2022-08-06 15:16:40,425] loss: 0.009085  [    0/ 4763]
[2022-08-06 15:16:40,574] loss: 0.009612  [  960/ 4763]
[2022-08-06 15:16:40,724] loss: 0.006349  [ 1920/ 4763]
[2022-08-06 15:16:40,871] loss: 0.014170  [ 2880/ 4763]
[2022-08-06 15:16:41,021] loss: 0.021116  [ 3840/ 4763]
[2022-08-06 15:16:41,428] Train Error: Accuracy: 99.832%, Avg loss: 0.010055
[2022-08-06 15:16:41,543] Test  Error: Accuracy: 99.703%, Avg loss: 0.018461
[2022-08-06 15:16:41,543] Epoch 10---------------
[2022-08-06 15:16:41,544] lr: 9.265825e-04
[2022-08-06 15:16:41,556] loss: 0.016608  [    0/ 4763]
[2022-08-06 15:16:41,708] loss: 0.004689  [  960/ 4763]
[2022-08-06 15:16:41,862] loss: 0.007562  [ 1920/ 4763]
[2022-08-06 15:16:42,011] loss: 0.006739  [ 2880/ 4763]
[2022-08-06 15:16:42,161] loss: 0.004741  [ 3840/ 4763]
[2022-08-06 15:16:42,568] Train Error: Accuracy: 99.769%, Avg loss: 0.015170
[2022-08-06 15:16:42,681] Test  Error: Accuracy: 99.406%, Avg loss: 0.025853
[2022-08-06 15:16:42,681] Done!
[2022-08-06 15:16:42,683] Number of parameters:42954
[2022-08-06 15:16:42,683] ## end time: 2022-08-06 15:16:42.681353
[2022-08-06 15:16:42,684] ## used time: 0:00:14.037494
