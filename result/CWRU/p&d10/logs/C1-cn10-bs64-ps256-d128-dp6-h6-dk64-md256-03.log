[2022-08-03 17:06:13,063] ## start time: 2022-08-03 17:06:12.915142
[2022-08-03 17:06:13,064] Using cuda device
[2022-08-03 17:06:13,065] In train:p&d10.npy.
[2022-08-03 17:06:13,066] One Channel
[2022-08-03 17:06:13,066] With Normal data.
[2022-08-03 17:06:13,067] Nunber of classes:10.
[2022-08-03 17:06:13,068] Nunber of ViT channels:1.
[2022-08-03 17:06:13,329] Totol epochs: 15
[2022-08-03 17:06:13,332] Epoch 1---------------
[2022-08-03 17:06:13,332] lr: 2.000000e-03
[2022-08-03 17:06:13,442] loss: 2.500260  [    0/ 4802]
[2022-08-03 17:06:15,075] loss: 1.674955  [  960/ 4802]
[2022-08-03 17:06:16,704] loss: 1.830083  [ 1920/ 4802]
[2022-08-03 17:06:18,336] loss: 0.182513  [ 2880/ 4802]
[2022-08-03 17:06:19,970] loss: 0.026530  [ 3840/ 4802]
[2022-08-03 17:06:21,524] loss: 0.007798  [  150/ 4802]
[2022-08-03 17:06:22,579] Test Error: Accuracy: 99.849%, Avg loss: 0.022515
[2022-08-03 17:06:22,580] Epoch 2---------------
[2022-08-03 17:06:22,581] lr: 1.900000e-03
[2022-08-03 17:06:22,692] loss: 0.015304  [    0/ 4802]
[2022-08-03 17:06:24,326] loss: 0.007124  [  960/ 4802]
[2022-08-03 17:06:25,954] loss: 0.012755  [ 1920/ 4802]
[2022-08-03 17:06:27,585] loss: 0.077758  [ 2880/ 4802]
[2022-08-03 17:06:29,219] loss: 0.842558  [ 3840/ 4802]
[2022-08-03 17:06:30,776] loss: 0.064272  [  150/ 4802]
[2022-08-03 17:06:31,830] Test Error: Accuracy: 98.637%, Avg loss: 0.065176
[2022-08-03 17:06:31,830] Epoch 3---------------
[2022-08-03 17:06:31,831] lr: 1.326841e-03
[2022-08-03 17:06:31,942] loss: 0.081894  [    0/ 4802]
[2022-08-03 17:06:33,571] loss: 0.015613  [  960/ 4802]
[2022-08-03 17:06:35,197] loss: 0.007022  [ 1920/ 4802]
[2022-08-03 17:06:36,828] loss: 0.006193  [ 2880/ 4802]
[2022-08-03 17:06:38,457] loss: 0.005046  [ 3840/ 4802]
[2022-08-03 17:06:40,015] loss: 0.005673  [  150/ 4802]
[2022-08-03 17:06:41,068] Test Error: Accuracy: 99.950%, Avg loss: 0.005709
[2022-08-03 17:06:41,068] Epoch 4---------------
[2022-08-03 17:06:41,068] lr: 1.260499e-03
[2022-08-03 17:06:41,179] loss: 0.003059  [    0/ 4802]
[2022-08-03 17:06:42,813] loss: 0.003722  [  960/ 4802]
[2022-08-03 17:06:44,444] loss: 0.003581  [ 1920/ 4802]
[2022-08-03 17:06:46,073] loss: 0.003080  [ 2880/ 4802]
[2022-08-03 17:06:47,707] loss: 0.002689  [ 3840/ 4802]
[2022-08-03 17:06:49,264] loss: 0.001223  [  150/ 4802]
[2022-08-03 17:06:50,316] Test Error: Accuracy: 100.000%, Avg loss: 0.003331
[2022-08-03 17:06:50,317] Epoch 5---------------
[2022-08-03 17:06:50,318] lr: 1.197474e-03
[2022-08-03 17:06:50,429] loss: 0.002336  [    0/ 4802]
[2022-08-03 17:06:52,058] loss: 0.005220  [  960/ 4802]
[2022-08-03 17:06:53,691] loss: 0.002191  [ 1920/ 4802]
[2022-08-03 17:06:55,319] loss: 0.002286  [ 2880/ 4802]
[2022-08-03 17:06:56,950] loss: 0.002651  [ 3840/ 4802]
[2022-08-03 17:06:58,515] loss: 0.001192  [  150/ 4802]
[2022-08-03 17:06:59,573] Test Error: Accuracy: 99.899%, Avg loss: 0.004859
[2022-08-03 17:06:59,574] Epoch 6---------------
[2022-08-03 17:06:59,576] lr: 8.362407e-04
[2022-08-03 17:06:59,688] loss: 0.002407  [    0/ 4802]
[2022-08-03 17:07:01,321] loss: 0.002049  [  960/ 4802]
[2022-08-03 17:07:02,957] loss: 0.001915  [ 1920/ 4802]
[2022-08-03 17:07:04,586] loss: 0.001600  [ 2880/ 4802]
[2022-08-03 17:07:06,220] loss: 0.001886  [ 3840/ 4802]
[2022-08-03 17:07:07,776] loss: 0.001292  [  150/ 4802]
[2022-08-03 17:07:08,831] Test Error: Accuracy: 99.950%, Avg loss: 0.002336
[2022-08-03 17:07:08,831] Epoch 7---------------
[2022-08-03 17:07:08,832] lr: 7.944286e-04
[2022-08-03 17:07:08,943] loss: 0.001839  [    0/ 4802]
[2022-08-03 17:07:10,574] loss: 0.001601  [  960/ 4802]
[2022-08-03 17:07:12,207] loss: 0.001289  [ 1920/ 4802]
[2022-08-03 17:07:13,842] loss: 0.001294  [ 2880/ 4802]
[2022-08-03 17:07:15,473] loss: 0.001564  [ 3840/ 4802]
[2022-08-03 17:07:17,032] loss: 0.001513  [  150/ 4802]
[2022-08-03 17:07:18,088] Test Error: Accuracy: 100.000%, Avg loss: 0.001643
[2022-08-03 17:07:18,088] Epoch 8---------------
[2022-08-03 17:07:18,090] lr: 7.547072e-04
[2022-08-03 17:07:18,201] loss: 0.001290  [    0/ 4802]
[2022-08-03 17:07:19,828] loss: 0.001277  [  960/ 4802]
[2022-08-03 17:07:21,461] loss: 0.001435  [ 1920/ 4802]
[2022-08-03 17:07:23,091] loss: 0.001126  [ 2880/ 4802]
[2022-08-03 17:07:24,718] loss: 0.000975  [ 3840/ 4802]
[2022-08-03 17:07:26,273] loss: 0.000810  [  150/ 4802]
[2022-08-03 17:07:27,327] Test Error: Accuracy: 99.950%, Avg loss: 0.001776
[2022-08-03 17:07:27,327] Epoch 9---------------
[2022-08-03 17:07:27,328] lr: 6.470671e-04
[2022-08-03 17:07:27,438] loss: 0.001073  [    0/ 4802]
[2022-08-03 17:07:29,069] loss: 0.001005  [  960/ 4802]
[2022-08-03 17:07:30,699] loss: 0.001112  [ 1920/ 4802]
[2022-08-03 17:07:32,327] loss: 0.000892  [ 2880/ 4802]
[2022-08-03 17:07:33,957] loss: 0.001136  [ 3840/ 4802]
[2022-08-03 17:07:35,513] loss: 0.000961  [  150/ 4802]
[2022-08-03 17:07:36,570] Test Error: Accuracy: 100.000%, Avg loss: 0.001282
[2022-08-03 17:07:36,570] Epoch 10---------------
[2022-08-03 17:07:36,571] lr: 6.147137e-04
[2022-08-03 17:07:36,681] loss: 0.001177  [    0/ 4802]
[2022-08-03 17:07:38,318] loss: 0.000951  [  960/ 4802]
[2022-08-03 17:07:39,950] loss: 0.001072  [ 1920/ 4802]
[2022-08-03 17:07:41,581] loss: 0.001282  [ 2880/ 4802]
[2022-08-03 17:07:43,213] loss: 0.000860  [ 3840/ 4802]
[2022-08-03 17:07:44,769] loss: 0.000434  [  150/ 4802]
[2022-08-03 17:07:45,826] Test Error: Accuracy: 100.000%, Avg loss: 0.001284
[2022-08-03 17:07:45,826] Epoch 11---------------
[2022-08-03 17:07:45,828] lr: 5.270402e-04
[2022-08-03 17:07:45,939] loss: 0.000903  [    0/ 4802]
[2022-08-03 17:07:47,567] loss: 0.000943  [  960/ 4802]
[2022-08-03 17:08:00,767] loss: 0.000961  [ 1920/ 4802]
[2022-08-03 17:08:02,420] loss: 0.000908  [ 2880/ 4802]
[2022-08-03 17:08:04,074] loss: 0.000930  [ 3840/ 4802]
[2022-08-03 17:08:05,655] loss: 0.001551  [  150/ 4802]
[2022-08-03 17:08:06,701] Test Error: Accuracy: 100.000%, Avg loss: 0.001122
[2022-08-03 17:08:06,701] Epoch 12---------------
[2022-08-03 17:08:06,702] lr: 5.006882e-04
[2022-08-03 17:08:06,813] loss: 0.000908  [    0/ 4802]
[2022-08-03 17:08:08,467] loss: 0.000812  [  960/ 4802]
[2022-08-03 17:08:10,121] loss: 0.000714  [ 1920/ 4802]
[2022-08-03 17:08:11,775] loss: 0.000822  [ 2880/ 4802]
[2022-08-03 17:08:13,430] loss: 0.000849  [ 3840/ 4802]
[2022-08-03 17:08:15,011] loss: 0.000709  [  150/ 4802]
[2022-08-03 17:08:16,060] Test Error: Accuracy: 100.000%, Avg loss: 0.001139
[2022-08-03 17:08:16,060] Epoch 13---------------
[2022-08-03 17:08:16,061] lr: 4.292775e-04
[2022-08-03 17:08:16,175] loss: 0.000900  [    0/ 4802]
[2022-08-03 17:08:17,829] loss: 0.000692  [  960/ 4802]
[2022-08-03 17:08:19,483] loss: 0.000841  [ 1920/ 4802]
[2022-08-03 17:08:21,138] loss: 0.000820  [ 2880/ 4802]
[2022-08-03 17:08:22,791] loss: 0.000720  [ 3840/ 4802]
[2022-08-03 17:08:24,371] loss: 0.000892  [  150/ 4802]
[2022-08-03 17:08:25,415] Test Error: Accuracy: 100.000%, Avg loss: 0.000936
[2022-08-03 17:08:25,415] Epoch 14---------------
[2022-08-03 17:08:25,416] lr: 4.078137e-04
[2022-08-03 17:08:25,529] loss: 0.000863  [    0/ 4802]
[2022-08-03 17:08:27,184] loss: 0.000984  [  960/ 4802]
[2022-08-03 17:08:28,840] loss: 0.000791  [ 1920/ 4802]
[2022-08-03 17:08:30,496] loss: 0.000688  [ 2880/ 4802]
[2022-08-03 17:08:32,148] loss: 0.000742  [ 3840/ 4802]
[2022-08-03 17:08:33,731] loss: 0.001137  [  150/ 4802]
[2022-08-03 17:08:34,775] Test Error: Accuracy: 100.000%, Avg loss: 0.000934
[2022-08-03 17:08:34,776] Epoch 15---------------
[2022-08-03 17:08:34,777] lr: 3.874230e-04
[2022-08-03 17:08:34,890] loss: 0.000732  [    0/ 4802]
[2022-08-03 17:08:36,546] loss: 0.000796  [  960/ 4802]
[2022-08-03 17:08:38,201] loss: 0.000610  [ 1920/ 4802]
[2022-08-03 17:08:39,857] loss: 0.000721  [ 2880/ 4802]
[2022-08-03 17:08:41,510] loss: 0.000779  [ 3840/ 4802]
[2022-08-03 17:08:43,092] loss: 0.000689  [  150/ 4802]
[2022-08-03 17:08:44,141] Test Error: Accuracy: 100.000%, Avg loss: 0.001138
[2022-08-03 17:08:44,141] Done!
[2022-08-03 17:08:44,145] Number of parameters:3229450
[2022-08-03 17:08:44,145] ## end time: 2022-08-03 17:08:44.141847
[2022-08-03 17:08:44,146] ## used time: 0:02:31.226705
