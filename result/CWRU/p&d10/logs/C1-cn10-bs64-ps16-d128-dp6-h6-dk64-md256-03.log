[2022-08-03 17:56:24,025] ## start time: 2022-08-03 17:56:23.886271
[2022-08-03 17:56:24,026] Using cuda device
[2022-08-03 17:56:24,028] In train:p&d10.npy.
[2022-08-03 17:56:24,030] One Channel
[2022-08-03 17:56:24,030] With Normal data.
[2022-08-03 17:56:24,031] Nunber of classes:10.
[2022-08-03 17:56:24,031] Nunber of ViT channels:1.
[2022-08-03 17:56:24,290] Totol epochs: 10
[2022-08-03 17:56:24,293] Epoch 1---------------
[2022-08-03 17:56:24,293] lr: 2.000000e-03
[2022-08-03 17:56:25,790] loss: 2.466414  [    0/ 4723]
[2022-08-03 17:56:48,226] loss: 1.541779  [  960/ 4723]
[2022-08-03 17:57:10,660] loss: 1.720946  [ 1920/ 4723]
[2022-08-03 17:57:33,096] loss: 1.222337  [ 2880/ 4723]
[2022-08-03 17:57:55,529] loss: 0.570133  [ 3840/ 4723]
[2022-08-03 17:58:32,071] Test Error: Accuracy: 84.563%, Avg loss: 0.452368
[2022-08-03 17:58:32,072] Epoch 2---------------
[2022-08-03 17:58:32,073] lr: 1.900000e-03
[2022-08-03 17:58:33,570] loss: 0.302986  [    0/ 4723]
[2022-08-03 17:58:56,006] loss: 0.165911  [  960/ 4723]
[2022-08-03 17:59:18,439] loss: 0.465029  [ 1920/ 4723]
[2022-08-03 17:59:40,873] loss: 0.184115  [ 2880/ 4723]
[2022-08-03 18:00:03,308] loss: 0.031513  [ 3840/ 4723]
[2022-08-03 18:00:39,852] Test Error: Accuracy: 98.786%, Avg loss: 0.060297
[2022-08-03 18:00:39,852] Epoch 3---------------
[2022-08-03 18:00:39,853] lr: 1.805000e-03
[2022-08-03 18:00:41,352] loss: 0.069400  [    0/ 4723]
[2022-08-03 18:01:03,787] loss: 0.038691  [  960/ 4723]
[2022-08-03 18:01:26,221] loss: 0.096031  [ 1920/ 4723]
[2022-08-03 18:01:48,655] loss: 0.033035  [ 2880/ 4723]
[2022-08-03 18:02:11,091] loss: 0.026109  [ 3840/ 4723]
[2022-08-03 18:02:47,637] Test Error: Accuracy: 99.417%, Avg loss: 0.025134
[2022-08-03 18:02:47,638] Epoch 4---------------
[2022-08-03 18:02:47,640] lr: 1.714750e-03
[2022-08-03 18:02:49,138] loss: 0.012417  [    0/ 4723]
[2022-08-03 18:03:11,576] loss: 0.054098  [  960/ 4723]
[2022-08-03 18:03:34,012] loss: 0.243479  [ 1920/ 4723]
[2022-08-03 18:03:56,449] loss: 0.109324  [ 2880/ 4723]
[2022-08-03 18:04:18,886] loss: 0.050444  [ 3840/ 4723]
[2022-08-03 18:04:55,437] Test Error: Accuracy: 99.709%, Avg loss: 0.019260
[2022-08-03 18:04:55,438] Epoch 5---------------
[2022-08-03 18:04:55,438] lr: 1.629012e-03
[2022-08-03 18:04:56,935] loss: 0.021114  [    0/ 4723]
[2022-08-03 18:05:19,375] loss: 0.009288  [  960/ 4723]
[2022-08-03 18:05:41,814] loss: 0.029636  [ 1920/ 4723]
[2022-08-03 18:06:04,247] loss: 0.003796  [ 2880/ 4723]
[2022-08-03 18:06:26,681] loss: 0.006799  [ 3840/ 4723]
[2022-08-03 18:07:03,218] Test Error: Accuracy: 98.932%, Avg loss: 0.032321
[2022-08-03 18:07:03,218] Epoch 6---------------
[2022-08-03 18:07:03,219] lr: 1.137600e-03
[2022-08-03 18:07:04,717] loss: 0.009803  [    0/ 4723]
[2022-08-03 18:07:27,150] loss: 0.003392  [  960/ 4723]
[2022-08-03 18:07:49,583] loss: 0.005982  [ 1920/ 4723]
[2022-08-03 18:08:12,015] loss: 0.005221  [ 2880/ 4723]
[2022-08-03 18:08:34,448] loss: 0.006492  [ 3840/ 4723]
[2022-08-03 18:09:10,990] Test Error: Accuracy: 99.563%, Avg loss: 0.019172
[2022-08-03 18:09:10,990] Epoch 7---------------
[2022-08-03 18:09:10,991] lr: 1.080720e-03
[2022-08-03 18:09:12,489] loss: 0.011258  [    0/ 4723]
[2022-08-03 18:09:34,921] loss: 0.032827  [  960/ 4723]
[2022-08-03 18:09:57,355] loss: 0.004485  [ 1920/ 4723]
[2022-08-03 18:10:19,788] loss: 0.001699  [ 2880/ 4723]
[2022-08-03 18:10:42,222] loss: 0.004400  [ 3840/ 4723]
[2022-08-03 18:11:18,767] Test Error: Accuracy: 98.495%, Avg loss: 0.039960
[2022-08-03 18:11:18,767] Epoch 8---------------
[2022-08-03 18:11:18,768] lr: 7.547072e-04
[2022-08-03 18:11:20,266] loss: 0.068357  [    0/ 4723]
[2022-08-03 18:11:42,699] loss: 0.001855  [  960/ 4723]
[2022-08-03 18:12:05,132] loss: 0.002683  [ 1920/ 4723]
[2022-08-03 18:12:27,565] loss: 0.003808  [ 2880/ 4723]
[2022-08-03 18:12:49,999] loss: 0.003173  [ 3840/ 4723]
[2022-08-03 18:13:26,537] Test Error: Accuracy: 99.951%, Avg loss: 0.006082
[2022-08-03 18:13:26,537] Epoch 9---------------
[2022-08-03 18:13:26,538] lr: 7.169718e-04
[2022-08-03 18:13:28,036] loss: 0.001640  [    0/ 4723]
[2022-08-03 18:13:50,470] loss: 0.001649  [  960/ 4723]
[2022-08-03 18:14:12,902] loss: 0.002405  [ 1920/ 4723]
[2022-08-03 18:14:35,337] loss: 0.001932  [ 2880/ 4723]
[2022-08-03 18:14:57,769] loss: 0.001380  [ 3840/ 4723]
[2022-08-03 18:15:34,307] Test Error: Accuracy: 99.951%, Avg loss: 0.003970
[2022-08-03 18:15:34,308] Epoch 10---------------
[2022-08-03 18:15:34,309] lr: 6.811233e-04
[2022-08-03 18:15:35,807] loss: 0.001610  [    0/ 4723]
[2022-08-03 18:15:58,241] loss: 0.000982  [  960/ 4723]
[2022-08-03 18:16:20,674] loss: 0.001090  [ 1920/ 4723]
[2022-08-03 18:16:43,107] loss: 0.001501  [ 2880/ 4723]
[2022-08-03 18:17:05,541] loss: 0.000987  [ 3840/ 4723]
[2022-08-03 18:17:42,086] Test Error: Accuracy: 99.757%, Avg loss: 0.006145
[2022-08-03 18:17:42,087] Done!
[2022-08-03 18:17:42,091] Number of parameters:3198730
[2022-08-03 18:17:42,091] ## end time: 2022-08-03 18:17:42.087686
[2022-08-03 18:17:42,092] ## used time: 0:21:18.201415
