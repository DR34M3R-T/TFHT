[2022-08-03 16:49:35,501] ## start time: 2022-08-03 16:49:35.351411
[2022-08-03 16:49:35,501] Using cuda device
[2022-08-03 16:49:35,502] In train:p&d10.npy.
[2022-08-03 16:49:35,503] One Channel
[2022-08-03 16:49:35,504] With Normal data.
[2022-08-03 16:49:35,504] Nunber of classes:10.
[2022-08-03 16:49:35,505] Nunber of ViT channels:1.
[2022-08-03 16:49:35,761] Totol epochs: 15
[2022-08-03 16:49:35,763] Epoch 1---------------
[2022-08-03 16:49:35,764] lr: 2.000000e-03
[2022-08-03 16:49:35,989] loss: 2.362670  [    0/ 4689]
[2022-08-03 16:49:38,544] loss: 1.875480  [  960/ 4689]
[2022-08-03 16:49:41,086] loss: 1.511614  [ 1920/ 4689]
[2022-08-03 16:49:43,630] loss: 0.815096  [ 2880/ 4689]
[2022-08-03 16:49:46,172] loss: 0.164598  [ 3840/ 4689]
[2022-08-03 16:49:50,152] Test Error: Accuracy: 96.896%, Avg loss: 0.113787
[2022-08-03 16:49:50,152] Epoch 2---------------
[2022-08-03 16:49:50,153] lr: 1.900000e-03
[2022-08-03 16:49:50,325] loss: 0.108788  [    0/ 4689]
[2022-08-03 16:49:52,879] loss: 0.027264  [  960/ 4689]
[2022-08-03 16:49:55,434] loss: 0.016119  [ 1920/ 4689]
[2022-08-03 16:49:57,989] loss: 0.017195  [ 2880/ 4689]
[2022-08-03 16:50:00,548] loss: 0.008982  [ 3840/ 4689]
[2022-08-03 16:50:04,538] Test Error: Accuracy: 99.857%, Avg loss: 0.014038
[2022-08-03 16:50:04,538] Epoch 3---------------
[2022-08-03 16:50:04,539] lr: 1.805000e-03
[2022-08-03 16:50:04,711] loss: 0.014452  [    0/ 4689]
[2022-08-03 16:50:07,265] loss: 0.007176  [  960/ 4689]
[2022-08-03 16:50:09,819] loss: 0.004191  [ 1920/ 4689]
[2022-08-03 16:50:12,374] loss: 0.004474  [ 2880/ 4689]
[2022-08-03 16:50:14,927] loss: 0.002904  [ 3840/ 4689]
[2022-08-03 16:50:18,924] Test Error: Accuracy: 100.000%, Avg loss: 0.004420
[2022-08-03 16:50:18,925] Epoch 4---------------
[2022-08-03 16:50:18,927] lr: 1.714750e-03
[2022-08-03 16:50:19,100] loss: 0.003405  [    0/ 4689]
[2022-08-03 16:50:21,656] loss: 0.002896  [  960/ 4689]
[2022-08-03 16:50:24,230] loss: 0.004205  [ 1920/ 4689]
[2022-08-03 16:50:26,803] loss: 0.751463  [ 2880/ 4689]
[2022-08-03 16:50:29,376] loss: 0.079970  [ 3840/ 4689]
[2022-08-03 16:50:33,395] Test Error: Accuracy: 99.522%, Avg loss: 0.037763
[2022-08-03 16:50:33,396] Epoch 5---------------
[2022-08-03 16:50:33,397] lr: 1.197474e-03
[2022-08-03 16:50:33,570] loss: 0.072090  [    0/ 4689]
[2022-08-03 16:50:36,147] loss: 0.016095  [  960/ 4689]
[2022-08-03 16:50:38,718] loss: 0.008687  [ 1920/ 4689]
[2022-08-03 16:50:41,286] loss: 0.007562  [ 2880/ 4689]
[2022-08-03 16:50:43,853] loss: 0.006317  [ 3840/ 4689]
[2022-08-03 16:50:47,870] Test Error: Accuracy: 99.904%, Avg loss: 0.009764
[2022-08-03 16:50:47,870] Epoch 6---------------
[2022-08-03 16:50:47,871] lr: 1.137600e-03
[2022-08-03 16:50:48,045] loss: 0.004951  [    0/ 4689]
[2022-08-03 16:50:50,615] loss: 0.006732  [  960/ 4689]
[2022-08-03 16:50:53,184] loss: 0.004584  [ 1920/ 4689]
[2022-08-03 16:50:55,754] loss: 0.004331  [ 2880/ 4689]
[2022-08-03 16:50:58,323] loss: 0.003188  [ 3840/ 4689]
[2022-08-03 16:51:02,352] Test Error: Accuracy: 99.857%, Avg loss: 0.005492
[2022-08-03 16:51:02,352] Epoch 7---------------
[2022-08-03 16:51:02,353] lr: 1.080720e-03
[2022-08-03 16:51:02,528] loss: 0.003037  [    0/ 4689]
[2022-08-03 16:51:05,101] loss: 0.002672  [  960/ 4689]
[2022-08-03 16:51:07,676] loss: 0.004491  [ 1920/ 4689]
[2022-08-03 16:51:10,244] loss: 0.002398  [ 2880/ 4689]
[2022-08-03 16:51:12,813] loss: 0.002491  [ 3840/ 4689]
[2022-08-03 16:51:16,835] Test Error: Accuracy: 99.904%, Avg loss: 0.011323
[2022-08-03 16:51:16,835] Epoch 8---------------
[2022-08-03 16:51:16,836] lr: 7.547072e-04
[2022-08-03 16:51:17,009] loss: 0.003074  [    0/ 4689]
[2022-08-03 16:51:19,582] loss: 0.004414  [  960/ 4689]
[2022-08-03 16:51:22,153] loss: 0.003345  [ 1920/ 4689]
[2022-08-03 16:51:24,721] loss: 0.005158  [ 2880/ 4689]
[2022-08-03 16:51:28,243] loss: 0.002983  [ 3840/ 4689]
[2022-08-03 16:51:32,269] Test Error: Accuracy: 99.904%, Avg loss: 0.005213
[2022-08-03 16:51:32,646] Epoch 9---------------
[2022-08-03 16:51:32,646] lr: 7.169718e-04
[2022-08-03 16:51:32,820] loss: 0.002249  [    0/ 4689]
[2022-08-03 16:51:35,399] loss: 0.001781  [  960/ 4689]
[2022-08-03 16:51:37,981] loss: 0.002288  [ 1920/ 4689]
[2022-08-03 16:51:40,561] loss: 0.001666  [ 2880/ 4689]
[2022-08-03 16:51:43,143] loss: 0.001862  [ 3840/ 4689]
[2022-08-03 16:51:47,175] Test Error: Accuracy: 99.904%, Avg loss: 0.005251
[2022-08-03 16:51:47,176] Epoch 10---------------
[2022-08-03 16:51:47,178] lr: 6.147137e-04
[2022-08-03 16:51:47,352] loss: 0.001495  [    0/ 4689]
[2022-08-03 16:51:49,936] loss: 0.001754  [  960/ 4689]
[2022-08-03 16:51:52,519] loss: 0.001485  [ 1920/ 4689]
[2022-08-03 16:51:55,101] loss: 0.001610  [ 2880/ 4689]
[2022-08-03 16:51:57,683] loss: 0.001752  [ 3840/ 4689]
[2022-08-03 16:52:01,722] Test Error: Accuracy: 99.857%, Avg loss: 0.004051
[2022-08-03 16:52:01,722] Epoch 11---------------
[2022-08-03 16:52:01,724] lr: 5.839780e-04
[2022-08-03 16:52:01,898] loss: 0.001780  [    0/ 4689]
[2022-08-03 16:52:04,484] loss: 0.001158  [  960/ 4689]
[2022-08-03 16:52:07,067] loss: 0.001368  [ 1920/ 4689]
[2022-08-03 16:52:09,648] loss: 0.001474  [ 2880/ 4689]
[2022-08-03 16:52:12,227] loss: 0.001563  [ 3840/ 4689]
[2022-08-03 16:52:16,257] Test Error: Accuracy: 99.952%, Avg loss: 0.003744
[2022-08-03 16:52:16,258] Epoch 12---------------
[2022-08-03 16:52:16,259] lr: 5.547791e-04
[2022-08-03 16:52:16,433] loss: 0.001291  [    0/ 4689]
[2022-08-03 16:52:19,014] loss: 0.001504  [  960/ 4689]
[2022-08-03 16:52:21,596] loss: 0.001157  [ 1920/ 4689]
[2022-08-03 16:52:24,177] loss: 0.001120  [ 2880/ 4689]
[2022-08-03 16:52:26,758] loss: 0.000915  [ 3840/ 4689]
[2022-08-03 16:52:30,795] Test Error: Accuracy: 99.952%, Avg loss: 0.002398
[2022-08-03 16:52:30,795] Epoch 13---------------
[2022-08-03 16:52:30,797] lr: 5.270402e-04
[2022-08-03 16:52:30,971] loss: 0.001515  [    0/ 4689]
[2022-08-03 16:52:33,555] loss: 0.001669  [  960/ 4689]
[2022-08-03 16:52:36,135] loss: 0.001091  [ 1920/ 4689]
[2022-08-03 16:52:38,715] loss: 0.001198  [ 2880/ 4689]
[2022-08-03 16:52:41,297] loss: 0.001230  [ 3840/ 4689]
[2022-08-03 16:52:45,340] Test Error: Accuracy: 99.952%, Avg loss: 0.002310
[2022-08-03 16:52:45,340] Epoch 14---------------
[2022-08-03 16:52:45,341] lr: 5.006882e-04
[2022-08-03 16:52:45,515] loss: 0.001243  [    0/ 4689]
[2022-08-03 16:52:48,097] loss: 0.001086  [  960/ 4689]
[2022-08-03 16:52:50,679] loss: 0.001200  [ 1920/ 4689]
[2022-08-03 16:52:53,260] loss: 0.000956  [ 2880/ 4689]
[2022-08-03 16:52:55,842] loss: 0.000816  [ 3840/ 4689]
[2022-08-03 16:52:59,880] Test Error: Accuracy: 99.952%, Avg loss: 0.001912
[2022-08-03 16:52:59,881] Epoch 15---------------
[2022-08-03 16:52:59,883] lr: 4.756538e-04
[2022-08-03 16:53:00,058] loss: 0.001109  [    0/ 4689]
[2022-08-03 16:53:02,639] loss: 0.000981  [  960/ 4689]
[2022-08-03 16:53:05,221] loss: 0.002021  [ 1920/ 4689]
[2022-08-03 16:53:07,802] loss: 0.001121  [ 2880/ 4689]
[2022-08-03 16:53:10,384] loss: 0.001227  [ 3840/ 4689]
[2022-08-03 16:53:14,416] Test Error: Accuracy: 99.952%, Avg loss: 0.002983
[2022-08-03 16:53:14,417] Done!
[2022-08-03 16:53:14,421] Number of parameters:3198730
[2022-08-03 16:53:14,421] ## end time: 2022-08-03 16:53:14.417903
[2022-08-03 16:53:14,422] ## used time: 0:03:39.066492
