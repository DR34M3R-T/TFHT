[2022-08-06 15:30:13,074] ## start time: 2022-08-06 15:30:12.952874
[2022-08-06 15:30:13,074] Using cuda device
[2022-08-06 15:30:13,076] In train:p&d10.npy.
[2022-08-06 15:30:13,077] One Channel
[2022-08-06 15:30:13,078] With Normal data.
[2022-08-06 15:30:13,078] Nunber of classes:10.
[2022-08-06 15:30:13,078] Nunber of ViT channels:1.
[2022-08-06 15:30:13,268] Totol epochs: 10
[2022-08-06 15:30:13,270] Epoch 1---------------
[2022-08-06 15:30:13,271] lr: 2.000000e-03
[2022-08-06 15:30:13,282] loss: 2.677638  [    0/ 4758]
[2022-08-06 15:30:13,448] loss: 1.786122  [  960/ 4758]
[2022-08-06 15:30:13,610] loss: 1.103521  [ 1920/ 4758]
[2022-08-06 15:30:13,764] loss: 0.853336  [ 2880/ 4758]
[2022-08-06 15:30:13,919] loss: 0.433997  [ 3840/ 4758]
[2022-08-06 15:30:14,348] Train Error: Accuracy: 82.808%, Avg loss: 0.482240
[2022-08-06 15:30:14,473] Test  Error: Accuracy: 82.568%, Avg loss: 0.495056
[2022-08-06 15:30:14,473] Epoch 2---------------
[2022-08-06 15:30:14,474] lr: 1.900000e-03
[2022-08-06 15:30:14,486] loss: 0.513491  [    0/ 4758]
[2022-08-06 15:30:14,639] loss: 0.204031  [  960/ 4758]
[2022-08-06 15:30:14,790] loss: 0.201683  [ 1920/ 4758]
[2022-08-06 15:30:14,942] loss: 0.200933  [ 2880/ 4758]
[2022-08-06 15:30:15,093] loss: 0.147732  [ 3840/ 4758]
[2022-08-06 15:30:15,528] Train Error: Accuracy: 96.679%, Avg loss: 0.117221
[2022-08-06 15:30:15,654] Test  Error: Accuracy: 96.247%, Avg loss: 0.142851
[2022-08-06 15:30:15,654] Epoch 3---------------
[2022-08-06 15:30:15,656] lr: 1.805000e-03
[2022-08-06 15:30:15,667] loss: 0.100462  [    0/ 4758]
[2022-08-06 15:30:15,823] loss: 0.100000  [  960/ 4758]
[2022-08-06 15:30:15,978] loss: 0.183152  [ 1920/ 4758]
[2022-08-06 15:30:16,130] loss: 0.018011  [ 2880/ 4758]
[2022-08-06 15:30:16,281] loss: 0.067305  [ 3840/ 4758]
[2022-08-06 15:30:16,714] Train Error: Accuracy: 94.662%, Avg loss: 0.153567
[2022-08-06 15:30:16,840] Test  Error: Accuracy: 92.988%, Avg loss: 0.197725
[2022-08-06 15:30:16,840] Epoch 4---------------
[2022-08-06 15:30:16,841] lr: 1.260499e-03
[2022-08-06 15:30:16,853] loss: 0.100266  [    0/ 4758]
[2022-08-06 15:30:17,004] loss: 0.176584  [  960/ 4758]
[2022-08-06 15:30:17,156] loss: 0.025746  [ 1920/ 4758]
[2022-08-06 15:30:17,308] loss: 0.037283  [ 2880/ 4758]
[2022-08-06 15:30:17,460] loss: 0.010421  [ 3840/ 4758]
[2022-08-06 15:30:17,899] Train Error: Accuracy: 99.685%, Avg loss: 0.016844
[2022-08-06 15:30:18,024] Test  Error: Accuracy: 98.963%, Avg loss: 0.038214
[2022-08-06 15:30:18,024] Epoch 5---------------
[2022-08-06 15:30:18,025] lr: 1.197474e-03
[2022-08-06 15:30:18,038] loss: 0.008089  [    0/ 4758]
[2022-08-06 15:30:18,188] loss: 0.012238  [  960/ 4758]
[2022-08-06 15:30:18,339] loss: 0.024287  [ 1920/ 4758]
[2022-08-06 15:30:18,491] loss: 0.088952  [ 2880/ 4758]
[2022-08-06 15:30:18,643] loss: 0.170205  [ 3840/ 4758]
[2022-08-06 15:30:19,078] Train Error: Accuracy: 99.769%, Avg loss: 0.017518
[2022-08-06 15:30:19,207] Test  Error: Accuracy: 99.259%, Avg loss: 0.033373
[2022-08-06 15:30:19,207] Epoch 6---------------
[2022-08-06 15:30:19,208] lr: 1.137600e-03
[2022-08-06 15:30:19,220] loss: 0.011475  [    0/ 4758]
[2022-08-06 15:30:19,371] loss: 0.023114  [  960/ 4758]
[2022-08-06 15:30:19,522] loss: 0.008782  [ 1920/ 4758]
[2022-08-06 15:30:19,673] loss: 0.005184  [ 2880/ 4758]
[2022-08-06 15:30:19,825] loss: 0.030985  [ 3840/ 4758]
[2022-08-06 15:30:20,258] Train Error: Accuracy: 99.895%, Avg loss: 0.009884
[2022-08-06 15:30:20,381] Test  Error: Accuracy: 99.062%, Avg loss: 0.031627
[2022-08-06 15:30:20,382] Epoch 7---------------
[2022-08-06 15:30:20,383] lr: 1.080720e-03
[2022-08-06 15:30:20,395] loss: 0.008117  [    0/ 4758]
[2022-08-06 15:30:20,547] loss: 0.010801  [  960/ 4758]
[2022-08-06 15:30:20,697] loss: 0.010935  [ 1920/ 4758]
[2022-08-06 15:30:20,847] loss: 0.030098  [ 2880/ 4758]
[2022-08-06 15:30:21,010] loss: 0.006984  [ 3840/ 4758]
[2022-08-06 15:30:21,446] Train Error: Accuracy: 99.958%, Avg loss: 0.005722
[2022-08-06 15:30:21,570] Test  Error: Accuracy: 99.358%, Avg loss: 0.023319
[2022-08-06 15:30:21,571] Epoch 8---------------
[2022-08-06 15:30:21,572] lr: 1.026684e-03
[2022-08-06 15:30:21,584] loss: 0.002551  [    0/ 4758]
[2022-08-06 15:30:21,737] loss: 0.004195  [  960/ 4758]
[2022-08-06 15:30:21,889] loss: 0.008036  [ 1920/ 4758]
[2022-08-06 15:30:22,042] loss: 0.005188  [ 2880/ 4758]
[2022-08-06 15:30:22,191] loss: 0.169906  [ 3840/ 4758]
[2022-08-06 15:30:22,618] Train Error: Accuracy: 99.517%, Avg loss: 0.019628
[2022-08-06 15:30:22,742] Test  Error: Accuracy: 98.667%, Avg loss: 0.048125
[2022-08-06 15:30:22,743] Epoch 9---------------
[2022-08-06 15:30:22,744] lr: 7.169718e-04
[2022-08-06 15:30:22,755] loss: 0.011006  [    0/ 4758]
[2022-08-06 15:30:22,907] loss: 0.079721  [  960/ 4758]
[2022-08-06 15:30:23,059] loss: 0.003882  [ 1920/ 4758]
[2022-08-06 15:30:23,211] loss: 0.008613  [ 2880/ 4758]
[2022-08-06 15:30:23,361] loss: 0.003657  [ 3840/ 4758]
[2022-08-06 15:30:23,795] Train Error: Accuracy: 99.916%, Avg loss: 0.008403
[2022-08-06 15:30:23,918] Test  Error: Accuracy: 99.358%, Avg loss: 0.025763
[2022-08-06 15:30:23,919] Epoch 10---------------
[2022-08-06 15:30:23,920] lr: 6.811233e-04
[2022-08-06 15:30:23,933] loss: 0.008370  [    0/ 4758]
[2022-08-06 15:30:24,084] loss: 0.008537  [  960/ 4758]
[2022-08-06 15:30:24,239] loss: 0.032580  [ 1920/ 4758]
[2022-08-06 15:30:24,391] loss: 0.003713  [ 2880/ 4758]
[2022-08-06 15:30:24,541] loss: 0.002597  [ 3840/ 4758]
[2022-08-06 15:30:24,968] Train Error: Accuracy: 99.769%, Avg loss: 0.012169
[2022-08-06 15:30:25,092] Test  Error: Accuracy: 99.012%, Avg loss: 0.029762
[2022-08-06 15:30:25,093] Done!
[2022-08-06 15:30:25,095] Number of parameters:135050
[2022-08-06 15:30:25,095] ## end time: 2022-08-06 15:30:25.093127
[2022-08-06 15:30:25,095] ## used time: 0:00:12.140253
