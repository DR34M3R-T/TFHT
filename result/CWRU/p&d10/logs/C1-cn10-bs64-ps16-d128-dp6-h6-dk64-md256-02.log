[2022-08-03 17:34:57,845] ## start time: 2022-08-03 17:34:57.698619
[2022-08-03 17:34:57,845] Using cuda device
[2022-08-03 17:34:57,847] In train:p&d10.npy.
[2022-08-03 17:34:57,848] One Channel
[2022-08-03 17:34:57,848] With Normal data.
[2022-08-03 17:34:57,848] Nunber of classes:10.
[2022-08-03 17:34:57,849] Nunber of ViT channels:1.
[2022-08-03 17:34:58,099] Totol epochs: 10
[2022-08-03 17:34:58,101] Epoch 1---------------
[2022-08-03 17:34:58,102] lr: 2.000000e-03
[2022-08-03 17:34:59,599] loss: 2.529975  [    0/ 4774]
[2022-08-03 17:35:22,034] loss: 1.653630  [  960/ 4774]
[2022-08-03 17:35:44,469] loss: 1.632843  [ 1920/ 4774]
[2022-08-03 17:36:06,905] loss: 1.258849  [ 2880/ 4774]
[2022-08-03 17:36:29,340] loss: 0.812209  [ 3840/ 4774]
[2022-08-03 17:37:06,681] Test Error: Accuracy: 83.474%, Avg loss: 0.491165
[2022-08-03 17:37:06,682] Epoch 2---------------
[2022-08-03 17:37:06,683] lr: 1.900000e-03
[2022-08-03 17:37:08,181] loss: 0.408654  [    0/ 4774]
[2022-08-03 17:37:30,614] loss: 0.227237  [  960/ 4774]
[2022-08-03 17:37:53,048] loss: 0.154515  [ 1920/ 4774]
[2022-08-03 17:38:15,483] loss: 0.113262  [ 2880/ 4774]
[2022-08-03 17:38:37,916] loss: 0.044110  [ 3840/ 4774]
[2022-08-03 17:39:15,255] Test Error: Accuracy: 98.756%, Avg loss: 0.051564
[2022-08-03 17:39:15,256] Epoch 3---------------
[2022-08-03 17:39:15,257] lr: 1.805000e-03
[2022-08-03 17:39:16,755] loss: 0.022867  [    0/ 4774]
[2022-08-03 17:39:39,189] loss: 0.028707  [  960/ 4774]
[2022-08-03 17:40:01,623] loss: 0.041399  [ 1920/ 4774]
[2022-08-03 17:40:24,056] loss: 0.040699  [ 2880/ 4774]
[2022-08-03 17:40:46,490] loss: 0.020157  [ 3840/ 4774]
[2022-08-03 17:41:23,826] Test Error: Accuracy: 98.606%, Avg loss: 0.039795
[2022-08-03 17:41:23,826] Epoch 4---------------
[2022-08-03 17:41:23,827] lr: 1.714750e-03
[2022-08-03 17:41:25,325] loss: 0.094853  [    0/ 4774]
[2022-08-03 17:41:47,759] loss: 0.006329  [  960/ 4774]
[2022-08-03 17:42:10,193] loss: 0.012647  [ 1920/ 4774]
[2022-08-03 17:42:32,626] loss: 0.993837  [ 2880/ 4774]
[2022-08-03 17:42:55,059] loss: 0.056536  [ 3840/ 4774]
[2022-08-03 17:43:32,398] Test Error: Accuracy: 99.204%, Avg loss: 0.042919
[2022-08-03 17:43:32,398] Epoch 5---------------
[2022-08-03 17:43:32,399] lr: 1.470184e-03
[2022-08-03 17:43:33,897] loss: 0.016611  [    0/ 4774]
[2022-08-03 17:43:56,330] loss: 0.009940  [  960/ 4774]
[2022-08-03 17:44:18,765] loss: 0.038689  [ 1920/ 4774]
[2022-08-03 17:44:41,197] loss: 0.032845  [ 2880/ 4774]
[2022-08-03 17:45:03,631] loss: 0.052351  [ 3840/ 4774]
[2022-08-03 17:45:40,965] Test Error: Accuracy: 99.204%, Avg loss: 0.033277
[2022-08-03 17:45:40,966] Epoch 6---------------
[2022-08-03 17:45:40,967] lr: 1.396675e-03
[2022-08-03 17:45:42,464] loss: 0.008924  [    0/ 4774]
[2022-08-03 17:46:04,899] loss: 0.042485  [  960/ 4774]
[2022-08-03 17:46:27,332] loss: 0.007225  [ 1920/ 4774]
[2022-08-03 17:46:49,766] loss: 0.011655  [ 2880/ 4774]
[2022-08-03 17:47:12,199] loss: 0.007667  [ 3840/ 4774]
[2022-08-03 17:47:49,538] Test Error: Accuracy: 99.253%, Avg loss: 0.031063
[2022-08-03 17:47:49,539] Epoch 7---------------
[2022-08-03 17:47:49,540] lr: 1.326841e-03
[2022-08-03 17:47:51,038] loss: 0.039658  [    0/ 4774]
[2022-08-03 17:48:13,471] loss: 0.006329  [  960/ 4774]
[2022-08-03 17:48:35,905] loss: 0.009165  [ 1920/ 4774]
[2022-08-03 17:48:58,338] loss: 0.002170  [ 2880/ 4774]
[2022-08-03 17:49:20,772] loss: 0.005111  [ 3840/ 4774]
[2022-08-03 17:49:58,106] Test Error: Accuracy: 99.253%, Avg loss: 0.027814
[2022-08-03 17:49:58,107] Epoch 8---------------
[2022-08-03 17:49:58,109] lr: 1.260499e-03
[2022-08-03 17:49:59,606] loss: 0.008031  [    0/ 4774]
[2022-08-03 17:50:22,039] loss: 0.002558  [  960/ 4774]
[2022-08-03 17:50:44,471] loss: 0.011826  [ 1920/ 4774]
[2022-08-03 17:51:06,905] loss: 0.010273  [ 2880/ 4774]
[2022-08-03 17:51:29,338] loss: 0.001627  [ 3840/ 4774]
[2022-08-03 17:52:06,675] Test Error: Accuracy: 99.204%, Avg loss: 0.021754
[2022-08-03 17:52:06,676] Epoch 9---------------
[2022-08-03 17:52:06,677] lr: 1.197474e-03
[2022-08-03 17:52:08,175] loss: 0.001988  [    0/ 4774]
[2022-08-03 17:52:30,608] loss: 0.011112  [  960/ 4774]
[2022-08-03 17:52:53,041] loss: 0.002753  [ 1920/ 4774]
[2022-08-03 17:53:15,474] loss: 0.001404  [ 2880/ 4774]
[2022-08-03 17:53:37,908] loss: 0.001367  [ 3840/ 4774]
[2022-08-03 17:54:15,242] Test Error: Accuracy: 99.701%, Avg loss: 0.011785
[2022-08-03 17:54:15,242] Epoch 10---------------
[2022-08-03 17:54:15,243] lr: 1.137600e-03
[2022-08-03 17:54:16,740] loss: 0.021741  [    0/ 4774]
[2022-08-03 17:54:39,175] loss: 0.004168  [  960/ 4774]
[2022-08-03 17:55:01,609] loss: 0.002089  [ 1920/ 4774]
[2022-08-03 17:55:24,043] loss: 0.001532  [ 2880/ 4774]
[2022-08-03 17:55:46,477] loss: 0.004511  [ 3840/ 4774]
[2022-08-03 17:56:23,812] Test Error: Accuracy: 99.502%, Avg loss: 0.014942
[2022-08-03 17:56:23,813] Done!
[2022-08-03 17:56:23,818] Number of parameters:3198730
[2022-08-03 17:56:23,818] ## end time: 2022-08-03 17:56:23.813356
[2022-08-03 17:56:23,819] ## used time: 0:21:26.114737
