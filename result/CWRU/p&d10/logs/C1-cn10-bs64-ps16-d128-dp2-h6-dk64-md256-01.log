[2022-08-07 14:56:20,095] ## start time: 2022-08-07 14:56:19.960654
[2022-08-07 14:56:20,096] Using cuda device
[2022-08-07 14:56:20,097] In train:p&d10.npy.
[2022-08-07 14:56:20,099] One Channel
[2022-08-07 14:56:20,099] With Normal data.
[2022-08-07 14:56:20,099] Nunber of classes:10.
[2022-08-07 14:56:20,100] Nunber of ViT channels:1.
[2022-08-07 14:56:20,297] Totol epochs: 15
[2022-08-07 14:56:20,299] Epoch 1---------------
[2022-08-07 14:56:20,300] lr: 2.000000e-03
[2022-08-07 14:56:20,803] loss: 2.428514  [    0/ 4757]
[2022-08-07 14:56:28,333] loss: 1.778729  [  960/ 4757]
[2022-08-07 14:56:35,864] loss: 0.905934  [ 1920/ 4757]
[2022-08-07 14:56:43,394] loss: 0.761708  [ 2880/ 4757]
[2022-08-07 14:56:50,924] loss: 0.162332  [ 3840/ 4757]
[2022-08-07 14:57:11,219] Train Error: Accuracy: 95.985%, Avg loss: 0.149475
[2022-08-07 14:57:17,011] Test  Error: Accuracy: 95.015%, Avg loss: 0.178553
[2022-08-07 14:57:17,011] Epoch 2---------------
[2022-08-07 14:57:17,012] lr: 1.900000e-03
[2022-08-07 14:57:17,517] loss: 0.142739  [    0/ 4757]
[2022-08-07 14:57:25,047] loss: 0.122901  [  960/ 4757]
[2022-08-07 14:57:32,577] loss: 0.054609  [ 1920/ 4757]
[2022-08-07 14:57:40,108] loss: 0.163226  [ 2880/ 4757]
[2022-08-07 14:57:47,638] loss: 0.081232  [ 3840/ 4757]
[2022-08-07 14:58:07,932] Train Error: Accuracy: 89.132%, Avg loss: 0.390514
[2022-08-07 14:58:13,722] Test  Error: Accuracy: 87.759%, Avg loss: 0.467178
[2022-08-07 14:58:13,722] Epoch 3---------------
[2022-08-07 14:58:13,723] lr: 1.326841e-03
[2022-08-07 14:58:14,228] loss: 0.451195  [    0/ 4757]
[2022-08-07 14:58:21,759] loss: 0.084607  [  960/ 4757]
[2022-08-07 14:58:29,288] loss: 0.023021  [ 1920/ 4757]
[2022-08-07 14:58:36,817] loss: 0.051020  [ 2880/ 4757]
[2022-08-07 14:58:44,347] loss: 0.089378  [ 3840/ 4757]
[2022-08-07 14:59:04,640] Train Error: Accuracy: 99.369%, Avg loss: 0.026180
[2022-08-07 14:59:10,433] Test  Error: Accuracy: 98.717%, Avg loss: 0.050896
[2022-08-07 14:59:10,434] Epoch 4---------------
[2022-08-07 14:59:10,436] lr: 1.260499e-03
[2022-08-07 14:59:10,940] loss: 0.022868  [    0/ 4757]
[2022-08-07 14:59:18,470] loss: 0.016947  [  960/ 4757]
[2022-08-07 14:59:26,001] loss: 0.014235  [ 1920/ 4757]
[2022-08-07 14:59:33,531] loss: 0.018524  [ 2880/ 4757]
[2022-08-07 14:59:41,061] loss: 0.015962  [ 3840/ 4757]
[2022-08-07 15:00:01,356] Train Error: Accuracy: 99.474%, Avg loss: 0.022396
[2022-08-07 15:00:07,148] Test  Error: Accuracy: 98.914%, Avg loss: 0.041949
[2022-08-07 15:00:07,149] Epoch 5---------------
[2022-08-07 15:00:07,150] lr: 1.197474e-03
[2022-08-07 15:00:07,655] loss: 0.022541  [    0/ 4757]
[2022-08-07 15:00:15,186] loss: 0.005773  [  960/ 4757]
[2022-08-07 15:00:22,716] loss: 0.016201  [ 1920/ 4757]
[2022-08-07 15:00:30,245] loss: 0.008485  [ 2880/ 4757]
[2022-08-07 15:00:37,776] loss: 0.032416  [ 3840/ 4757]
[2022-08-07 15:00:58,069] Train Error: Accuracy: 99.790%, Avg loss: 0.011736
[2022-08-07 15:01:03,861] Test  Error: Accuracy: 99.358%, Avg loss: 0.031475
[2022-08-07 15:01:03,862] Epoch 6---------------
[2022-08-07 15:01:03,862] lr: 1.137600e-03
[2022-08-07 15:01:04,367] loss: 0.043366  [    0/ 4757]
[2022-08-07 15:01:11,897] loss: 0.105354  [  960/ 4757]
[2022-08-07 15:01:19,425] loss: 0.017288  [ 1920/ 4757]
[2022-08-07 15:01:26,957] loss: 0.018987  [ 2880/ 4757]
[2022-08-07 15:01:34,487] loss: 0.117550  [ 3840/ 4757]
[2022-08-07 15:01:54,782] Train Error: Accuracy: 91.297%, Avg loss: 0.275997
[2022-08-07 15:02:00,572] Test  Error: Accuracy: 90.128%, Avg loss: 0.319696
[2022-08-07 15:02:00,573] Epoch 7---------------
[2022-08-07 15:02:00,574] lr: 7.944286e-04
[2022-08-07 15:02:01,078] loss: 0.316741  [    0/ 4757]
[2022-08-07 15:02:08,608] loss: 0.020025  [  960/ 4757]
[2022-08-07 15:02:16,137] loss: 0.021065  [ 1920/ 4757]
[2022-08-07 15:02:23,667] loss: 0.005659  [ 2880/ 4757]
[2022-08-07 15:02:31,197] loss: 0.018924  [ 3840/ 4757]
[2022-08-07 15:02:51,491] Train Error: Accuracy: 99.748%, Avg loss: 0.012794
[2022-08-07 15:02:57,281] Test  Error: Accuracy: 99.013%, Avg loss: 0.035569
[2022-08-07 15:02:57,282] Epoch 8---------------
[2022-08-07 15:02:57,283] lr: 7.547072e-04
[2022-08-07 15:02:57,787] loss: 0.011647  [    0/ 4757]
[2022-08-07 15:03:05,317] loss: 0.012439  [  960/ 4757]
[2022-08-07 15:03:12,848] loss: 0.004538  [ 1920/ 4757]
[2022-08-07 15:03:20,379] loss: 0.003204  [ 2880/ 4757]
[2022-08-07 15:03:27,909] loss: 0.005787  [ 3840/ 4757]
[2022-08-07 15:03:48,202] Train Error: Accuracy: 99.853%, Avg loss: 0.007142
[2022-08-07 15:03:53,993] Test  Error: Accuracy: 99.506%, Avg loss: 0.020132
[2022-08-07 15:03:53,994] Epoch 9---------------
[2022-08-07 15:03:53,995] lr: 7.169718e-04
[2022-08-07 15:03:54,499] loss: 0.003154  [    0/ 4757]
[2022-08-07 15:04:02,028] loss: 0.002476  [  960/ 4757]
[2022-08-07 15:04:09,560] loss: 0.009110  [ 1920/ 4757]
[2022-08-07 15:04:17,090] loss: 0.005701  [ 2880/ 4757]
[2022-08-07 15:04:24,620] loss: 0.004239  [ 3840/ 4757]
[2022-08-07 15:04:44,917] Train Error: Accuracy: 99.958%, Avg loss: 0.003800
[2022-08-07 15:04:50,710] Test  Error: Accuracy: 99.605%, Avg loss: 0.017533
[2022-08-07 15:04:50,710] Epoch 10---------------
[2022-08-07 15:04:50,711] lr: 6.811233e-04
[2022-08-07 15:04:51,216] loss: 0.007154  [    0/ 4757]
[2022-08-07 15:04:58,746] loss: 0.006591  [  960/ 4757]
[2022-08-07 15:05:06,276] loss: 0.003158  [ 1920/ 4757]
[2022-08-07 15:05:13,806] loss: 0.002302  [ 2880/ 4757]
[2022-08-07 15:05:21,336] loss: 0.007529  [ 3840/ 4757]
[2022-08-07 15:05:41,631] Train Error: Accuracy: 99.958%, Avg loss: 0.005798
[2022-08-07 15:05:47,420] Test  Error: Accuracy: 99.556%, Avg loss: 0.015916
[2022-08-07 15:05:47,421] Epoch 11---------------
[2022-08-07 15:05:47,422] lr: 6.470671e-04
[2022-08-07 15:05:47,926] loss: 0.001525  [    0/ 4757]
[2022-08-07 15:05:55,456] loss: 0.001280  [  960/ 4757]
[2022-08-07 15:06:02,986] loss: 0.001323  [ 1920/ 4757]
[2022-08-07 15:06:10,515] loss: 0.001465  [ 2880/ 4757]
[2022-08-07 15:06:18,046] loss: 0.003148  [ 3840/ 4757]
[2022-08-07 15:06:38,338] Train Error: Accuracy: 99.958%, Avg loss: 0.004908
[2022-08-07 15:06:44,132] Test  Error: Accuracy: 99.210%, Avg loss: 0.027920
[2022-08-07 15:06:44,132] Epoch 12---------------
[2022-08-07 15:06:44,136] lr: 4.518711e-04
[2022-08-07 15:06:44,640] loss: 0.003925  [    0/ 4757]
[2022-08-07 15:06:52,169] loss: 0.001229  [  960/ 4757]
[2022-08-07 15:06:59,699] loss: 0.003411  [ 1920/ 4757]
[2022-08-07 15:07:07,228] loss: 0.001273  [ 2880/ 4757]
[2022-08-07 15:07:14,758] loss: 0.002926  [ 3840/ 4757]
[2022-08-07 15:07:35,055] Train Error: Accuracy: 99.979%, Avg loss: 0.002585
[2022-08-07 15:07:40,844] Test  Error: Accuracy: 99.753%, Avg loss: 0.008629
[2022-08-07 15:07:40,845] Epoch 13---------------
[2022-08-07 15:07:40,846] lr: 4.292775e-04
[2022-08-07 15:07:41,350] loss: 0.048787  [    0/ 4757]
[2022-08-07 15:07:48,881] loss: 0.001758  [  960/ 4757]
[2022-08-07 15:07:56,412] loss: 0.001656  [ 1920/ 4757]
[2022-08-07 15:08:03,940] loss: 0.002069  [ 2880/ 4757]
[2022-08-07 15:08:11,471] loss: 0.000889  [ 3840/ 4757]
[2022-08-07 15:08:31,763] Train Error: Accuracy: 100.000%, Avg loss: 0.001910
[2022-08-07 15:08:37,553] Test  Error: Accuracy: 99.556%, Avg loss: 0.013967
[2022-08-07 15:08:37,554] Epoch 14---------------
[2022-08-07 15:08:37,554] lr: 2.997805e-04
[2022-08-07 15:08:38,059] loss: 0.000822  [    0/ 4757]
[2022-08-07 15:08:45,588] loss: 0.001868  [  960/ 4757]
[2022-08-07 15:08:53,119] loss: 0.002407  [ 1920/ 4757]
[2022-08-07 15:09:00,648] loss: 0.000905  [ 2880/ 4757]
[2022-08-07 15:09:08,178] loss: 0.002399  [ 3840/ 4757]
[2022-08-07 15:09:28,477] Train Error: Accuracy: 99.958%, Avg loss: 0.001715
[2022-08-07 15:09:34,270] Test  Error: Accuracy: 99.556%, Avg loss: 0.015157
[2022-08-07 15:09:34,270] Epoch 15---------------
[2022-08-07 15:09:34,271] lr: 2.570243e-04
[2022-08-07 15:09:34,776] loss: 0.000987  [    0/ 4757]
[2022-08-07 15:09:42,308] loss: 0.000772  [  960/ 4757]
[2022-08-07 15:09:49,837] loss: 0.001485  [ 1920/ 4757]
[2022-08-07 15:09:57,367] loss: 0.000659  [ 2880/ 4757]
[2022-08-07 15:10:04,897] loss: 0.000847  [ 3840/ 4757]
[2022-08-07 15:10:25,189] Train Error: Accuracy: 99.958%, Avg loss: 0.001961
[2022-08-07 15:10:30,979] Test  Error: Accuracy: 99.556%, Avg loss: 0.016433
[2022-08-07 15:10:30,980] Done!
[2022-08-07 15:10:30,986] Number of parameters:1093386
[2022-08-07 15:10:30,986] ## end time: 2022-08-07 15:10:30.980749
[2022-08-07 15:10:30,986] ## used time: 0:14:11.020095
