[2022-08-03 17:03:55,497] ## start time: 2022-08-03 17:03:55.336794
[2022-08-03 17:03:55,497] Using cuda device
[2022-08-03 17:03:55,499] In train:p&d10.npy.
[2022-08-03 17:03:55,500] One Channel
[2022-08-03 17:03:55,500] With Normal data.
[2022-08-03 17:03:55,501] Nunber of classes:10.
[2022-08-03 17:03:55,501] Nunber of ViT channels:1.
[2022-08-03 17:03:55,760] Totol epochs: 15
[2022-08-03 17:03:55,764] Epoch 1---------------
[2022-08-03 17:03:55,764] lr: 2.000000e-03
[2022-08-03 17:03:55,875] loss: 2.344800  [    0/ 4727]
[2022-08-03 17:03:57,512] loss: 1.631576  [  960/ 4727]
[2022-08-03 17:03:59,140] loss: 1.585662  [ 1920/ 4727]
[2022-08-03 17:04:00,772] loss: 0.264146  [ 2880/ 4727]
[2022-08-03 17:04:02,403] loss: 0.029395  [ 3840/ 4727]
[2022-08-03 17:04:04,922] Test Error: Accuracy: 98.687%, Avg loss: 0.103770
[2022-08-03 17:04:04,923] Epoch 2---------------
[2022-08-03 17:04:04,923] lr: 1.900000e-03
[2022-08-03 17:04:05,038] loss: 0.117280  [    0/ 4727]
[2022-08-03 17:04:06,670] loss: 0.029084  [  960/ 4727]
[2022-08-03 17:04:08,298] loss: 0.018849  [ 1920/ 4727]
[2022-08-03 17:04:09,929] loss: 0.017408  [ 2880/ 4727]
[2022-08-03 17:04:11,561] loss: 0.006302  [ 3840/ 4727]
[2022-08-03 17:04:14,063] Test Error: Accuracy: 99.951%, Avg loss: 0.006240
[2022-08-03 17:04:14,063] Epoch 3---------------
[2022-08-03 17:04:14,064] lr: 1.805000e-03
[2022-08-03 17:04:14,175] loss: 0.006201  [    0/ 4727]
[2022-08-03 17:04:15,806] loss: 0.004221  [  960/ 4727]
[2022-08-03 17:04:17,435] loss: 0.004459  [ 1920/ 4727]
[2022-08-03 17:04:19,069] loss: 0.002633  [ 2880/ 4727]
[2022-08-03 17:04:20,702] loss: 0.002514  [ 3840/ 4727]
[2022-08-03 17:04:23,205] Test Error: Accuracy: 100.000%, Avg loss: 0.002995
[2022-08-03 17:04:23,206] Epoch 4---------------
[2022-08-03 17:04:23,206] lr: 1.714750e-03
[2022-08-03 17:04:23,318] loss: 0.002531  [    0/ 4727]
[2022-08-03 17:04:24,950] loss: 0.002173  [  960/ 4727]
[2022-08-03 17:04:26,581] loss: 0.002269  [ 1920/ 4727]
[2022-08-03 17:04:28,211] loss: 0.001988  [ 2880/ 4727]
[2022-08-03 17:04:29,837] loss: 0.001650  [ 3840/ 4727]
[2022-08-03 17:04:32,341] Test Error: Accuracy: 100.000%, Avg loss: 0.002315
[2022-08-03 17:04:32,341] Epoch 5---------------
[2022-08-03 17:04:32,343] lr: 1.629012e-03
[2022-08-03 17:04:32,454] loss: 0.001805  [    0/ 4727]
[2022-08-03 17:04:34,090] loss: 0.001464  [  960/ 4727]
[2022-08-03 17:04:35,724] loss: 0.001233  [ 1920/ 4727]
[2022-08-03 17:04:37,354] loss: 0.001236  [ 2880/ 4727]
[2022-08-03 17:04:38,984] loss: 0.001270  [ 3840/ 4727]
[2022-08-03 17:04:41,487] Test Error: Accuracy: 100.000%, Avg loss: 0.001793
[2022-08-03 17:04:41,488] Epoch 6---------------
[2022-08-03 17:04:41,489] lr: 1.547562e-03
[2022-08-03 17:04:41,599] loss: 0.001318  [    0/ 4727]
[2022-08-03 17:04:43,226] loss: 0.001367  [  960/ 4727]
[2022-08-03 17:04:44,850] loss: 0.001168  [ 1920/ 4727]
[2022-08-03 17:04:46,478] loss: 0.001242  [ 2880/ 4727]
[2022-08-03 17:04:48,112] loss: 0.001128  [ 3840/ 4727]
[2022-08-03 17:04:50,612] Test Error: Accuracy: 99.951%, Avg loss: 0.002061
[2022-08-03 17:04:50,613] Epoch 7---------------
[2022-08-03 17:04:50,614] lr: 1.197474e-03
[2022-08-03 17:04:50,725] loss: 0.001383  [    0/ 4727]
[2022-08-03 17:04:52,355] loss: 0.001070  [  960/ 4727]
[2022-08-03 17:04:53,990] loss: 0.001107  [ 1920/ 4727]
[2022-08-03 17:04:55,626] loss: 0.001040  [ 2880/ 4727]
[2022-08-03 17:04:57,256] loss: 0.001047  [ 3840/ 4727]
[2022-08-03 17:04:59,766] Test Error: Accuracy: 99.951%, Avg loss: 0.001575
[2022-08-03 17:04:59,766] Epoch 8---------------
[2022-08-03 17:04:59,767] lr: 1.137600e-03
[2022-08-03 17:04:59,878] loss: 0.000869  [    0/ 4727]
[2022-08-03 17:05:01,512] loss: 0.000891  [  960/ 4727]
[2022-08-03 17:05:03,142] loss: 0.000706  [ 1920/ 4727]
[2022-08-03 17:05:04,774] loss: 0.000878  [ 2880/ 4727]
[2022-08-03 17:05:06,405] loss: 0.000817  [ 3840/ 4727]
[2022-08-03 17:05:08,907] Test Error: Accuracy: 100.000%, Avg loss: 0.001232
[2022-08-03 17:05:08,907] Epoch 9---------------
[2022-08-03 17:05:08,908] lr: 1.080720e-03
[2022-08-03 17:05:09,020] loss: 0.000785  [    0/ 4727]
[2022-08-03 17:05:10,650] loss: 0.000873  [  960/ 4727]
[2022-08-03 17:05:12,282] loss: 0.000811  [ 1920/ 4727]
[2022-08-03 17:05:13,908] loss: 0.000876  [ 2880/ 4727]
[2022-08-03 17:05:15,537] loss: 0.000828  [ 3840/ 4727]
[2022-08-03 17:05:18,040] Test Error: Accuracy: 100.000%, Avg loss: 0.001194
[2022-08-03 17:05:18,040] Epoch 10---------------
[2022-08-03 17:05:18,041] lr: 1.026684e-03
[2022-08-03 17:05:18,152] loss: 0.000786  [    0/ 4727]
[2022-08-03 17:05:19,787] loss: 0.000770  [  960/ 4727]
[2022-08-03 17:05:21,414] loss: 0.000755  [ 1920/ 4727]
[2022-08-03 17:05:23,044] loss: 0.000885  [ 2880/ 4727]
[2022-08-03 17:05:24,675] loss: 0.000710  [ 3840/ 4727]
[2022-08-03 17:05:27,174] Test Error: Accuracy: 100.000%, Avg loss: 0.001378
[2022-08-03 17:05:27,175] Epoch 11---------------
[2022-08-03 17:05:27,176] lr: 7.944286e-04
[2022-08-03 17:05:27,287] loss: 0.000755  [    0/ 4727]
[2022-08-03 17:05:28,918] loss: 0.000976  [  960/ 4727]
[2022-08-03 17:05:30,547] loss: 0.000704  [ 1920/ 4727]
[2022-08-03 17:05:32,175] loss: 0.000862  [ 2880/ 4727]
[2022-08-03 17:05:33,807] loss: 0.000739  [ 3840/ 4727]
[2022-08-03 17:05:36,308] Test Error: Accuracy: 100.000%, Avg loss: 0.000875
[2022-08-03 17:05:36,308] Epoch 12---------------
[2022-08-03 17:05:36,309] lr: 7.547072e-04
[2022-08-03 17:05:36,422] loss: 0.000731  [    0/ 4727]
[2022-08-03 17:05:38,056] loss: 0.000811  [  960/ 4727]
[2022-08-03 17:05:39,684] loss: 0.001173  [ 1920/ 4727]
[2022-08-03 17:05:41,314] loss: 0.000675  [ 2880/ 4727]
[2022-08-03 17:05:42,945] loss: 0.000743  [ 3840/ 4727]
[2022-08-03 17:05:45,442] Test Error: Accuracy: 100.000%, Avg loss: 0.000896
[2022-08-03 17:05:45,443] Epoch 13---------------
[2022-08-03 17:05:45,444] lr: 6.470671e-04
[2022-08-03 17:05:45,554] loss: 0.000863  [    0/ 4727]
[2022-08-03 17:05:47,185] loss: 0.000650  [  960/ 4727]
[2022-08-03 17:05:48,818] loss: 0.000673  [ 1920/ 4727]
[2022-08-03 17:05:50,452] loss: 0.000592  [ 2880/ 4727]
[2022-08-03 17:05:52,081] loss: 0.000556  [ 3840/ 4727]
[2022-08-03 17:05:54,578] Test Error: Accuracy: 100.000%, Avg loss: 0.001090
[2022-08-03 17:05:54,578] Epoch 14---------------
[2022-08-03 17:05:54,579] lr: 5.006882e-04
[2022-08-03 17:05:54,690] loss: 0.000577  [    0/ 4727]
[2022-08-03 17:05:56,319] loss: 0.000646  [  960/ 4727]
[2022-08-03 17:05:57,952] loss: 0.000626  [ 1920/ 4727]
[2022-08-03 17:05:59,584] loss: 0.000690  [ 2880/ 4727]
[2022-08-03 17:06:01,217] loss: 0.000754  [ 3840/ 4727]
[2022-08-03 17:06:03,716] Test Error: Accuracy: 100.000%, Avg loss: 0.001108
[2022-08-03 17:06:03,716] Epoch 15---------------
[2022-08-03 17:06:03,717] lr: 4.292775e-04
[2022-08-03 17:06:03,828] loss: 0.000655  [    0/ 4727]
[2022-08-03 17:06:05,456] loss: 0.000636  [  960/ 4727]
[2022-08-03 17:06:07,088] loss: 0.000609  [ 1920/ 4727]
[2022-08-03 17:06:08,724] loss: 0.000597  [ 2880/ 4727]
[2022-08-03 17:06:10,356] loss: 0.000567  [ 3840/ 4727]
[2022-08-03 17:06:12,862] Test Error: Accuracy: 100.000%, Avg loss: 0.000937
[2022-08-03 17:06:12,863] Done!
[2022-08-03 17:06:12,869] Number of parameters:3229450
[2022-08-03 17:06:12,870] ## end time: 2022-08-03 17:06:12.863164
[2022-08-03 17:06:12,870] ## used time: 0:02:17.526370
