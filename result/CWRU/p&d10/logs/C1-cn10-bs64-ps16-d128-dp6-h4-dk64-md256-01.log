[2022-08-06 17:40:51,751] ## start time: 2022-08-06 17:40:51.615402
[2022-08-06 17:40:51,751] Using cuda device
[2022-08-06 17:40:51,753] In train:p&d10.npy.
[2022-08-06 17:40:51,754] One Channel
[2022-08-06 17:40:51,754] With Normal data.
[2022-08-06 17:40:51,755] Nunber of classes:10.
[2022-08-06 17:40:51,755] Nunber of ViT channels:1.
[2022-08-06 17:40:52,000] Totol epochs: 15
[2022-08-06 17:40:52,004] Epoch 1---------------
[2022-08-06 17:40:52,004] lr: 2.000000e-03
[2022-08-06 17:40:53,096] loss: 2.416170  [    0/ 4735]
[2022-08-06 17:41:09,419] loss: 1.760745  [  960/ 4735]
[2022-08-06 17:41:25,741] loss: 1.612105  [ 1920/ 4735]
[2022-08-06 17:41:42,065] loss: 1.206818  [ 2880/ 4735]
[2022-08-06 17:41:58,388] loss: 0.895688  [ 3840/ 4735]
[2022-08-06 17:42:42,400] Train Error: Accuracy: 73.390%, Avg loss: 0.645325
[2022-08-06 17:42:55,328] Test  Error: Accuracy: 73.242%, Avg loss: 0.632840
[2022-08-06 17:42:55,328] Epoch 2---------------
[2022-08-06 17:42:55,329] lr: 1.900000e-03
[2022-08-06 17:42:56,420] loss: 0.707805  [    0/ 4735]
[2022-08-06 17:43:12,743] loss: 0.499301  [  960/ 4735]
[2022-08-06 17:43:29,065] loss: 0.316385  [ 1920/ 4735]
[2022-08-06 17:43:45,387] loss: 0.194589  [ 2880/ 4735]
[2022-08-06 17:44:01,709] loss: 0.256700  [ 3840/ 4735]
[2022-08-06 17:44:45,709] Train Error: Accuracy: 98.437%, Avg loss: 0.080581
[2022-08-06 17:44:58,630] Test  Error: Accuracy: 98.535%, Avg loss: 0.083246
[2022-08-06 17:44:58,630] Epoch 3---------------
[2022-08-06 17:44:58,632] lr: 1.805000e-03
[2022-08-06 17:44:59,723] loss: 0.075355  [    0/ 4735]
[2022-08-06 17:45:16,045] loss: 0.125901  [  960/ 4735]
[2022-08-06 17:45:32,366] loss: 0.077218  [ 1920/ 4735]
[2022-08-06 17:45:48,689] loss: 0.026390  [ 2880/ 4735]
[2022-08-06 17:46:05,010] loss: 0.131436  [ 3840/ 4735]
[2022-08-06 17:46:49,015] Train Error: Accuracy: 73.178%, Avg loss: 1.016035
[2022-08-06 17:47:01,945] Test  Error: Accuracy: 71.826%, Avg loss: 1.074787
[2022-08-06 17:47:01,945] Epoch 4---------------
[2022-08-06 17:47:01,946] lr: 1.260499e-03
[2022-08-06 17:47:03,037] loss: 0.809585  [    0/ 4735]
[2022-08-06 17:47:19,359] loss: 0.060800  [  960/ 4735]
[2022-08-06 17:47:35,682] loss: 0.021465  [ 1920/ 4735]
[2022-08-06 17:47:52,004] loss: 0.015831  [ 2880/ 4735]
[2022-08-06 17:48:08,325] loss: 0.031715  [ 3840/ 4735]
[2022-08-06 17:48:52,328] Train Error: Accuracy: 99.662%, Avg loss: 0.020208
[2022-08-06 17:49:05,257] Test  Error: Accuracy: 99.414%, Avg loss: 0.030132
[2022-08-06 17:49:05,257] Epoch 5---------------
[2022-08-06 17:49:05,258] lr: 1.197474e-03
[2022-08-06 17:49:06,350] loss: 0.014195  [    0/ 4735]
[2022-08-06 17:49:22,671] loss: 0.004886  [  960/ 4735]
[2022-08-06 17:49:38,994] loss: 0.017328  [ 1920/ 4735]
[2022-08-06 17:49:55,317] loss: 0.038451  [ 2880/ 4735]
[2022-08-06 17:50:11,639] loss: 0.003620  [ 3840/ 4735]
[2022-08-06 17:50:55,638] Train Error: Accuracy: 99.683%, Avg loss: 0.013518
[2022-08-06 17:51:08,561] Test  Error: Accuracy: 99.463%, Avg loss: 0.021024
[2022-08-06 17:51:08,561] Epoch 6---------------
[2022-08-06 17:51:08,562] lr: 1.137600e-03
[2022-08-06 17:51:09,653] loss: 0.004516  [    0/ 4735]
[2022-08-06 17:51:25,977] loss: 0.062374  [  960/ 4735]
[2022-08-06 17:51:42,299] loss: 0.047195  [ 1920/ 4735]
[2022-08-06 17:51:58,620] loss: 0.002924  [ 2880/ 4735]
[2022-08-06 17:52:14,944] loss: 0.002549  [ 3840/ 4735]
[2022-08-06 17:52:58,949] Train Error: Accuracy: 99.366%, Avg loss: 0.022596
[2022-08-06 17:53:11,874] Test  Error: Accuracy: 98.926%, Avg loss: 0.030599
[2022-08-06 17:53:11,875] Epoch 7---------------
[2022-08-06 17:53:11,876] lr: 7.944286e-04
[2022-08-06 17:53:12,967] loss: 0.111247  [    0/ 4735]
[2022-08-06 17:53:29,292] loss: 0.099542  [  960/ 4735]
[2022-08-06 17:53:45,620] loss: 0.016776  [ 1920/ 4735]
[2022-08-06 17:54:01,945] loss: 0.003599  [ 2880/ 4735]
[2022-08-06 17:54:18,270] loss: 0.003399  [ 3840/ 4735]
[2022-08-06 17:55:02,285] Train Error: Accuracy: 99.831%, Avg loss: 0.010389
[2022-08-06 17:55:15,211] Test  Error: Accuracy: 99.463%, Avg loss: 0.018688
[2022-08-06 17:55:15,212] Epoch 8---------------
[2022-08-06 17:55:15,213] lr: 7.547072e-04
[2022-08-06 17:55:16,303] loss: 0.005133  [    0/ 4735]
[2022-08-06 17:55:32,630] loss: 0.001902  [  960/ 4735]
[2022-08-06 17:55:48,957] loss: 0.002921  [ 1920/ 4735]
[2022-08-06 17:56:05,282] loss: 0.001881  [ 2880/ 4735]
[2022-08-06 17:56:21,608] loss: 0.005533  [ 3840/ 4735]
[2022-08-06 17:57:05,614] Train Error: Accuracy: 99.937%, Avg loss: 0.003657
[2022-08-06 17:57:18,540] Test  Error: Accuracy: 99.756%, Avg loss: 0.009931
[2022-08-06 17:57:18,540] Epoch 9---------------
[2022-08-06 17:57:18,541] lr: 7.169718e-04
[2022-08-06 17:57:19,633] loss: 0.004705  [    0/ 4735]
[2022-08-06 17:57:35,961] loss: 0.005362  [  960/ 4735]
[2022-08-06 17:57:52,288] loss: 0.001470  [ 1920/ 4735]
[2022-08-06 17:58:08,613] loss: 0.001646  [ 2880/ 4735]
[2022-08-06 17:58:24,940] loss: 0.002804  [ 3840/ 4735]
[2022-08-06 17:59:08,950] Train Error: Accuracy: 99.958%, Avg loss: 0.003039
[2022-08-06 17:59:21,878] Test  Error: Accuracy: 99.805%, Avg loss: 0.009878
[2022-08-06 17:59:21,878] Epoch 10---------------
[2022-08-06 17:59:21,879] lr: 6.811233e-04
[2022-08-06 17:59:22,969] loss: 0.002741  [    0/ 4735]
[2022-08-06 17:59:39,296] loss: 0.002429  [  960/ 4735]
[2022-08-06 17:59:55,622] loss: 0.001083  [ 1920/ 4735]
[2022-08-06 18:00:11,949] loss: 0.002740  [ 2880/ 4735]
[2022-08-06 18:00:28,275] loss: 0.001563  [ 3840/ 4735]
[2022-08-06 18:01:12,284] Train Error: Accuracy: 99.894%, Avg loss: 0.005713
[2022-08-06 18:01:25,209] Test  Error: Accuracy: 99.756%, Avg loss: 0.011266
[2022-08-06 18:01:25,209] Epoch 11---------------
[2022-08-06 18:01:25,210] lr: 5.270402e-04
[2022-08-06 18:01:26,299] loss: 0.005686  [    0/ 4735]
[2022-08-06 18:01:42,626] loss: 0.003206  [  960/ 4735]
[2022-08-06 18:01:58,951] loss: 0.003181  [ 1920/ 4735]
[2022-08-06 18:02:15,278] loss: 0.001613  [ 2880/ 4735]
[2022-08-06 18:02:31,603] loss: 0.001371  [ 3840/ 4735]
[2022-08-06 18:03:15,621] Train Error: Accuracy: 100.000%, Avg loss: 0.002346
[2022-08-06 18:03:28,549] Test  Error: Accuracy: 99.609%, Avg loss: 0.010848
[2022-08-06 18:03:28,549] Epoch 12---------------
[2022-08-06 18:03:28,549] lr: 5.006882e-04
[2022-08-06 18:03:29,639] loss: 0.008576  [    0/ 4735]
[2022-08-06 18:03:45,965] loss: 0.003912  [  960/ 4735]
[2022-08-06 18:04:02,293] loss: 0.001430  [ 1920/ 4735]
[2022-08-06 18:04:18,621] loss: 0.009698  [ 2880/ 4735]
[2022-08-06 18:04:34,948] loss: 0.001342  [ 3840/ 4735]
[2022-08-06 18:05:18,960] Train Error: Accuracy: 99.979%, Avg loss: 0.001718
[2022-08-06 18:05:31,885] Test  Error: Accuracy: 99.707%, Avg loss: 0.007621
[2022-08-06 19:01:54,646] Epoch 13---------------
[2022-08-06 19:01:54,646] lr: 4.756538e-04
[2022-08-06 19:01:56,056] loss: 0.001538  [    0/ 4735]
[2022-08-06 19:02:12,120] loss: 0.004673  [  960/ 4735]
[2022-08-06 19:02:28,099] loss: 0.000931  [ 1920/ 4735]
[2022-08-06 19:02:44,181] loss: 0.001076  [ 2880/ 4735]
[2022-08-06 19:03:00,267] loss: 0.000890  [ 3840/ 4735]
[2022-08-06 19:03:43,729] Train Error: Accuracy: 100.000%, Avg loss: 0.001511
[2022-08-06 19:03:56,518] Test  Error: Accuracy: 99.609%, Avg loss: 0.010740
[2022-08-06 19:03:56,519] Epoch 14---------------
[2022-08-06 19:03:56,519] lr: 3.321668e-04
[2022-08-06 19:03:57,598] loss: 0.006172  [    0/ 4735]
[2022-08-06 19:04:13,747] loss: 0.002141  [  960/ 4735]
[2022-08-06 19:04:29,897] loss: 0.001181  [ 1920/ 4735]
[2022-08-06 19:04:46,046] loss: 0.001187  [ 2880/ 4735]
[2022-08-06 19:05:02,194] loss: 0.000760  [ 3840/ 4735]
[2022-08-06 19:05:45,856] Train Error: Accuracy: 100.000%, Avg loss: 0.001615
[2022-08-06 19:05:58,729] Test  Error: Accuracy: 99.854%, Avg loss: 0.006641
[2022-08-06 19:05:58,730] Epoch 15---------------
[2022-08-06 19:05:58,731] lr: 3.155584e-04
[2022-08-06 19:05:59,818] loss: 0.000809  [    0/ 4735]
[2022-08-06 19:06:16,078] loss: 0.000818  [  960/ 4735]
[2022-08-06 19:06:32,339] loss: 0.000871  [ 1920/ 4735]
[2022-08-06 19:06:48,599] loss: 0.001256  [ 2880/ 4735]
[2022-08-06 19:07:04,858] loss: 0.000811  [ 3840/ 4735]
[2022-08-06 19:07:48,694] Train Error: Accuracy: 100.000%, Avg loss: 0.001271
[2022-08-06 19:08:01,570] Test  Error: Accuracy: 99.707%, Avg loss: 0.011371
[2022-08-06 19:08:01,571] Done!
[2022-08-06 19:08:01,575] Number of parameters:2412298
[2022-08-06 19:08:01,575] ## end time: 2022-08-06 19:08:01.571309
[2022-08-06 19:08:01,575] ## used time: 1:27:09.955907
