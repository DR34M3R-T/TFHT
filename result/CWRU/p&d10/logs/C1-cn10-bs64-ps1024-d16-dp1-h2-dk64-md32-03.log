[2022-08-03 16:49:32,399] ## start time: 2022-08-03 16:49:32.249355
[2022-08-03 16:49:32,400] Using cuda device
[2022-08-03 16:49:32,401] In train:p&d10.npy.
[2022-08-03 16:49:32,402] One Channel
[2022-08-03 16:49:32,402] With Normal data.
[2022-08-03 16:49:32,402] Nunber of classes:10.
[2022-08-03 16:49:32,403] Nunber of ViT channels:1.
[2022-08-03 16:49:32,592] Totol epochs: 3
[2022-08-03 16:49:32,593] Epoch 1---------------
[2022-08-03 16:49:32,594] lr: 2.000000e-03
[2022-08-03 16:49:32,606] loss: 2.457110  [    0/ 4776]
[2022-08-03 16:49:32,766] loss: 1.817221  [  960/ 4776]
[2022-08-03 16:49:32,926] loss: 1.326972  [ 1920/ 4776]
[2022-08-03 16:49:33,081] loss: 0.973948  [ 2880/ 4776]
[2022-08-03 16:49:33,238] loss: 0.760467  [ 3840/ 4776]
[2022-08-03 16:49:33,498] Test Error: Accuracy: 93.373%, Avg loss: 0.552859
[2022-08-03 16:49:33,499] Epoch 2---------------
[2022-08-03 16:49:33,500] lr: 1.900000e-03
[2022-08-03 16:49:33,511] loss: 0.523245  [    0/ 4776]
[2022-08-03 16:49:33,669] loss: 0.366420  [  960/ 4776]
[2022-08-03 16:49:33,824] loss: 0.285829  [ 1920/ 4776]
[2022-08-03 16:49:33,981] loss: 0.255369  [ 2880/ 4776]
[2022-08-03 16:49:34,136] loss: 0.192297  [ 3840/ 4776]
[2022-08-03 16:49:34,397] Test Error: Accuracy: 97.658%, Avg loss: 0.178939
[2022-08-03 16:49:34,398] Epoch 3---------------
[2022-08-03 16:49:34,399] lr: 1.805000e-03
[2022-08-03 16:49:34,410] loss: 0.178329  [    0/ 4776]
[2022-08-03 16:49:34,563] loss: 0.107990  [  960/ 4776]
[2022-08-03 16:49:34,720] loss: 0.078949  [ 1920/ 4776]
[2022-08-03 16:49:34,872] loss: 0.069667  [ 2880/ 4776]
[2022-08-03 16:49:35,028] loss: 0.093925  [ 3840/ 4776]
[2022-08-03 16:49:35,298] Test Error: Accuracy: 99.651%, Avg loss: 0.071412
[2022-08-03 16:49:35,298] Done!
[2022-08-03 16:49:35,300] Number of parameters:52010
[2022-08-03 16:49:35,300] ## end time: 2022-08-03 16:49:35.298399
[2022-08-03 16:49:35,301] ## used time: 0:00:03.049044
