[2022-08-06 15:20:50,103] ## start time: 2022-08-06 15:20:49.982104
[2022-08-06 15:20:50,104] Using cuda device
[2022-08-06 15:20:50,105] In train:p&d10.npy.
[2022-08-06 15:20:50,106] One Channel
[2022-08-06 15:20:50,107] With Normal data.
[2022-08-06 15:20:50,107] Nunber of classes:10.
[2022-08-06 15:20:50,108] Nunber of ViT channels:1.
[2022-08-06 15:20:50,300] Totol epochs: 10
[2022-08-06 15:20:50,302] Epoch 1---------------
[2022-08-06 15:20:50,302] lr: 2.000000e-03
[2022-08-06 15:20:50,315] loss: 2.412336  [    0/ 4714]
[2022-08-06 15:20:50,472] loss: 2.139431  [  960/ 4714]
[2022-08-06 15:20:50,630] loss: 1.605748  [ 1920/ 4714]
[2022-08-06 15:20:50,787] loss: 1.180680  [ 2880/ 4714]
[2022-08-06 15:20:50,938] loss: 0.900226  [ 3840/ 4714]
[2022-08-06 15:20:51,334] Train Error: Accuracy: 76.008%, Avg loss: 0.772090
[2022-08-06 15:20:51,454] Test  Error: Accuracy: 75.834%, Avg loss: 0.771307
[2022-08-06 15:20:51,454] Epoch 2---------------
[2022-08-06 15:20:51,455] lr: 1.900000e-03
[2022-08-06 15:20:51,467] loss: 0.900593  [    0/ 4714]
[2022-08-06 15:20:51,619] loss: 0.364090  [  960/ 4714]
[2022-08-06 15:20:51,769] loss: 0.275804  [ 1920/ 4714]
[2022-08-06 15:20:51,919] loss: 0.300765  [ 2880/ 4714]
[2022-08-06 15:20:52,068] loss: 0.272562  [ 3840/ 4714]
[2022-08-06 15:20:52,463] Train Error: Accuracy: 97.370%, Avg loss: 0.150736
[2022-08-06 15:20:52,580] Test  Error: Accuracy: 96.472%, Avg loss: 0.173820
[2022-08-06 15:20:52,581] Epoch 3---------------
[2022-08-06 15:20:52,582] lr: 1.805000e-03
[2022-08-06 15:20:52,595] loss: 0.130180  [    0/ 4714]
[2022-08-06 15:20:52,745] loss: 0.121780  [  960/ 4714]
[2022-08-06 15:20:52,894] loss: 0.085690  [ 1920/ 4714]
[2022-08-06 15:20:53,047] loss: 0.116127  [ 2880/ 4714]
[2022-08-06 15:20:53,197] loss: 0.118305  [ 3840/ 4714]
[2022-08-06 15:20:53,592] Train Error: Accuracy: 98.388%, Avg loss: 0.077877
[2022-08-06 15:20:53,710] Test  Error: Accuracy: 97.777%, Avg loss: 0.099168
[2022-08-06 15:20:53,710] Epoch 4---------------
[2022-08-06 15:20:53,712] lr: 1.714750e-03
[2022-08-06 15:20:53,723] loss: 0.150606  [    0/ 4714]
[2022-08-06 15:20:53,875] loss: 0.063422  [  960/ 4714]
[2022-08-06 15:20:54,025] loss: 0.051887  [ 1920/ 4714]
[2022-08-06 15:20:54,174] loss: 0.027023  [ 2880/ 4714]
[2022-08-06 15:20:54,323] loss: 0.026376  [ 3840/ 4714]
[2022-08-06 15:20:54,724] Train Error: Accuracy: 98.409%, Avg loss: 0.065054
[2022-08-06 15:20:54,841] Test  Error: Accuracy: 97.583%, Avg loss: 0.079695
[2022-08-06 15:20:54,842] Epoch 5---------------
[2022-08-06 15:20:54,843] lr: 1.629012e-03
[2022-08-06 15:20:54,854] loss: 0.085328  [    0/ 4714]
[2022-08-06 15:20:55,005] loss: 0.024309  [  960/ 4714]
[2022-08-06 15:20:55,153] loss: 0.038725  [ 1920/ 4714]
[2022-08-06 15:20:55,301] loss: 0.015389  [ 2880/ 4714]
[2022-08-06 15:20:55,450] loss: 0.037071  [ 3840/ 4714]
[2022-08-06 15:20:55,846] Train Error: Accuracy: 99.767%, Avg loss: 0.021002
[2022-08-06 15:20:55,963] Test  Error: Accuracy: 99.323%, Avg loss: 0.033920
[2022-08-06 15:20:55,963] Epoch 6---------------
[2022-08-06 15:20:55,964] lr: 1.547562e-03
[2022-08-06 15:20:55,976] loss: 0.013513  [    0/ 4714]
[2022-08-06 15:20:56,124] loss: 0.011454  [  960/ 4714]
[2022-08-06 15:20:56,272] loss: 0.045122  [ 1920/ 4714]
[2022-08-06 15:20:56,420] loss: 0.020590  [ 2880/ 4714]
[2022-08-06 15:20:56,570] loss: 0.055951  [ 3840/ 4714]
[2022-08-06 15:20:56,965] Train Error: Accuracy: 98.218%, Avg loss: 0.065650
[2022-08-06 15:20:57,082] Test  Error: Accuracy: 97.680%, Avg loss: 0.078867
[2022-08-06 15:20:57,082] Epoch 7---------------
[2022-08-06 15:20:57,083] lr: 1.080720e-03
[2022-08-06 15:20:57,095] loss: 0.047557  [    0/ 4714]
[2022-08-06 15:20:57,247] loss: 0.012051  [  960/ 4714]
[2022-08-06 15:20:57,398] loss: 0.008824  [ 1920/ 4714]
[2022-08-06 15:20:57,547] loss: 0.010470  [ 2880/ 4714]
[2022-08-06 15:20:57,696] loss: 0.019259  [ 3840/ 4714]
[2022-08-06 15:20:58,092] Train Error: Accuracy: 99.830%, Avg loss: 0.013534
[2022-08-06 15:20:58,210] Test  Error: Accuracy: 99.468%, Avg loss: 0.024293
[2022-08-06 15:20:58,210] Epoch 8---------------
[2022-08-06 15:20:58,213] lr: 1.026684e-03
[2022-08-06 15:20:58,224] loss: 0.036787  [    0/ 4714]
[2022-08-06 15:20:58,373] loss: 0.006305  [  960/ 4714]
[2022-08-06 15:20:58,522] loss: 0.007457  [ 1920/ 4714]
[2022-08-06 15:20:58,672] loss: 0.030825  [ 2880/ 4714]
[2022-08-06 15:20:58,820] loss: 0.004243  [ 3840/ 4714]
[2022-08-06 15:20:59,216] Train Error: Accuracy: 99.873%, Avg loss: 0.012064
[2022-08-06 15:20:59,332] Test  Error: Accuracy: 99.662%, Avg loss: 0.017034
[2022-08-06 15:20:59,333] Epoch 9---------------
[2022-08-06 15:20:59,334] lr: 9.753500e-04
[2022-08-06 15:20:59,345] loss: 0.012137  [    0/ 4714]
[2022-08-06 15:20:59,496] loss: 0.009103  [  960/ 4714]
[2022-08-06 15:20:59,647] loss: 0.009122  [ 1920/ 4714]
[2022-08-06 15:20:59,795] loss: 0.005606  [ 2880/ 4714]
[2022-08-06 15:20:59,944] loss: 0.012889  [ 3840/ 4714]
[2022-08-06 15:21:00,342] Train Error: Accuracy: 99.809%, Avg loss: 0.011122
[2022-08-06 15:21:00,460] Test  Error: Accuracy: 99.323%, Avg loss: 0.025204
[2022-08-06 15:21:00,460] Epoch 10---------------
[2022-08-06 15:21:00,461] lr: 6.811233e-04
[2022-08-06 15:21:00,473] loss: 0.008016  [    0/ 4714]
[2022-08-06 15:21:00,622] loss: 0.009005  [  960/ 4714]
[2022-08-06 15:21:00,772] loss: 0.004158  [ 1920/ 4714]
[2022-08-06 15:21:00,922] loss: 0.003998  [ 2880/ 4714]
[2022-08-06 15:21:01,079] loss: 0.003536  [ 3840/ 4714]
[2022-08-06 15:21:01,479] Train Error: Accuracy: 99.915%, Avg loss: 0.007575
[2022-08-06 15:21:01,597] Test  Error: Accuracy: 99.758%, Avg loss: 0.012471
[2022-08-06 15:21:01,597] Done!
[2022-08-06 15:21:01,599] Number of parameters:30666
[2022-08-06 15:21:01,599] ## end time: 2022-08-06 15:21:01.597642
[2022-08-06 15:21:01,600] ## used time: 0:00:11.615538
