[2022-08-07 14:42:02,056] ## start time: 2022-08-07 14:42:01.909369
[2022-08-07 14:42:02,056] Using cuda device
[2022-08-07 14:42:02,057] In train:p&d10.npy.
[2022-08-07 14:42:02,059] One Channel
[2022-08-07 14:42:02,059] With Normal data.
[2022-08-07 14:42:02,060] Nunber of classes:10.
[2022-08-07 14:42:02,060] Nunber of ViT channels:1.
[2022-08-07 14:42:02,261] Totol epochs: 15
[2022-08-07 14:42:02,262] Epoch 1---------------
[2022-08-07 14:42:02,263] lr: 2.000000e-03
[2022-08-07 14:42:02,518] loss: 2.365082  [    0/ 4783]
[2022-08-07 14:42:06,302] loss: 1.553170  [  960/ 4783]
[2022-08-07 14:42:10,086] loss: 0.892522  [ 1920/ 4783]
[2022-08-07 14:42:13,870] loss: 0.591499  [ 2880/ 4783]
[2022-08-07 14:42:17,654] loss: 0.572495  [ 3840/ 4783]
[2022-08-07 14:42:28,069] Train Error: Accuracy: 87.205%, Avg loss: 0.337896
[2022-08-07 14:42:30,978] Test  Error: Accuracy: 86.500%, Avg loss: 0.370986
[2022-08-07 14:42:30,978] Epoch 2---------------
[2022-08-07 14:42:30,979] lr: 1.900000e-03
[2022-08-07 14:42:31,235] loss: 0.333269  [    0/ 4783]
[2022-08-07 14:42:35,019] loss: 0.190723  [  960/ 4783]
[2022-08-07 14:42:38,804] loss: 0.338770  [ 1920/ 4783]
[2022-08-07 14:42:42,589] loss: 0.194539  [ 2880/ 4783]
[2022-08-07 14:42:46,374] loss: 0.179134  [ 3840/ 4783]
[2022-08-07 14:42:56,792] Train Error: Accuracy: 83.797%, Avg loss: 0.414683
[2022-08-07 14:42:59,701] Test  Error: Accuracy: 82.450%, Avg loss: 0.472150
[2022-08-07 14:42:59,701] Epoch 3---------------
[2022-08-07 14:42:59,702] lr: 1.326841e-03
[2022-08-07 14:42:59,957] loss: 0.380698  [    0/ 4783]
[2022-08-07 14:43:03,741] loss: 0.079207  [  960/ 4783]
[2022-08-07 14:43:07,525] loss: 0.108392  [ 1920/ 4783]
[2022-08-07 14:43:11,308] loss: 0.054074  [ 2880/ 4783]
[2022-08-07 14:43:15,092] loss: 0.051292  [ 3840/ 4783]
[2022-08-07 14:43:25,506] Train Error: Accuracy: 97.888%, Avg loss: 0.072369
[2022-08-07 14:43:28,415] Test  Error: Accuracy: 97.400%, Avg loss: 0.085633
[2022-08-07 14:43:28,415] Epoch 4---------------
[2022-08-07 14:43:28,416] lr: 1.260499e-03
[2022-08-07 14:43:28,671] loss: 0.104920  [    0/ 4783]
[2022-08-07 14:43:32,454] loss: 0.032854  [  960/ 4783]
[2022-08-07 14:43:36,238] loss: 0.063673  [ 1920/ 4783]
[2022-08-07 14:43:40,022] loss: 0.049138  [ 2880/ 4783]
[2022-08-07 14:43:43,806] loss: 0.091955  [ 3840/ 4783]
[2022-08-07 14:43:54,220] Train Error: Accuracy: 98.181%, Avg loss: 0.059980
[2022-08-07 14:43:57,128] Test  Error: Accuracy: 97.650%, Avg loss: 0.085172
[2022-08-07 14:43:57,128] Epoch 5---------------
[2022-08-07 14:43:57,129] lr: 1.197474e-03
[2022-08-07 14:43:57,384] loss: 0.031455  [    0/ 4783]
[2022-08-07 14:44:01,168] loss: 0.024256  [  960/ 4783]
[2022-08-07 14:44:04,952] loss: 0.020339  [ 1920/ 4783]
[2022-08-07 14:44:08,735] loss: 0.036118  [ 2880/ 4783]
[2022-08-07 14:44:12,519] loss: 0.046523  [ 3840/ 4783]
[2022-08-07 14:44:22,933] Train Error: Accuracy: 98.829%, Avg loss: 0.044022
[2022-08-07 14:44:25,842] Test  Error: Accuracy: 98.050%, Avg loss: 0.068859
[2022-08-07 14:44:25,843] Epoch 6---------------
[2022-08-07 14:44:25,844] lr: 1.137600e-03
[2022-08-07 14:44:26,097] loss: 0.022438  [    0/ 4783]
[2022-08-07 14:44:29,881] loss: 0.065463  [  960/ 4783]
[2022-08-07 14:44:33,665] loss: 0.031754  [ 1920/ 4783]
[2022-08-07 14:44:37,449] loss: 0.034108  [ 2880/ 4783]
[2022-08-07 14:44:41,232] loss: 0.148079  [ 3840/ 4783]
[2022-08-07 14:44:51,647] Train Error: Accuracy: 99.185%, Avg loss: 0.025780
[2022-08-07 14:44:54,556] Test  Error: Accuracy: 98.650%, Avg loss: 0.043173
[2022-08-07 14:44:54,556] Epoch 7---------------
[2022-08-07 14:44:54,557] lr: 1.080720e-03
[2022-08-07 14:44:54,812] loss: 0.031526  [    0/ 4783]
[2022-08-07 14:44:58,595] loss: 0.007101  [  960/ 4783]
[2022-08-07 14:45:02,380] loss: 0.004996  [ 1920/ 4783]
[2022-08-07 14:45:06,163] loss: 0.026364  [ 2880/ 4783]
[2022-08-07 14:45:09,946] loss: 0.065263  [ 3840/ 4783]
[2022-08-07 14:45:20,364] Train Error: Accuracy: 99.561%, Avg loss: 0.018377
[2022-08-07 14:45:23,274] Test  Error: Accuracy: 98.600%, Avg loss: 0.056009
[2022-08-07 14:45:23,275] Epoch 8---------------
[2022-08-07 14:45:23,276] lr: 7.547072e-04
[2022-08-07 14:45:23,531] loss: 0.007354  [    0/ 4783]
[2022-08-07 14:45:27,317] loss: 0.007514  [  960/ 4783]
[2022-08-07 14:45:31,101] loss: 0.008808  [ 1920/ 4783]
[2022-08-07 14:45:34,884] loss: 0.011158  [ 2880/ 4783]
[2022-08-07 14:45:38,668] loss: 0.024718  [ 3840/ 4783]
[2022-08-07 14:45:49,082] Train Error: Accuracy: 99.665%, Avg loss: 0.011181
[2022-08-07 14:45:51,990] Test  Error: Accuracy: 98.850%, Avg loss: 0.038925
[2022-08-07 14:45:51,990] Epoch 9---------------
[2022-08-07 14:45:51,991] lr: 7.169718e-04
[2022-08-07 14:45:52,246] loss: 0.007492  [    0/ 4783]
[2022-08-07 14:45:56,030] loss: 0.005659  [  960/ 4783]
[2022-08-07 14:45:59,815] loss: 0.006937  [ 1920/ 4783]
[2022-08-07 14:46:03,598] loss: 0.023663  [ 2880/ 4783]
[2022-08-07 14:46:07,383] loss: 0.002097  [ 3840/ 4783]
[2022-08-07 14:46:17,799] Train Error: Accuracy: 99.728%, Avg loss: 0.011453
[2022-08-07 14:46:20,706] Test  Error: Accuracy: 98.400%, Avg loss: 0.057541
[2022-08-07 14:46:20,706] Epoch 10---------------
[2022-08-07 14:46:20,707] lr: 5.006882e-04
[2022-08-07 14:46:20,961] loss: 0.013835  [    0/ 4783]
[2022-08-07 14:46:24,745] loss: 0.006449  [  960/ 4783]
[2022-08-07 14:46:28,531] loss: 0.003848  [ 1920/ 4783]
[2022-08-07 14:46:32,315] loss: 0.002934  [ 2880/ 4783]
[2022-08-07 14:46:36,098] loss: 0.004457  [ 3840/ 4783]
[2022-08-07 14:46:46,514] Train Error: Accuracy: 99.582%, Avg loss: 0.015365
[2022-08-07 14:46:49,422] Test  Error: Accuracy: 98.100%, Avg loss: 0.062537
[2022-08-07 14:46:49,422] Epoch 11---------------
[2022-08-07 14:46:49,423] lr: 4.292775e-04
[2022-08-07 14:46:49,678] loss: 0.025685  [    0/ 4783]
[2022-08-07 14:46:53,463] loss: 0.005139  [  960/ 4783]
[2022-08-07 14:46:57,246] loss: 0.002719  [ 1920/ 4783]
[2022-08-07 14:47:01,031] loss: 0.003025  [ 2880/ 4783]
[2022-08-07 14:47:04,816] loss: 0.002916  [ 3840/ 4783]
[2022-08-07 14:47:15,230] Train Error: Accuracy: 99.791%, Avg loss: 0.009898
[2022-08-07 14:47:18,140] Test  Error: Accuracy: 98.550%, Avg loss: 0.048754
[2022-08-07 14:47:18,140] Epoch 12---------------
[2022-08-07 14:47:18,143] lr: 4.078137e-04
[2022-08-07 14:47:18,397] loss: 0.007140  [    0/ 4783]
[2022-08-07 14:47:22,179] loss: 0.005816  [  960/ 4783]
[2022-08-07 14:47:25,962] loss: 0.003791  [ 1920/ 4783]
[2022-08-07 14:47:29,747] loss: 0.001036  [ 2880/ 4783]
[2022-08-07 14:47:33,530] loss: 0.001756  [ 3840/ 4783]
[2022-08-07 14:47:43,945] Train Error: Accuracy: 99.979%, Avg loss: 0.004715
[2022-08-07 14:47:46,852] Test  Error: Accuracy: 98.650%, Avg loss: 0.042931
[2022-08-07 14:47:46,852] Epoch 13---------------
[2022-08-07 14:47:46,853] lr: 3.874230e-04
[2022-08-07 14:47:47,108] loss: 0.002254  [    0/ 4783]
[2022-08-07 14:47:50,894] loss: 0.004510  [  960/ 4783]
[2022-08-07 14:47:54,677] loss: 0.010325  [ 1920/ 4783]
[2022-08-07 14:47:58,461] loss: 0.005890  [ 2880/ 4783]
[2022-08-07 14:48:02,246] loss: 0.033661  [ 3840/ 4783]
[2022-08-07 14:48:12,660] Train Error: Accuracy: 99.937%, Avg loss: 0.005680
[2022-08-07 14:48:15,569] Test  Error: Accuracy: 99.050%, Avg loss: 0.047013
[2022-08-07 14:48:15,569] Epoch 14---------------
[2022-08-07 14:48:15,570] lr: 3.321668e-04
[2022-08-07 14:48:15,824] loss: 0.002559  [    0/ 4783]
[2022-08-07 14:48:19,608] loss: 0.016538  [  960/ 4783]
[2022-08-07 14:48:23,392] loss: 0.003481  [ 1920/ 4783]
[2022-08-07 14:48:27,176] loss: 0.002414  [ 2880/ 4783]
[2022-08-07 14:48:30,960] loss: 0.003103  [ 3840/ 4783]
[2022-08-07 14:48:41,377] Train Error: Accuracy: 99.937%, Avg loss: 0.004893
[2022-08-07 14:48:44,290] Test  Error: Accuracy: 98.900%, Avg loss: 0.040912
[2022-08-07 14:48:44,291] Epoch 15---------------
[2022-08-07 14:48:44,292] lr: 3.155584e-04
[2022-08-07 14:48:44,546] loss: 0.003636  [    0/ 4783]
[2022-08-07 14:48:48,330] loss: 0.004359  [  960/ 4783]
[2022-08-07 14:48:52,113] loss: 0.022963  [ 1920/ 4783]
[2022-08-07 14:48:55,897] loss: 0.003932  [ 2880/ 4783]
[2022-08-07 14:48:59,681] loss: 0.001479  [ 3840/ 4783]
[2022-08-07 14:49:10,095] Train Error: Accuracy: 99.958%, Avg loss: 0.004661
[2022-08-07 14:49:13,003] Test  Error: Accuracy: 99.050%, Avg loss: 0.039769
[2022-08-07 14:49:13,003] Done!
[2022-08-07 14:49:13,005] Number of parameters:567050
[2022-08-07 14:49:13,006] ## end time: 2022-08-07 14:49:13.003340
[2022-08-07 14:49:13,006] ## used time: 0:07:11.093971
