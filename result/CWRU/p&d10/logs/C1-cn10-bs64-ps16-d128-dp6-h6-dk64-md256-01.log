[2022-08-03 17:13:36,321] ## start time: 2022-08-03 17:13:36.175418
[2022-08-03 17:13:36,322] Using cuda device
[2022-08-03 17:13:36,323] In train:p&d10.npy.
[2022-08-03 17:13:36,323] One Channel
[2022-08-03 17:13:36,323] With Normal data.
[2022-08-03 17:13:36,323] Nunber of classes:10.
[2022-08-03 17:13:36,324] Nunber of ViT channels:1.
[2022-08-03 17:13:37,487] Totol epochs: 10
[2022-08-03 17:13:37,490] Epoch 1---------------
[2022-08-03 17:13:37,490] lr: 2.000000e-03
[2022-08-03 17:13:40,619] loss: 2.475076  [    0/ 4750]
[2022-08-03 17:14:02,650] loss: 1.921233  [  960/ 4750]
[2022-08-03 17:14:24,752] loss: 1.624273  [ 1920/ 4750]
[2022-08-03 17:14:46,876] loss: 1.243595  [ 2880/ 4750]
[2022-08-03 17:15:09,065] loss: 0.892933  [ 3840/ 4750]
[2022-08-03 17:15:45,761] Test Error: Accuracy: 53.222%, Avg loss: 1.545850
[2022-08-03 17:15:45,761] Epoch 2---------------
[2022-08-03 17:15:45,761] lr: 1.900000e-03
[2022-08-03 17:15:47,247] loss: 1.299900  [    0/ 4750]
[2022-08-03 17:16:09,518] loss: 0.328011  [  960/ 4750]
[2022-08-03 17:16:31,790] loss: 0.158455  [ 1920/ 4750]
[2022-08-03 17:16:54,068] loss: 0.224842  [ 2880/ 4750]
[2022-08-03 17:17:16,344] loss: 0.086958  [ 3840/ 4750]
[2022-08-03 17:17:53,040] Test Error: Accuracy: 96.065%, Avg loss: 0.134547
[2022-08-03 17:17:53,041] Epoch 3---------------
[2022-08-03 17:17:53,042] lr: 1.805000e-03
[2022-08-03 17:17:54,530] loss: 0.181237  [    0/ 4750]
[2022-08-03 17:18:16,801] loss: 0.081676  [  960/ 4750]
[2022-08-03 17:18:39,072] loss: 0.096027  [ 1920/ 4750]
[2022-08-03 17:19:01,344] loss: 0.060885  [ 2880/ 4750]
[2022-08-03 17:19:23,616] loss: 0.090853  [ 3840/ 4750]
[2022-08-03 17:20:00,315] Test Error: Accuracy: 95.770%, Avg loss: 0.135487
[2022-08-03 17:20:00,315] Epoch 4---------------
[2022-08-03 17:20:00,316] lr: 1.547562e-03
[2022-08-03 17:20:01,802] loss: 0.147718  [    0/ 4750]
[2022-08-03 17:20:24,172] loss: 0.013253  [  960/ 4750]
[2022-08-03 17:20:46,606] loss: 0.039284  [ 1920/ 4750]
[2022-08-03 17:21:09,039] loss: 0.006078  [ 2880/ 4750]
[2022-08-03 17:21:31,473] loss: 0.026835  [ 3840/ 4750]
[2022-08-03 17:22:08,436] Test Error: Accuracy: 99.557%, Avg loss: 0.022929
[2022-08-03 17:22:08,437] Epoch 5---------------
[2022-08-03 17:22:08,438] lr: 1.470184e-03
[2022-08-03 17:22:09,936] loss: 0.006558  [    0/ 4750]
[2022-08-03 17:22:32,371] loss: 0.004170  [  960/ 4750]
[2022-08-03 17:22:54,805] loss: 0.007424  [ 1920/ 4750]
[2022-08-03 17:23:17,237] loss: 0.005684  [ 2880/ 4750]
[2022-08-03 17:23:39,671] loss: 0.017323  [ 3840/ 4750]
[2022-08-03 17:24:16,640] Test Error: Accuracy: 99.852%, Avg loss: 0.010976
[2022-08-03 17:24:16,640] Epoch 6---------------
[2022-08-03 17:24:16,642] lr: 1.396675e-03
[2022-08-03 17:24:18,139] loss: 0.007602  [    0/ 4750]
[2022-08-03 17:24:40,573] loss: 0.004215  [  960/ 4750]
[2022-08-03 17:25:03,009] loss: 0.032354  [ 1920/ 4750]
[2022-08-03 17:25:25,443] loss: 0.005850  [ 2880/ 4750]
[2022-08-03 17:25:47,875] loss: 0.003400  [ 3840/ 4750]
[2022-08-03 17:26:24,835] Test Error: Accuracy: 99.803%, Avg loss: 0.008301
[2022-08-03 17:26:24,836] Epoch 7---------------
[2022-08-03 17:26:24,837] lr: 1.326841e-03
[2022-08-03 17:26:26,335] loss: 0.003912  [    0/ 4750]
[2022-08-03 17:26:48,767] loss: 0.002746  [  960/ 4750]
[2022-08-03 17:27:11,201] loss: 0.002457  [ 1920/ 4750]
[2022-08-03 17:27:33,634] loss: 0.001381  [ 2880/ 4750]
[2022-08-03 17:27:56,066] loss: 0.001139  [ 3840/ 4750]
[2022-08-03 17:28:33,024] Test Error: Accuracy: 99.705%, Avg loss: 0.007456
[2022-08-03 17:28:33,025] Epoch 8---------------
[2022-08-03 17:28:33,026] lr: 1.260499e-03
[2022-08-03 17:28:34,524] loss: 0.001648  [    0/ 4750]
[2022-08-03 17:28:56,958] loss: 0.002316  [  960/ 4750]
[2022-08-03 17:29:19,392] loss: 0.003304  [ 1920/ 4750]
[2022-08-03 17:29:41,825] loss: 0.361486  [ 2880/ 4750]
[2022-08-03 17:30:04,258] loss: 0.151739  [ 3840/ 4750]
[2022-08-03 17:30:41,222] Test Error: Accuracy: 98.426%, Avg loss: 0.058954
[2022-08-03 17:30:41,223] Epoch 9---------------
[2022-08-03 17:30:41,224] lr: 8.802533e-04
[2022-08-03 17:30:42,723] loss: 0.050073  [    0/ 4750]
[2022-08-03 17:31:05,157] loss: 0.028098  [  960/ 4750]
[2022-08-03 17:31:27,589] loss: 0.019669  [ 1920/ 4750]
[2022-08-03 17:31:50,023] loss: 0.041431  [ 2880/ 4750]
[2022-08-03 17:32:12,457] loss: 0.009088  [ 3840/ 4750]
[2022-08-03 17:32:49,417] Test Error: Accuracy: 98.721%, Avg loss: 0.050429
[2022-08-03 17:32:49,417] Epoch 10---------------
[2022-08-03 17:32:49,418] lr: 8.362407e-04
[2022-08-03 17:32:50,918] loss: 0.023699  [    0/ 4750]
[2022-08-03 17:33:13,351] loss: 0.005285  [  960/ 4750]
[2022-08-03 17:33:35,786] loss: 0.007516  [ 1920/ 4750]
[2022-08-03 17:33:58,220] loss: 0.010152  [ 2880/ 4750]
[2022-08-03 17:34:20,655] loss: 0.016867  [ 3840/ 4750]
[2022-08-03 17:34:57,621] Test Error: Accuracy: 99.754%, Avg loss: 0.010623
[2022-08-03 17:34:57,621] Done!
[2022-08-03 17:34:57,625] Number of parameters:3198730
[2022-08-03 17:34:57,626] ## end time: 2022-08-03 17:34:57.621615
[2022-08-03 17:34:57,626] ## used time: 0:21:21.446197
