[2022-08-06 15:18:07,036] ## start time: 2022-08-06 15:18:06.903047
[2022-08-06 15:18:07,036] Using cuda device
[2022-08-06 15:18:07,038] In train:p&d10.npy.
[2022-08-06 15:18:07,038] One Channel
[2022-08-06 15:18:07,039] With Normal data.
[2022-08-06 15:18:07,039] Nunber of classes:10.
[2022-08-06 15:18:07,040] Nunber of ViT channels:1.
[2022-08-06 15:18:07,230] Totol epochs: 10
[2022-08-06 15:18:07,232] Epoch 1---------------
[2022-08-06 15:18:07,232] lr: 2.000000e-03
[2022-08-06 15:18:07,247] loss: 2.362392  [    0/ 4794]
[2022-08-06 15:18:07,408] loss: 1.798008  [  960/ 4794]
[2022-08-06 15:18:07,573] loss: 1.378060  [ 1920/ 4794]
[2022-08-06 15:18:07,732] loss: 0.642343  [ 2880/ 4794]
[2022-08-06 15:18:07,887] loss: 0.470051  [ 3840/ 4794]
[2022-08-06 15:18:08,342] Train Error: Accuracy: 92.845%, Avg loss: 0.310053
[2022-08-06 15:18:08,475] Test  Error: Accuracy: 92.157%, Avg loss: 0.330668
[2022-08-06 15:18:08,475] Epoch 2---------------
[2022-08-06 15:18:08,476] lr: 1.900000e-03
[2022-08-06 15:18:08,489] loss: 0.318690  [    0/ 4794]
[2022-08-06 15:18:08,649] loss: 0.147724  [  960/ 4794]
[2022-08-06 15:18:08,809] loss: 0.089577  [ 1920/ 4794]
[2022-08-06 15:18:08,966] loss: 0.078184  [ 2880/ 4794]
[2022-08-06 15:18:09,123] loss: 0.043912  [ 3840/ 4794]
[2022-08-06 15:18:09,566] Train Error: Accuracy: 99.479%, Avg loss: 0.048430
[2022-08-06 15:18:09,693] Test  Error: Accuracy: 99.849%, Avg loss: 0.044087
[2022-08-06 15:18:09,693] Epoch 3---------------
[2022-08-06 15:18:09,695] lr: 1.805000e-03
[2022-08-06 15:18:09,708] loss: 0.057080  [    0/ 4794]
[2022-08-06 15:18:09,863] loss: 0.029213  [  960/ 4794]
[2022-08-06 15:18:10,019] loss: 0.025672  [ 1920/ 4794]
[2022-08-06 15:18:10,175] loss: 0.022576  [ 2880/ 4794]
[2022-08-06 15:18:10,333] loss: 0.033312  [ 3840/ 4794]
[2022-08-06 15:18:10,778] Train Error: Accuracy: 99.771%, Avg loss: 0.023225
[2022-08-06 15:18:10,901] Test  Error: Accuracy: 99.548%, Avg loss: 0.027030
[2022-08-06 15:18:10,902] Epoch 4---------------
[2022-08-06 15:18:10,903] lr: 1.714750e-03
[2022-08-06 15:18:10,916] loss: 0.015684  [    0/ 4794]
[2022-08-06 15:18:11,071] loss: 0.011750  [  960/ 4794]
[2022-08-06 15:18:11,227] loss: 0.009626  [ 1920/ 4794]
[2022-08-06 15:18:11,383] loss: 0.022631  [ 2880/ 4794]
[2022-08-06 15:18:11,539] loss: 0.036009  [ 3840/ 4794]
[2022-08-06 15:18:11,982] Train Error: Accuracy: 99.833%, Avg loss: 0.015073
[2022-08-06 15:18:12,107] Test  Error: Accuracy: 99.648%, Avg loss: 0.020985
[2022-08-06 15:18:12,107] Epoch 5---------------
[2022-08-06 15:18:12,108] lr: 1.629012e-03
[2022-08-06 15:18:12,122] loss: 0.017255  [    0/ 4794]
[2022-08-06 15:18:12,280] loss: 0.443820  [  960/ 4794]
[2022-08-06 15:18:12,440] loss: 0.041686  [ 1920/ 4794]
[2022-08-06 15:18:12,597] loss: 0.016736  [ 2880/ 4794]
[2022-08-06 15:18:12,757] loss: 0.016021  [ 3840/ 4794]
[2022-08-06 15:18:13,195] Train Error: Accuracy: 99.812%, Avg loss: 0.015418
[2022-08-06 15:18:13,319] Test  Error: Accuracy: 99.749%, Avg loss: 0.018951
[2022-08-06 15:18:13,319] Epoch 6---------------
[2022-08-06 15:18:13,320] lr: 1.547562e-03
[2022-08-06 15:18:13,333] loss: 0.048839  [    0/ 4794]
[2022-08-06 15:18:13,488] loss: 0.008898  [  960/ 4794]
[2022-08-06 15:18:13,644] loss: 0.008086  [ 1920/ 4794]
[2022-08-06 15:18:13,803] loss: 0.010157  [ 2880/ 4794]
[2022-08-06 15:18:13,960] loss: 0.005046  [ 3840/ 4794]
[2022-08-06 15:18:14,401] Train Error: Accuracy: 99.875%, Avg loss: 0.009820
[2022-08-06 15:18:14,536] Test  Error: Accuracy: 99.799%, Avg loss: 0.011635
[2022-08-06 15:18:14,536] Epoch 7---------------
[2022-08-06 15:18:14,537] lr: 1.470184e-03
[2022-08-06 15:18:14,550] loss: 0.006260  [    0/ 4794]
[2022-08-06 15:18:14,711] loss: 0.006426  [  960/ 4794]
[2022-08-06 15:18:14,869] loss: 0.003867  [ 1920/ 4794]
[2022-08-06 15:18:15,025] loss: 0.022424  [ 2880/ 4794]
[2022-08-06 15:18:15,182] loss: 0.037955  [ 3840/ 4794]
[2022-08-06 15:18:15,632] Train Error: Accuracy: 99.291%, Avg loss: 0.030122
[2022-08-06 15:18:15,759] Test  Error: Accuracy: 99.397%, Avg loss: 0.025673
[2022-08-06 15:18:15,760] Epoch 8---------------
[2022-08-06 15:18:15,761] lr: 1.026684e-03
[2022-08-06 15:18:15,775] loss: 0.062417  [    0/ 4794]
[2022-08-06 15:18:15,934] loss: 0.070424  [  960/ 4794]
[2022-08-06 15:18:16,090] loss: 0.004371  [ 1920/ 4794]
[2022-08-06 15:18:16,247] loss: 0.006327  [ 2880/ 4794]
[2022-08-06 15:18:16,404] loss: 0.006818  [ 3840/ 4794]
[2022-08-06 15:18:16,868] Train Error: Accuracy: 99.979%, Avg loss: 0.006601
[2022-08-06 15:18:17,000] Test  Error: Accuracy: 99.899%, Avg loss: 0.009387
[2022-08-06 15:18:17,000] Epoch 9---------------
[2022-08-06 15:18:17,001] lr: 9.753500e-04
[2022-08-06 15:18:17,015] loss: 0.008791  [    0/ 4794]
[2022-08-06 15:18:17,171] loss: 0.004070  [  960/ 4794]
[2022-08-06 15:18:17,329] loss: 0.008367  [ 1920/ 4794]
[2022-08-06 15:18:17,484] loss: 0.005328  [ 2880/ 4794]
[2022-08-06 15:18:17,644] loss: 0.003331  [ 3840/ 4794]
[2022-08-06 15:18:18,102] Train Error: Accuracy: 99.958%, Avg loss: 0.005458
[2022-08-06 15:18:18,232] Test  Error: Accuracy: 99.899%, Avg loss: 0.007108
[2022-08-06 15:18:18,232] Epoch 10---------------
[2022-08-06 15:18:18,235] lr: 9.265825e-04
[2022-08-06 15:18:18,248] loss: 0.008194  [    0/ 4794]
[2022-08-06 15:18:18,404] loss: 0.003570  [  960/ 4794]
[2022-08-06 15:18:18,561] loss: 0.004888  [ 1920/ 4794]
[2022-08-06 15:18:18,718] loss: 0.003436  [ 2880/ 4794]
[2022-08-06 15:18:18,877] loss: 0.003218  [ 3840/ 4794]
[2022-08-06 15:18:19,331] Train Error: Accuracy: 99.979%, Avg loss: 0.004097
[2022-08-06 15:18:19,460] Test  Error: Accuracy: 100.000%, Avg loss: 0.004934
[2022-08-06 15:18:19,460] Done!
[2022-08-06 15:18:19,462] Number of parameters:124874
[2022-08-06 15:18:19,462] ## end time: 2022-08-06 15:18:19.460404
[2022-08-06 15:18:19,463] ## used time: 0:00:12.557357
