[2022-08-06 15:30:25,258] ## start time: 2022-08-06 15:30:25.133136
[2022-08-06 15:30:25,259] Using cuda device
[2022-08-06 15:30:25,260] In train:p&d10.npy.
[2022-08-06 15:30:25,261] One Channel
[2022-08-06 15:30:25,262] With Normal data.
[2022-08-06 15:30:25,262] Nunber of classes:10.
[2022-08-06 15:30:25,263] Nunber of ViT channels:1.
[2022-08-06 15:30:25,450] Totol epochs: 10
[2022-08-06 15:30:25,451] Epoch 1---------------
[2022-08-06 15:30:25,453] lr: 2.000000e-03
[2022-08-06 15:30:25,465] loss: 2.537815  [    0/ 4709]
[2022-08-06 15:30:25,635] loss: 1.745436  [  960/ 4709]
[2022-08-06 15:30:25,798] loss: 1.210436  [ 1920/ 4709]
[2022-08-06 15:30:25,952] loss: 0.727406  [ 2880/ 4709]
[2022-08-06 15:30:26,105] loss: 0.411761  [ 3840/ 4709]
[2022-08-06 15:30:26,531] Train Error: Accuracy: 94.203%, Avg loss: 0.225057
[2022-08-06 15:30:26,662] Test  Error: Accuracy: 93.877%, Avg loss: 0.222789
[2022-08-06 15:30:26,662] Epoch 2---------------
[2022-08-06 15:30:26,663] lr: 1.900000e-03
[2022-08-06 15:30:26,675] loss: 0.182736  [    0/ 4709]
[2022-08-06 15:30:26,829] loss: 0.111629  [  960/ 4709]
[2022-08-06 15:30:26,980] loss: 0.061572  [ 1920/ 4709]
[2022-08-06 15:30:27,132] loss: 0.046372  [ 2880/ 4709]
[2022-08-06 15:30:27,285] loss: 0.040286  [ 3840/ 4709]
[2022-08-06 15:30:27,710] Train Error: Accuracy: 99.320%, Avg loss: 0.040608
[2022-08-06 15:30:27,837] Test  Error: Accuracy: 99.373%, Avg loss: 0.043027
[2022-08-06 15:30:27,837] Epoch 3---------------
[2022-08-06 15:30:27,838] lr: 1.805000e-03
[2022-08-06 15:30:27,850] loss: 0.029608  [    0/ 4709]
[2022-08-06 15:30:28,001] loss: 0.040875  [  960/ 4709]
[2022-08-06 15:30:28,151] loss: 0.017951  [ 1920/ 4709]
[2022-08-06 15:30:28,301] loss: 0.020015  [ 2880/ 4709]
[2022-08-06 15:30:28,452] loss: 0.038901  [ 3840/ 4709]
[2022-08-06 15:30:28,873] Train Error: Accuracy: 97.154%, Avg loss: 0.088345
[2022-08-06 15:30:29,000] Test  Error: Accuracy: 97.734%, Avg loss: 0.085642
[2022-08-06 15:30:29,001] Epoch 4---------------
[2022-08-06 15:30:29,001] lr: 1.260499e-03
[2022-08-06 15:30:29,014] loss: 0.071147  [    0/ 4709]
[2022-08-06 15:30:29,165] loss: 0.022932  [  960/ 4709]
[2022-08-06 15:30:29,316] loss: 0.021483  [ 1920/ 4709]
[2022-08-06 15:30:29,467] loss: 0.015365  [ 2880/ 4709]
[2022-08-06 15:30:29,622] loss: 0.008674  [ 3840/ 4709]
[2022-08-06 15:30:30,042] Train Error: Accuracy: 99.936%, Avg loss: 0.009307
[2022-08-06 15:30:30,169] Test  Error: Accuracy: 99.614%, Avg loss: 0.017544
[2022-08-06 15:30:30,169] Epoch 5---------------
[2022-08-06 15:30:30,170] lr: 1.197474e-03
[2022-08-06 15:30:30,183] loss: 0.024312  [    0/ 4709]
[2022-08-06 15:30:30,334] loss: 0.008867  [  960/ 4709]
[2022-08-06 15:30:30,486] loss: 0.006650  [ 1920/ 4709]
[2022-08-06 15:30:30,640] loss: 0.012338  [ 2880/ 4709]
[2022-08-06 15:30:30,792] loss: 0.009184  [ 3840/ 4709]
[2022-08-06 15:30:31,213] Train Error: Accuracy: 99.894%, Avg loss: 0.007858
[2022-08-06 15:30:31,339] Test  Error: Accuracy: 99.711%, Avg loss: 0.014508
[2022-08-06 15:30:31,340] Epoch 6---------------
[2022-08-06 15:30:31,341] lr: 1.137600e-03
[2022-08-06 15:30:31,352] loss: 0.010291  [    0/ 4709]
[2022-08-06 15:30:31,503] loss: 0.002791  [  960/ 4709]
[2022-08-06 15:30:31,658] loss: 0.004068  [ 1920/ 4709]
[2022-08-06 15:30:31,818] loss: 0.003776  [ 2880/ 4709]
[2022-08-06 15:30:31,971] loss: 0.008068  [ 3840/ 4709]
[2022-08-06 15:30:32,389] Train Error: Accuracy: 99.979%, Avg loss: 0.004773
[2022-08-06 15:30:32,518] Test  Error: Accuracy: 99.807%, Avg loss: 0.008796
[2022-08-06 15:30:32,518] Epoch 7---------------
[2022-08-06 15:30:32,519] lr: 1.080720e-03
[2022-08-06 15:30:32,532] loss: 0.007708  [    0/ 4709]
[2022-08-06 15:30:32,684] loss: 0.023434  [  960/ 4709]
[2022-08-06 15:30:32,838] loss: 0.003584  [ 1920/ 4709]
[2022-08-06 15:30:32,989] loss: 0.003163  [ 2880/ 4709]
[2022-08-06 15:30:33,140] loss: 0.016389  [ 3840/ 4709]
[2022-08-06 15:30:33,563] Train Error: Accuracy: 99.936%, Avg loss: 0.004942
[2022-08-06 15:30:33,690] Test  Error: Accuracy: 99.904%, Avg loss: 0.008440
[2022-08-06 15:30:33,690] Epoch 8---------------
[2022-08-06 15:30:33,691] lr: 1.026684e-03
[2022-08-06 15:30:33,704] loss: 0.007102  [    0/ 4709]
[2022-08-06 15:30:33,859] loss: 0.002232  [  960/ 4709]
[2022-08-06 15:30:34,010] loss: 0.005150  [ 1920/ 4709]
[2022-08-06 15:30:34,161] loss: 0.002449  [ 2880/ 4709]
[2022-08-06 15:30:34,311] loss: 0.002684  [ 3840/ 4709]
[2022-08-06 15:30:34,725] Train Error: Accuracy: 99.979%, Avg loss: 0.003337
[2022-08-06 15:30:34,852] Test  Error: Accuracy: 99.952%, Avg loss: 0.005862
[2022-08-06 15:30:34,853] Epoch 9---------------
[2022-08-06 15:30:34,854] lr: 9.753500e-04
[2022-08-06 15:30:34,866] loss: 0.002378  [    0/ 4709]
[2022-08-06 15:30:35,023] loss: 0.005092  [  960/ 4709]
[2022-08-06 15:30:35,174] loss: 0.008205  [ 1920/ 4709]
[2022-08-06 15:30:35,331] loss: 0.001501  [ 2880/ 4709]
[2022-08-06 15:30:35,484] loss: 0.001721  [ 3840/ 4709]
[2022-08-06 15:30:35,900] Train Error: Accuracy: 99.979%, Avg loss: 0.002994
[2022-08-06 15:30:36,028] Test  Error: Accuracy: 99.855%, Avg loss: 0.006647
[2022-08-06 15:30:36,030] Epoch 10---------------
[2022-08-06 15:30:36,030] lr: 7.547072e-04
[2022-08-06 15:30:36,044] loss: 0.003062  [    0/ 4709]
[2022-08-06 15:30:36,199] loss: 0.001593  [  960/ 4709]
[2022-08-06 15:30:36,351] loss: 0.001519  [ 1920/ 4709]
[2022-08-06 15:30:36,503] loss: 0.001812  [ 2880/ 4709]
[2022-08-06 15:30:36,654] loss: 0.002581  [ 3840/ 4709]
[2022-08-06 15:30:37,082] Train Error: Accuracy: 99.958%, Avg loss: 0.002496
[2022-08-06 15:30:37,213] Test  Error: Accuracy: 99.904%, Avg loss: 0.005791
[2022-08-06 15:30:37,213] Done!
[2022-08-06 15:30:37,216] Number of parameters:135050
[2022-08-06 15:30:37,217] ## end time: 2022-08-06 15:30:37.213924
[2022-08-06 15:30:37,217] ## used time: 0:00:12.080788
